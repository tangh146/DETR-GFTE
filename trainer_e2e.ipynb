{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\tangy\\AppData\\Local\\Temp\\ipykernel_16680\\2112509340.py:14: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  checkpoint=\"checkpoints\\encoder-pretraining-1\\loss=0.86.ckpt\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([3, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Detr(\n",
       "  (model): DetrForObjectDetection(\n",
       "    (model): DetrModel(\n",
       "      (backbone): DetrConvModel(\n",
       "        (conv_encoder): DetrConvEncoder(\n",
       "          (model): FeatureListNet(\n",
       "            (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "            (bn1): DetrFrozenBatchNorm2d()\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "            (layer1): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "                (downsample): Sequential(\n",
       "                  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): DetrFrozenBatchNorm2d()\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Bottleneck(\n",
       "                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (layer2): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "                (downsample): Sequential(\n",
       "                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                  (1): DetrFrozenBatchNorm2d()\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Bottleneck(\n",
       "                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (3): Bottleneck(\n",
       "                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (layer3): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "                (downsample): Sequential(\n",
       "                  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                  (1): DetrFrozenBatchNorm2d()\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (3): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (4): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (5): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (layer4): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "                (downsample): Sequential(\n",
       "                  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                  (1): DetrFrozenBatchNorm2d()\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Bottleneck(\n",
       "                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (position_embedding): DetrSinePositionEmbedding()\n",
       "      )\n",
       "      (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (query_position_embeddings): Embedding(100, 256)\n",
       "      (encoder): DetrEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x DetrEncoderLayer(\n",
       "            (self_attn): DetrAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): ReLU()\n",
       "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): DetrDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x DetrDecoderLayer(\n",
       "            (self_attn): DetrAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): DetrAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (class_labels_classifier): Linear(in_features=256, out_features=3, bias=True)\n",
       "    (bbox_predictor): DetrMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (simplified_tbnet): SimplifiedTbNet(\n",
       "    (conv1): GCNConv(256, 256)\n",
       "    (conv2): GCNConv(256, 256)\n",
       "    (lin1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (lin_final): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       "  (gcn_criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models import Detr\n",
    "from utils import load_config\n",
    "import torch\n",
    "\n",
    "config = load_config(r\"configs\\train.yaml\")\n",
    "\n",
    "model = Detr(\n",
    "    train_mode=True,\n",
    "    with_gcn=True,\n",
    "    pretrained='facebook/detr-resnet-50',\n",
    "    checkpoint=\"checkpoints\\encoder-pretraining-1\\loss=0.86.ckpt\",\n",
    "    config=config)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# logger = WandbLogger(project='parallel_tables', name='e2e_attempt_1')\n",
    "\n",
    "# Set up checkpointing and trainer\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation/loss\",\n",
    "    filename=\"detr-{epoch:02d}-{validation/loss:.2f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    "    dirpath=r\"C:\\Users\\tangy\\Downloads\\DETR-GFTE\\checkpoints\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    log_every_n_steps=10,\n",
    "    logger=None,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    val_check_interval=0.5,  # Run validation 2 times per epoch\n",
    "    devices=1,\n",
    "    accelerator=\"gpu\",\n",
    "    gradient_clip_val=0.1,\n",
    "    accumulate_grad_batches=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: c:\\Users\\tangy\\Downloads\\DETR-GFTE\\lightning_logs\n",
      "c:\\Users\\tangy\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory C:\\Users\\tangy\\Downloads\\DETR-GFTE\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                   | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | model            | DetrForObjectDetection | 41.5 M | train\n",
      "1 | simplified_tbnet | SimplifiedTbNet        | 263 K  | train\n",
      "2 | gcn_criterion    | NLLLoss                | 0      | train\n",
      "--------------------------------------------------------------------\n",
      "41.5 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "41.8 M    Total params\n",
      "167.063   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede94f87b78a450382e052853a65eac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tangy\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\tangy\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ee23874b1c4502ab4828d776eb198e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 - Training Loss: 2.3237009048461914\n",
      "Batch 0 - loss_ce: 0.09316719323396683\n",
      "Batch 0 - loss_bbox: 0.027639105916023254\n",
      "Batch 0 - loss_giou: 0.3572673499584198\n",
      "Batch 0 - cardinality_error: 31.75\n",
      "Batch 0 - gcn_loss: 1.3778034448623657\n",
      "Batch 1 - Training Loss: 2.408313274383545\n",
      "Batch 1 - loss_ce: 0.051782190799713135\n",
      "Batch 1 - loss_bbox: 0.03437685966491699\n",
      "Batch 1 - loss_giou: 0.4069203734397888\n",
      "Batch 1 - cardinality_error: 30.75\n",
      "Batch 1 - gcn_loss: 1.3708058595657349\n",
      "Batch 2 - Training Loss: 1.9261085987091064\n",
      "Batch 2 - loss_ce: 0.027516089379787445\n",
      "Batch 2 - loss_bbox: 0.017769910395145416\n",
      "Batch 2 - loss_giou: 0.23768889904022217\n",
      "Batch 2 - cardinality_error: 108.0\n",
      "Batch 2 - gcn_loss: 1.3343651294708252\n",
      "Batch 3 - Training Loss: 2.3871939182281494\n",
      "Batch 3 - loss_ce: 0.030021892860531807\n",
      "Batch 3 - loss_bbox: 0.03727351874113083\n",
      "Batch 3 - loss_giou: 0.40244245529174805\n",
      "Batch 3 - cardinality_error: 19.5\n",
      "Batch 3 - gcn_loss: 1.3659194707870483\n",
      "Batch 4 - Training Loss: 1.9630613327026367\n",
      "Batch 4 - loss_ce: 0.058700401335954666\n",
      "Batch 4 - loss_bbox: 0.011838161386549473\n",
      "Batch 4 - loss_giou: 0.22280853986740112\n",
      "Batch 4 - cardinality_error: 29.0\n",
      "Batch 4 - gcn_loss: 1.3995530605316162\n",
      "Batch 5 - Training Loss: 2.172518014907837\n",
      "Batch 5 - loss_ce: 0.10493314266204834\n",
      "Batch 5 - loss_bbox: 0.0184775423258543\n",
      "Batch 5 - loss_giou: 0.2909954786300659\n",
      "Batch 5 - cardinality_error: 35.75\n",
      "Batch 5 - gcn_loss: 1.393206238746643\n",
      "Batch 6 - Training Loss: 1.9822807312011719\n",
      "Batch 6 - loss_ce: 0.030334528535604477\n",
      "Batch 6 - loss_bbox: 0.010909258387982845\n",
      "Batch 6 - loss_giou: 0.24959567189216614\n",
      "Batch 6 - cardinality_error: 46.25\n",
      "Batch 6 - gcn_loss: 1.3982086181640625\n",
      "Batch 7 - Training Loss: 2.3792600631713867\n",
      "Batch 7 - loss_ce: 0.17224445939064026\n",
      "Batch 7 - loss_bbox: 0.02539784647524357\n",
      "Batch 7 - loss_giou: 0.3357115685939789\n",
      "Batch 7 - cardinality_error: 29.75\n",
      "Batch 7 - gcn_loss: 1.4086031913757324\n",
      "Batch 8 - Training Loss: 2.4863622188568115\n",
      "Batch 8 - loss_ce: 0.1535903960466385\n",
      "Batch 8 - loss_bbox: 0.04409105330705643\n",
      "Batch 8 - loss_giou: 0.35276609659194946\n",
      "Batch 8 - cardinality_error: 23.25\n",
      "Batch 8 - gcn_loss: 1.4067842960357666\n",
      "Batch 9 - Training Loss: 3.154306173324585\n",
      "Batch 9 - loss_ce: 0.06417980790138245\n",
      "Batch 9 - loss_bbox: 0.10932578146457672\n",
      "Batch 9 - loss_giou: 0.5748746395111084\n",
      "Batch 9 - cardinality_error: 19.75\n",
      "Batch 9 - gcn_loss: 1.393748164176941\n",
      "Batch 10 - Training Loss: 2.8230767250061035\n",
      "Batch 10 - loss_ce: 0.1077873632311821\n",
      "Batch 10 - loss_bbox: 0.07645143568515778\n",
      "Batch 10 - loss_giou: 0.4666258692741394\n",
      "Batch 10 - cardinality_error: 16.75\n",
      "Batch 10 - gcn_loss: 1.3997803926467896\n",
      "Batch 11 - Training Loss: 2.0364017486572266\n",
      "Batch 11 - loss_ce: 0.09772269427776337\n",
      "Batch 11 - loss_bbox: 0.013694032095372677\n",
      "Batch 11 - loss_giou: 0.2401999533176422\n",
      "Batch 11 - cardinality_error: 51.0\n",
      "Batch 11 - gcn_loss: 1.3898091316223145\n",
      "Batch 12 - Training Loss: 3.011345863342285\n",
      "Batch 12 - loss_ce: 0.09166882187128067\n",
      "Batch 12 - loss_bbox: 0.06799766421318054\n",
      "Batch 12 - loss_giou: 0.63475501537323\n",
      "Batch 12 - cardinality_error: 16.75\n",
      "Batch 12 - gcn_loss: 1.3101788759231567\n",
      "Batch 13 - Training Loss: 2.7862586975097656\n",
      "Batch 13 - loss_ce: 0.11283230781555176\n",
      "Batch 13 - loss_bbox: 0.05044535920023918\n",
      "Batch 13 - loss_giou: 0.5457054972648621\n",
      "Batch 13 - cardinality_error: 27.75\n",
      "Batch 13 - gcn_loss: 1.3297884464263916\n",
      "Batch 14 - Training Loss: 2.790437698364258\n",
      "Batch 14 - loss_ce: 0.06978823989629745\n",
      "Batch 14 - loss_bbox: 0.05638958886265755\n",
      "Batch 14 - loss_giou: 0.5626291036605835\n",
      "Batch 14 - cardinality_error: 17.25\n",
      "Batch 14 - gcn_loss: 1.3134433031082153\n",
      "Batch 15 - Training Loss: 2.916959285736084\n",
      "Batch 15 - loss_ce: 0.14600206911563873\n",
      "Batch 15 - loss_bbox: 0.05516558513045311\n",
      "Batch 15 - loss_giou: 0.5755566358566284\n",
      "Batch 15 - cardinality_error: 18.0\n",
      "Batch 15 - gcn_loss: 1.344016194343567\n",
      "Batch 16 - Training Loss: 2.585517406463623\n",
      "Batch 16 - loss_ce: 0.14336876571178436\n",
      "Batch 16 - loss_bbox: 0.03814918175339699\n",
      "Batch 16 - loss_giou: 0.45482009649276733\n",
      "Batch 16 - cardinality_error: 16.75\n",
      "Batch 16 - gcn_loss: 1.3417625427246094\n",
      "Batch 17 - Training Loss: 2.791227102279663\n",
      "Batch 17 - loss_ce: 0.16159655153751373\n",
      "Batch 17 - loss_bbox: 0.05801881477236748\n",
      "Batch 17 - loss_giou: 0.5006895661354065\n",
      "Batch 17 - cardinality_error: 13.5\n",
      "Batch 17 - gcn_loss: 1.3381574153900146\n",
      "Batch 18 - Training Loss: 2.427093505859375\n",
      "Batch 18 - loss_ce: 0.11188089102506638\n",
      "Batch 18 - loss_bbox: 0.02158357948064804\n",
      "Batch 18 - loss_giou: 0.4431651830673218\n",
      "Batch 18 - cardinality_error: 29.5\n",
      "Batch 18 - gcn_loss: 1.3209642171859741\n",
      "Batch 19 - Training Loss: 2.0466394424438477\n",
      "Batch 19 - loss_ce: 0.005693146493285894\n",
      "Batch 19 - loss_bbox: 0.01926121488213539\n",
      "Batch 19 - loss_giou: 0.33803603053092957\n",
      "Batch 19 - cardinality_error: 110.0\n",
      "Batch 19 - gcn_loss: 1.2685681581497192\n",
      "Batch 20 - Training Loss: 2.269900321960449\n",
      "Batch 20 - loss_ce: 0.04333938658237457\n",
      "Batch 20 - loss_bbox: 0.023955615237355232\n",
      "Batch 20 - loss_giou: 0.39932015538215637\n",
      "Batch 20 - cardinality_error: 29.75\n",
      "Batch 20 - gcn_loss: 1.3081425428390503\n",
      "Batch 21 - Training Loss: 2.638195514678955\n",
      "Batch 21 - loss_ce: 0.10087940841913223\n",
      "Batch 21 - loss_bbox: 0.03828693926334381\n",
      "Batch 21 - loss_giou: 0.5054514408111572\n",
      "Batch 21 - cardinality_error: 31.25\n",
      "Batch 21 - gcn_loss: 1.334978699684143\n",
      "Batch 22 - Training Loss: 2.6555583477020264\n",
      "Batch 22 - loss_ce: 0.17207568883895874\n",
      "Batch 22 - loss_bbox: 0.046919677406549454\n",
      "Batch 22 - loss_giou: 0.45704740285873413\n",
      "Batch 22 - cardinality_error: 27.25\n",
      "Batch 22 - gcn_loss: 1.334789514541626\n",
      "Batch 23 - Training Loss: 2.6914947032928467\n",
      "Batch 23 - loss_ce: 0.09122872352600098\n",
      "Batch 23 - loss_bbox: 0.047874655574560165\n",
      "Batch 23 - loss_giou: 0.5098063349723816\n",
      "Batch 23 - cardinality_error: 12.5\n",
      "Batch 23 - gcn_loss: 1.3412799835205078\n",
      "Batch 24 - Training Loss: 2.5727689266204834\n",
      "Batch 24 - loss_ce: 0.1906966269016266\n",
      "Batch 24 - loss_bbox: 0.038086868822574615\n",
      "Batch 24 - loss_giou: 0.44742774963378906\n",
      "Batch 24 - cardinality_error: 24.75\n",
      "Batch 24 - gcn_loss: 1.2967824935913086\n",
      "Batch 25 - Training Loss: 2.0366220474243164\n",
      "Batch 25 - loss_ce: 0.02030123770236969\n",
      "Batch 25 - loss_bbox: 0.023939449340105057\n",
      "Batch 25 - loss_giou: 0.3464111387729645\n",
      "Batch 25 - cardinality_error: 66.0\n",
      "Batch 25 - gcn_loss: 1.203801155090332\n",
      "Batch 26 - Training Loss: 2.4722206592559814\n",
      "Batch 26 - loss_ce: 0.14807648956775665\n",
      "Batch 26 - loss_bbox: 0.034186795353889465\n",
      "Batch 26 - loss_giou: 0.42537686228752136\n",
      "Batch 26 - cardinality_error: 36.5\n",
      "Batch 26 - gcn_loss: 1.3024564981460571\n",
      "Batch 27 - Training Loss: 2.4055418968200684\n",
      "Batch 27 - loss_ce: 0.14489057660102844\n",
      "Batch 27 - loss_bbox: 0.03259975090622902\n",
      "Batch 27 - loss_giou: 0.4010317325592041\n",
      "Batch 27 - cardinality_error: 27.25\n",
      "Batch 27 - gcn_loss: 1.2955892086029053\n",
      "Batch 28 - Training Loss: 2.328496217727661\n",
      "Batch 28 - loss_ce: 0.11379958689212799\n",
      "Batch 28 - loss_bbox: 0.037540096789598465\n",
      "Batch 28 - loss_giou: 0.3840099275112152\n",
      "Batch 28 - cardinality_error: 32.25\n",
      "Batch 28 - gcn_loss: 1.2589762210845947\n",
      "Batch 29 - Training Loss: 1.9160661697387695\n",
      "Batch 29 - loss_ce: 0.0536976158618927\n",
      "Batch 29 - loss_bbox: 0.01605081371963024\n",
      "Batch 29 - loss_giou: 0.27770307660102844\n",
      "Batch 29 - cardinality_error: 89.25\n",
      "Batch 29 - gcn_loss: 1.2267082929611206\n",
      "Batch 30 - Training Loss: 2.469029426574707\n",
      "Batch 30 - loss_ce: 0.06601853668689728\n",
      "Batch 30 - loss_bbox: 0.043435703963041306\n",
      "Batch 30 - loss_giou: 0.46513304114341736\n",
      "Batch 30 - cardinality_error: 30.75\n",
      "Batch 30 - gcn_loss: 1.2555663585662842\n",
      "Batch 31 - Training Loss: 2.2479500770568848\n",
      "Batch 31 - loss_ce: 0.06518445909023285\n",
      "Batch 31 - loss_bbox: 0.01773439347743988\n",
      "Batch 31 - loss_giou: 0.43231698870658875\n",
      "Batch 31 - cardinality_error: 45.0\n",
      "Batch 31 - gcn_loss: 1.2294596433639526\n",
      "Batch 32 - Training Loss: 2.3697078227996826\n",
      "Batch 32 - loss_ce: 0.10477518290281296\n",
      "Batch 32 - loss_bbox: 0.03750849515199661\n",
      "Batch 32 - loss_giou: 0.40449362993240356\n",
      "Batch 32 - cardinality_error: 18.0\n",
      "Batch 32 - gcn_loss: 1.2684029340744019\n",
      "Batch 33 - Training Loss: 2.211254596710205\n",
      "Batch 33 - loss_ce: 0.0659342110157013\n",
      "Batch 33 - loss_bbox: 0.03181585296988487\n",
      "Batch 33 - loss_giou: 0.3648439645767212\n",
      "Batch 33 - cardinality_error: 36.25\n",
      "Batch 33 - gcn_loss: 1.2565531730651855\n",
      "Batch 34 - Training Loss: 2.3160245418548584\n",
      "Batch 34 - loss_ce: 0.022350309416651726\n",
      "Batch 34 - loss_bbox: 0.03826059773564339\n",
      "Batch 34 - loss_giou: 0.44864726066589355\n",
      "Batch 34 - cardinality_error: 46.75\n",
      "Batch 34 - gcn_loss: 1.2050766944885254\n",
      "Batch 35 - Training Loss: 2.4335451126098633\n",
      "Batch 35 - loss_ce: 0.10086698085069656\n",
      "Batch 35 - loss_bbox: 0.04189921170473099\n",
      "Batch 35 - loss_giou: 0.41995808482170105\n",
      "Batch 35 - cardinality_error: 20.0\n",
      "Batch 35 - gcn_loss: 1.2832660675048828\n",
      "Batch 36 - Training Loss: 2.2447829246520996\n",
      "Batch 36 - loss_ce: 0.02117997035384178\n",
      "Batch 36 - loss_bbox: 0.04753313958644867\n",
      "Batch 36 - loss_giou: 0.4009643495082855\n",
      "Batch 36 - cardinality_error: 35.75\n",
      "Batch 36 - gcn_loss: 1.1840085983276367\n",
      "Batch 37 - Training Loss: 1.9020311832427979\n",
      "Batch 37 - loss_ce: 0.06708498299121857\n",
      "Batch 37 - loss_bbox: 0.016989102587103844\n",
      "Batch 37 - loss_giou: 0.2784416973590851\n",
      "Batch 37 - cardinality_error: 49.0\n",
      "Batch 37 - gcn_loss: 1.1931172609329224\n",
      "Batch 38 - Training Loss: 2.4139113426208496\n",
      "Batch 38 - loss_ce: 0.13201311230659485\n",
      "Batch 38 - loss_bbox: 0.038875218480825424\n",
      "Batch 38 - loss_giou: 0.42341718077659607\n",
      "Batch 38 - cardinality_error: 20.25\n",
      "Batch 38 - gcn_loss: 1.2406879663467407\n",
      "Batch 39 - Training Loss: 1.9945437908172607\n",
      "Batch 39 - loss_ce: 0.05709623172879219\n",
      "Batch 39 - loss_bbox: 0.01841997727751732\n",
      "Batch 39 - loss_giou: 0.3347970247268677\n",
      "Batch 39 - cardinality_error: 64.75\n",
      "Batch 39 - gcn_loss: 1.1757535934448242\n",
      "Batch 40 - Training Loss: 2.221296787261963\n",
      "Batch 40 - loss_ce: 0.0757535994052887\n",
      "Batch 40 - loss_bbox: 0.03523897007107735\n",
      "Batch 40 - loss_giou: 0.3661222755908966\n",
      "Batch 40 - cardinality_error: 36.75\n",
      "Batch 40 - gcn_loss: 1.2371039390563965\n",
      "Batch 41 - Training Loss: 2.0416998863220215\n",
      "Batch 41 - loss_ce: 0.0905255600810051\n",
      "Batch 41 - loss_bbox: 0.022690322250127792\n",
      "Batch 41 - loss_giou: 0.3010016679763794\n",
      "Batch 41 - cardinality_error: 25.75\n",
      "Batch 41 - gcn_loss: 1.2357194423675537\n",
      "Batch 42 - Training Loss: 2.2813563346862793\n",
      "Batch 42 - loss_ce: 0.092591792345047\n",
      "Batch 42 - loss_bbox: 0.04128867760300636\n",
      "Batch 42 - loss_giou: 0.38314810395240784\n",
      "Batch 42 - cardinality_error: 34.75\n",
      "Batch 42 - gcn_loss: 1.2160247564315796\n",
      "Batch 43 - Training Loss: 2.1957058906555176\n",
      "Batch 43 - loss_ce: 0.14366859197616577\n",
      "Batch 43 - loss_bbox: 0.028386646881699562\n",
      "Batch 43 - loss_giou: 0.34250548481941223\n",
      "Batch 43 - cardinality_error: 18.5\n",
      "Batch 43 - gcn_loss: 1.225093126296997\n",
      "Batch 44 - Training Loss: 2.3139071464538574\n",
      "Batch 44 - loss_ce: 0.1849347949028015\n",
      "Batch 44 - loss_bbox: 0.0284787118434906\n",
      "Batch 44 - loss_giou: 0.35336461663246155\n",
      "Batch 44 - cardinality_error: 34.75\n",
      "Batch 44 - gcn_loss: 1.279849648475647\n",
      "Batch 45 - Training Loss: 2.2691593170166016\n",
      "Batch 45 - loss_ce: 0.12678863108158112\n",
      "Batch 45 - loss_bbox: 0.0321025624871254\n",
      "Batch 45 - loss_giou: 0.3928427994251251\n",
      "Batch 45 - cardinality_error: 27.25\n",
      "Batch 45 - gcn_loss: 1.1961723566055298\n",
      "Batch 46 - Training Loss: 2.423818588256836\n",
      "Batch 46 - loss_ce: 0.12467928975820541\n",
      "Batch 46 - loss_bbox: 0.0442301481962204\n",
      "Batch 46 - loss_giou: 0.43369168043136597\n",
      "Batch 46 - cardinality_error: 24.0\n",
      "Batch 46 - gcn_loss: 1.2106051445007324\n",
      "Batch 47 - Training Loss: 2.340775728225708\n",
      "Batch 47 - loss_ce: 0.0677691102027893\n",
      "Batch 47 - loss_bbox: 0.030925318598747253\n",
      "Batch 47 - loss_giou: 0.4458761215209961\n",
      "Batch 47 - cardinality_error: 30.5\n",
      "Batch 47 - gcn_loss: 1.2266278266906738\n",
      "Batch 48 - Training Loss: 1.9051878452301025\n",
      "Batch 48 - loss_ce: 0.07246957719326019\n",
      "Batch 48 - loss_bbox: 0.02007262408733368\n",
      "Batch 48 - loss_giou: 0.2905784547328949\n",
      "Batch 48 - cardinality_error: 24.5\n",
      "Batch 48 - gcn_loss: 1.1511982679367065\n",
      "Batch 49 - Training Loss: 2.444486141204834\n",
      "Batch 49 - loss_ce: 0.12211617827415466\n",
      "Batch 49 - loss_bbox: 0.05324753373861313\n",
      "Batch 49 - loss_giou: 0.44075003266334534\n",
      "Batch 49 - cardinality_error: 23.25\n",
      "Batch 49 - gcn_loss: 1.1746320724487305\n",
      "Batch 50 - Training Loss: 2.5162806510925293\n",
      "Batch 50 - loss_ce: 0.08185503631830215\n",
      "Batch 50 - loss_bbox: 0.06442227214574814\n",
      "Batch 50 - loss_giou: 0.4500313103199005\n",
      "Batch 50 - cardinality_error: 11.25\n",
      "Batch 50 - gcn_loss: 1.2122517824172974\n",
      "Batch 51 - Training Loss: 2.3075337409973145\n",
      "Batch 51 - loss_ce: 0.022005576640367508\n",
      "Batch 51 - loss_bbox: 0.04634643346071243\n",
      "Batch 51 - loss_giou: 0.4608536660671234\n",
      "Batch 51 - cardinality_error: 29.0\n",
      "Batch 51 - gcn_loss: 1.1320887804031372\n",
      "Batch 52 - Training Loss: 2.0806844234466553\n",
      "Batch 52 - loss_ce: 0.09058300405740738\n",
      "Batch 52 - loss_bbox: 0.027085844427347183\n",
      "Batch 52 - loss_giou: 0.35221001505851746\n",
      "Batch 52 - cardinality_error: 24.25\n",
      "Batch 52 - gcn_loss: 1.150252103805542\n",
      "Batch 53 - Training Loss: 2.386798858642578\n",
      "Batch 53 - loss_ce: 0.17501488327980042\n",
      "Batch 53 - loss_bbox: 0.04583638906478882\n",
      "Batch 53 - loss_giou: 0.3896538019180298\n",
      "Batch 53 - cardinality_error: 16.5\n",
      "Batch 53 - gcn_loss: 1.203294277191162\n",
      "Batch 54 - Training Loss: 2.6176538467407227\n",
      "Batch 54 - loss_ce: 0.12016843259334564\n",
      "Batch 54 - loss_bbox: 0.06862900406122208\n",
      "Batch 54 - loss_giou: 0.4628952443599701\n",
      "Batch 54 - cardinality_error: 22.25\n",
      "Batch 54 - gcn_loss: 1.2285500764846802\n",
      "Batch 55 - Training Loss: 2.209359884262085\n",
      "Batch 55 - loss_ce: 0.12719427049160004\n",
      "Batch 55 - loss_bbox: 0.03954075276851654\n",
      "Batch 55 - loss_giou: 0.34397220611572266\n",
      "Batch 55 - cardinality_error: 26.0\n",
      "Batch 55 - gcn_loss: 1.1965174674987793\n",
      "Batch 56 - Training Loss: 1.9982783794403076\n",
      "Batch 56 - loss_ce: 0.0801842212677002\n",
      "Batch 56 - loss_bbox: 0.02582678198814392\n",
      "Batch 56 - loss_giou: 0.3237378001213074\n",
      "Batch 56 - cardinality_error: 26.25\n",
      "Batch 56 - gcn_loss: 1.1414846181869507\n",
      "Batch 57 - Training Loss: 2.0789873600006104\n",
      "Batch 57 - loss_ce: 0.20405793190002441\n",
      "Batch 57 - loss_bbox: 0.02770390175282955\n",
      "Batch 57 - loss_giou: 0.2748611271381378\n",
      "Batch 57 - cardinality_error: 34.0\n",
      "Batch 57 - gcn_loss: 1.1866875886917114\n",
      "Batch 58 - Training Loss: 2.4522879123687744\n",
      "Batch 58 - loss_ce: 0.11558997631072998\n",
      "Batch 58 - loss_bbox: 0.05389300733804703\n",
      "Batch 58 - loss_giou: 0.4149359166622162\n",
      "Batch 58 - cardinality_error: 22.75\n",
      "Batch 58 - gcn_loss: 1.2373610734939575\n",
      "Batch 59 - Training Loss: 2.161280393600464\n",
      "Batch 59 - loss_ce: 0.10696516185998917\n",
      "Batch 59 - loss_bbox: 0.03155281022191048\n",
      "Batch 59 - loss_giou: 0.3721773028373718\n",
      "Batch 59 - cardinality_error: 28.25\n",
      "Batch 59 - gcn_loss: 1.1521966457366943\n",
      "Batch 60 - Training Loss: 2.5205307006835938\n",
      "Batch 60 - loss_ce: 0.07696323841810226\n",
      "Batch 60 - loss_bbox: 0.049215398728847504\n",
      "Batch 60 - loss_giou: 0.5156033635139465\n",
      "Batch 60 - cardinality_error: 23.5\n",
      "Batch 60 - gcn_loss: 1.1662836074829102\n",
      "Batch 61 - Training Loss: 2.2633535861968994\n",
      "Batch 61 - loss_ce: 0.1265769898891449\n",
      "Batch 61 - loss_bbox: 0.03441040217876434\n",
      "Batch 61 - loss_giou: 0.4021582007408142\n",
      "Batch 61 - cardinality_error: 24.5\n",
      "Batch 61 - gcn_loss: 1.1604082584381104\n",
      "Batch 62 - Training Loss: 2.01282000541687\n",
      "Batch 62 - loss_ce: 0.06391619145870209\n",
      "Batch 62 - loss_bbox: 0.03162024915218353\n",
      "Batch 62 - loss_giou: 0.3525983691215515\n",
      "Batch 62 - cardinality_error: 47.25\n",
      "Batch 62 - gcn_loss: 1.0856058597564697\n",
      "Batch 63 - Training Loss: 2.719313144683838\n",
      "Batch 63 - loss_ce: 0.06536991894245148\n",
      "Batch 63 - loss_bbox: 0.07261981070041656\n",
      "Batch 63 - loss_giou: 0.5603384375572205\n",
      "Batch 63 - cardinality_error: 15.25\n",
      "Batch 63 - gcn_loss: 1.170167326927185\n",
      "Batch 64 - Training Loss: 1.944138526916504\n",
      "Batch 64 - loss_ce: 0.16142849624156952\n",
      "Batch 64 - loss_bbox: 0.02594504877924919\n",
      "Batch 64 - loss_giou: 0.2709882855415344\n",
      "Batch 64 - cardinality_error: 18.25\n",
      "Batch 64 - gcn_loss: 1.1110081672668457\n",
      "Batch 65 - Training Loss: 2.362581729888916\n",
      "Batch 65 - loss_ce: 0.20347487926483154\n",
      "Batch 65 - loss_bbox: 0.03643791005015373\n",
      "Batch 65 - loss_giou: 0.4244145452976227\n",
      "Batch 65 - cardinality_error: 26.75\n",
      "Batch 65 - gcn_loss: 1.128088355064392\n",
      "Batch 66 - Training Loss: 2.207352876663208\n",
      "Batch 66 - loss_ce: 0.1741001009941101\n",
      "Batch 66 - loss_bbox: 0.031125763431191444\n",
      "Batch 66 - loss_giou: 0.36107566952705383\n",
      "Batch 66 - cardinality_error: 27.25\n",
      "Batch 66 - gcn_loss: 1.1554726362228394\n",
      "Batch 67 - Training Loss: 2.316260814666748\n",
      "Batch 67 - loss_ce: 0.01772131212055683\n",
      "Batch 67 - loss_bbox: 0.05116837099194527\n",
      "Batch 67 - loss_giou: 0.45398080348968506\n",
      "Batch 67 - cardinality_error: 18.75\n",
      "Batch 67 - gcn_loss: 1.134736180305481\n",
      "Batch 68 - Training Loss: 1.8465347290039062\n",
      "Batch 68 - loss_ce: 0.07086632400751114\n",
      "Batch 68 - loss_bbox: 0.01621682196855545\n",
      "Batch 68 - loss_giou: 0.2984694242477417\n",
      "Batch 68 - cardinality_error: 51.0\n",
      "Batch 68 - gcn_loss: 1.0976455211639404\n",
      "Batch 69 - Training Loss: 2.297288417816162\n",
      "Batch 69 - loss_ce: 0.05132472515106201\n",
      "Batch 69 - loss_bbox: 0.04306471720337868\n",
      "Batch 69 - loss_giou: 0.45643115043640137\n",
      "Batch 69 - cardinality_error: 16.0\n",
      "Batch 69 - gcn_loss: 1.117777943611145\n",
      "Batch 70 - Training Loss: 2.208616256713867\n",
      "Batch 70 - loss_ce: 0.11853399872779846\n",
      "Batch 70 - loss_bbox: 0.027986396104097366\n",
      "Batch 70 - loss_giou: 0.3813510835170746\n",
      "Batch 70 - cardinality_error: 19.0\n",
      "Batch 70 - gcn_loss: 1.1874481439590454\n",
      "Batch 71 - Training Loss: 2.3383898735046387\n",
      "Batch 71 - loss_ce: 0.2100794017314911\n",
      "Batch 71 - loss_bbox: 0.037316225469112396\n",
      "Batch 71 - loss_giou: 0.4032517373561859\n",
      "Batch 71 - cardinality_error: 21.0\n",
      "Batch 71 - gcn_loss: 1.1352258920669556\n",
      "Batch 72 - Training Loss: 1.9788882732391357\n",
      "Batch 72 - loss_ce: 0.11632087081670761\n",
      "Batch 72 - loss_bbox: 0.016241559758782387\n",
      "Batch 72 - loss_giou: 0.3279310166835785\n",
      "Batch 72 - cardinality_error: 25.75\n",
      "Batch 72 - gcn_loss: 1.125497579574585\n",
      "Batch 73 - Training Loss: 2.0087804794311523\n",
      "Batch 73 - loss_ce: 0.013912119902670383\n",
      "Batch 73 - loss_bbox: 0.03812991455197334\n",
      "Batch 73 - loss_giou: 0.38831406831741333\n",
      "Batch 73 - cardinality_error: 54.25\n",
      "Batch 73 - gcn_loss: 1.0275907516479492\n",
      "Batch 74 - Training Loss: 2.319115161895752\n",
      "Batch 74 - loss_ce: 0.1117149218916893\n",
      "Batch 74 - loss_bbox: 0.041546642780303955\n",
      "Batch 74 - loss_giou: 0.45670342445373535\n",
      "Batch 74 - cardinality_error: 22.0\n",
      "Batch 74 - gcn_loss: 1.0862603187561035\n",
      "Batch 75 - Training Loss: 1.8885371685028076\n",
      "Batch 75 - loss_ce: 0.06501390039920807\n",
      "Batch 75 - loss_bbox: 0.01660667546093464\n",
      "Batch 75 - loss_giou: 0.34324055910110474\n",
      "Batch 75 - cardinality_error: 40.5\n",
      "Batch 75 - gcn_loss: 1.0540088415145874\n",
      "Batch 76 - Training Loss: 1.8953814506530762\n",
      "Batch 76 - loss_ce: 0.08259185403585434\n",
      "Batch 76 - loss_bbox: 0.025125978514552116\n",
      "Batch 76 - loss_giou: 0.31065359711647034\n",
      "Batch 76 - cardinality_error: 25.25\n",
      "Batch 76 - gcn_loss: 1.0658525228500366\n",
      "Batch 77 - Training Loss: 2.2116384506225586\n",
      "Batch 77 - loss_ce: 0.061782825738191605\n",
      "Batch 77 - loss_bbox: 0.055541638284921646\n",
      "Batch 77 - loss_giou: 0.4159737527370453\n",
      "Batch 77 - cardinality_error: 43.25\n",
      "Batch 77 - gcn_loss: 1.0401999950408936\n",
      "Batch 78 - Training Loss: 2.532714366912842\n",
      "Batch 78 - loss_ce: 0.14002977311611176\n",
      "Batch 78 - loss_bbox: 0.08545923233032227\n",
      "Batch 78 - loss_giou: 0.43237778544425964\n",
      "Batch 78 - cardinality_error: 16.25\n",
      "Batch 78 - gcn_loss: 1.1006330251693726\n",
      "Batch 79 - Training Loss: 2.60494327545166\n",
      "Batch 79 - loss_ce: 0.07691646367311478\n",
      "Batch 79 - loss_bbox: 0.06808976829051971\n",
      "Batch 79 - loss_giou: 0.5632483959197998\n",
      "Batch 79 - cardinality_error: 19.25\n",
      "Batch 79 - gcn_loss: 1.0610812902450562\n",
      "Batch 80 - Training Loss: 1.9379737377166748\n",
      "Batch 80 - loss_ce: 0.04856792837381363\n",
      "Batch 80 - loss_bbox: 0.028392016887664795\n",
      "Batch 80 - loss_giou: 0.36749669909477234\n",
      "Batch 80 - cardinality_error: 47.25\n",
      "Batch 80 - gcn_loss: 1.0124523639678955\n",
      "Batch 81 - Training Loss: 1.9559528827667236\n",
      "Batch 81 - loss_ce: 0.10317154973745346\n",
      "Batch 81 - loss_bbox: 0.01880349963903427\n",
      "Batch 81 - loss_giou: 0.35915639996528625\n",
      "Batch 81 - cardinality_error: 36.0\n",
      "Batch 81 - gcn_loss: 1.0404510498046875\n",
      "Batch 82 - Training Loss: 2.4136695861816406\n",
      "Batch 82 - loss_ce: 0.09082633256912231\n",
      "Batch 82 - loss_bbox: 0.04224482923746109\n",
      "Batch 82 - loss_giou: 0.5007542967796326\n",
      "Batch 82 - cardinality_error: 45.5\n",
      "Batch 82 - gcn_loss: 1.1101105213165283\n",
      "Batch 83 - Training Loss: 2.041837215423584\n",
      "Batch 83 - loss_ce: 0.0549885556101799\n",
      "Batch 83 - loss_bbox: 0.02698601596057415\n",
      "Batch 83 - loss_giou: 0.3953520357608795\n",
      "Batch 83 - cardinality_error: 26.75\n",
      "Batch 83 - gcn_loss: 1.061214566230774\n",
      "Batch 84 - Training Loss: 1.8826349973678589\n",
      "Batch 84 - loss_ce: 0.07076576352119446\n",
      "Batch 84 - loss_bbox: 0.0285637266933918\n",
      "Batch 84 - loss_giou: 0.3241761028766632\n",
      "Batch 84 - cardinality_error: 78.0\n",
      "Batch 84 - gcn_loss: 1.0206984281539917\n",
      "Batch 85 - Training Loss: 2.5595202445983887\n",
      "Batch 85 - loss_ce: 0.1273927241563797\n",
      "Batch 85 - loss_bbox: 0.06032009422779083\n",
      "Batch 85 - loss_giou: 0.5542720556259155\n",
      "Batch 85 - cardinality_error: 20.25\n",
      "Batch 85 - gcn_loss: 1.0219827890396118\n",
      "Batch 86 - Training Loss: 1.7758163213729858\n",
      "Batch 86 - loss_ce: 0.06246790662407875\n",
      "Batch 86 - loss_bbox: 0.016576146706938744\n",
      "Batch 86 - loss_giou: 0.301220566034317\n",
      "Batch 86 - cardinality_error: 42.75\n",
      "Batch 86 - gcn_loss: 1.0280265808105469\n",
      "Batch 87 - Training Loss: 2.6049461364746094\n",
      "Batch 87 - loss_ce: 0.07079965621232986\n",
      "Batch 87 - loss_bbox: 0.08059950917959213\n",
      "Batch 87 - loss_giou: 0.5334656834602356\n",
      "Batch 87 - cardinality_error: 15.75\n",
      "Batch 87 - gcn_loss: 1.0642175674438477\n",
      "Batch 88 - Training Loss: 1.8219314813613892\n",
      "Batch 88 - loss_ce: 0.13833926618099213\n",
      "Batch 88 - loss_bbox: 0.016501545906066895\n",
      "Batch 88 - loss_giou: 0.2842658758163452\n",
      "Batch 88 - cardinality_error: 40.0\n",
      "Batch 88 - gcn_loss: 1.032552719116211\n",
      "Batch 89 - Training Loss: 1.925581693649292\n",
      "Batch 89 - loss_ce: 0.14870107173919678\n",
      "Batch 89 - loss_bbox: 0.022094445303082466\n",
      "Batch 89 - loss_giou: 0.3332628011703491\n",
      "Batch 89 - cardinality_error: 22.25\n",
      "Batch 89 - gcn_loss: 0.9998828172683716\n",
      "Batch 90 - Training Loss: 2.1974778175354004\n",
      "Batch 90 - loss_ce: 0.11580843478441238\n",
      "Batch 90 - loss_bbox: 0.04122179001569748\n",
      "Batch 90 - loss_giou: 0.3921648859977722\n",
      "Batch 90 - cardinality_error: 15.75\n",
      "Batch 90 - gcn_loss: 1.0912305116653442\n",
      "Batch 91 - Training Loss: 2.0750932693481445\n",
      "Batch 91 - loss_ce: 0.04587046429514885\n",
      "Batch 91 - loss_bbox: 0.03269856795668602\n",
      "Batch 91 - loss_giou: 0.43608856201171875\n",
      "Batch 91 - cardinality_error: 29.5\n",
      "Batch 91 - gcn_loss: 0.9935527443885803\n",
      "Batch 92 - Training Loss: 1.9526958465576172\n",
      "Batch 92 - loss_ce: 0.035185668617486954\n",
      "Batch 92 - loss_bbox: 0.03037034161388874\n",
      "Batch 92 - loss_giou: 0.38468581438064575\n",
      "Batch 92 - cardinality_error: 35.5\n",
      "Batch 92 - gcn_loss: 0.9962868690490723\n",
      "Batch 93 - Training Loss: 1.9030812978744507\n",
      "Batch 93 - loss_ce: 0.04292338341474533\n",
      "Batch 93 - loss_bbox: 0.02658764272928238\n",
      "Batch 93 - loss_giou: 0.3644981384277344\n",
      "Batch 93 - cardinality_error: 67.5\n",
      "Batch 93 - gcn_loss: 0.9982234239578247\n",
      "Batch 94 - Training Loss: 2.6861982345581055\n",
      "Batch 94 - loss_ce: 0.25754302740097046\n",
      "Batch 94 - loss_bbox: 0.07240419089794159\n",
      "Batch 94 - loss_giou: 0.541617214679718\n",
      "Batch 94 - cardinality_error: 36.5\n",
      "Batch 94 - gcn_loss: 0.9833999872207642\n",
      "Batch 95 - Training Loss: 1.946786642074585\n",
      "Batch 95 - loss_ce: 0.1071314737200737\n",
      "Batch 95 - loss_bbox: 0.024407047778367996\n",
      "Batch 95 - loss_giou: 0.3403775990009308\n",
      "Batch 95 - cardinality_error: 28.25\n",
      "Batch 95 - gcn_loss: 1.0368647575378418\n",
      "Batch 96 - Training Loss: 2.0348870754241943\n",
      "Batch 96 - loss_ce: 0.2250427007675171\n",
      "Batch 96 - loss_bbox: 0.030475540086627007\n",
      "Batch 96 - loss_giou: 0.330514132976532\n",
      "Batch 96 - cardinality_error: 19.75\n",
      "Batch 96 - gcn_loss: 0.9964383840560913\n",
      "Batch 97 - Training Loss: 2.264253616333008\n",
      "Batch 97 - loss_ce: 0.1395188719034195\n",
      "Batch 97 - loss_bbox: 0.04370108246803284\n",
      "Batch 97 - loss_giou: 0.4745621681213379\n",
      "Batch 97 - cardinality_error: 23.25\n",
      "Batch 97 - gcn_loss: 0.9571050405502319\n",
      "Batch 98 - Training Loss: 1.7823561429977417\n",
      "Batch 98 - loss_ce: 0.06414908170700073\n",
      "Batch 98 - loss_bbox: 0.01946486532688141\n",
      "Batch 98 - loss_giou: 0.31817343831062317\n",
      "Batch 98 - cardinality_error: 47.0\n",
      "Batch 98 - gcn_loss: 0.9845358729362488\n",
      "Batch 99 - Training Loss: 2.607027530670166\n",
      "Batch 99 - loss_ce: 0.07525168359279633\n",
      "Batch 99 - loss_bbox: 0.0840601697564125\n",
      "Batch 99 - loss_giou: 0.5438307523727417\n",
      "Batch 99 - cardinality_error: 11.75\n",
      "Batch 99 - gcn_loss: 1.0238136053085327\n",
      "Batch 100 - Training Loss: 1.8741931915283203\n",
      "Batch 100 - loss_ce: 0.04717953875660896\n",
      "Batch 100 - loss_bbox: 0.025192871689796448\n",
      "Batch 100 - loss_giou: 0.3329704701900482\n",
      "Batch 100 - cardinality_error: 27.25\n",
      "Batch 100 - gcn_loss: 1.0351083278656006\n",
      "Batch 101 - Training Loss: 1.9378554821014404\n",
      "Batch 101 - loss_ce: 0.02075786702334881\n",
      "Batch 101 - loss_bbox: 0.029671119526028633\n",
      "Batch 101 - loss_giou: 0.42367759346961975\n",
      "Batch 101 - cardinality_error: 33.0\n",
      "Batch 101 - gcn_loss: 0.9213868379592896\n",
      "Batch 102 - Training Loss: 1.9698944091796875\n",
      "Batch 102 - loss_ce: 0.047902777791023254\n",
      "Batch 102 - loss_bbox: 0.0399034321308136\n",
      "Batch 102 - loss_giou: 0.38852185010910034\n",
      "Batch 102 - cardinality_error: 51.75\n",
      "Batch 102 - gcn_loss: 0.9454306960105896\n",
      "Batch 103 - Training Loss: 1.8443381786346436\n",
      "Batch 103 - loss_ce: 0.1637970358133316\n",
      "Batch 103 - loss_bbox: 0.02383720874786377\n",
      "Batch 103 - loss_giou: 0.30023813247680664\n",
      "Batch 103 - cardinality_error: 16.0\n",
      "Batch 103 - gcn_loss: 0.9608787894248962\n",
      "Batch 104 - Training Loss: 2.3099961280822754\n",
      "Batch 104 - loss_ce: 0.14761829376220703\n",
      "Batch 104 - loss_bbox: 0.0467081181704998\n",
      "Batch 104 - loss_giou: 0.47993335127830505\n",
      "Batch 104 - cardinality_error: 26.75\n",
      "Batch 104 - gcn_loss: 0.968970537185669\n",
      "Batch 105 - Training Loss: 1.7466044425964355\n",
      "Batch 105 - loss_ce: 0.08745062351226807\n",
      "Batch 105 - loss_bbox: 0.017434531822800636\n",
      "Batch 105 - loss_giou: 0.3080090582370758\n",
      "Batch 105 - cardinality_error: 36.0\n",
      "Batch 105 - gcn_loss: 0.9559630751609802\n",
      "Batch 106 - Training Loss: 2.142683267593384\n",
      "Batch 106 - loss_ce: 0.07786191999912262\n",
      "Batch 106 - loss_bbox: 0.04298710450530052\n",
      "Batch 106 - loss_giou: 0.43913528323173523\n",
      "Batch 106 - cardinality_error: 13.0\n",
      "Batch 106 - gcn_loss: 0.9716153740882874\n",
      "Batch 107 - Training Loss: 1.9715439081192017\n",
      "Batch 107 - loss_ce: 0.08466673642396927\n",
      "Batch 107 - loss_bbox: 0.03828666731715202\n",
      "Batch 107 - loss_giou: 0.3716902732849121\n",
      "Batch 107 - cardinality_error: 15.5\n",
      "Batch 107 - gcn_loss: 0.9520633220672607\n",
      "Batch 108 - Training Loss: 2.1456379890441895\n",
      "Batch 108 - loss_ce: 0.07626993209123611\n",
      "Batch 108 - loss_bbox: 0.057060565799474716\n",
      "Batch 108 - loss_giou: 0.4238307476043701\n",
      "Batch 108 - cardinality_error: 16.5\n",
      "Batch 108 - gcn_loss: 0.9364038109779358\n",
      "Batch 109 - Training Loss: 1.6911448240280151\n",
      "Batch 109 - loss_ce: 0.07553430646657944\n",
      "Batch 109 - loss_bbox: 0.014373314566910267\n",
      "Batch 109 - loss_giou: 0.3240955173969269\n",
      "Batch 109 - cardinality_error: 51.5\n",
      "Batch 109 - gcn_loss: 0.8955528736114502\n",
      "Batch 110 - Training Loss: 1.9064030647277832\n",
      "Batch 110 - loss_ce: 0.16399528086185455\n",
      "Batch 110 - loss_bbox: 0.018757689744234085\n",
      "Batch 110 - loss_giou: 0.36959466338157654\n",
      "Batch 110 - cardinality_error: 54.0\n",
      "Batch 110 - gcn_loss: 0.9094300270080566\n",
      "Batch 111 - Training Loss: 1.7137129306793213\n",
      "Batch 111 - loss_ce: 0.07329290360212326\n",
      "Batch 111 - loss_bbox: 0.018752872943878174\n",
      "Batch 111 - loss_giou: 0.31838512420654297\n",
      "Batch 111 - cardinality_error: 48.75\n",
      "Batch 111 - gcn_loss: 0.9098854064941406\n",
      "Batch 112 - Training Loss: 2.137415647506714\n",
      "Batch 112 - loss_ce: 0.14934466779232025\n",
      "Batch 112 - loss_bbox: 0.045415248721838\n",
      "Batch 112 - loss_giou: 0.4025101959705353\n",
      "Batch 112 - cardinality_error: 34.25\n",
      "Batch 112 - gcn_loss: 0.9559744000434875\n",
      "Batch 113 - Training Loss: 2.4215216636657715\n",
      "Batch 113 - loss_ce: 0.07786055654287338\n",
      "Batch 113 - loss_bbox: 0.06283141672611237\n",
      "Batch 113 - loss_giou: 0.5366039872169495\n",
      "Batch 113 - cardinality_error: 12.5\n",
      "Batch 113 - gcn_loss: 0.9562959671020508\n",
      "Batch 114 - Training Loss: 1.9415135383605957\n",
      "Batch 114 - loss_ce: 0.032533012330532074\n",
      "Batch 114 - loss_bbox: 0.03948620334267616\n",
      "Batch 114 - loss_giou: 0.39786002039909363\n",
      "Batch 114 - cardinality_error: 25.0\n",
      "Batch 114 - gcn_loss: 0.9158293604850769\n",
      "Batch 115 - Training Loss: 1.9007148742675781\n",
      "Batch 115 - loss_ce: 0.17057214677333832\n",
      "Batch 115 - loss_bbox: 0.024506639689207077\n",
      "Batch 115 - loss_giou: 0.33839699625968933\n",
      "Batch 115 - cardinality_error: 15.25\n",
      "Batch 115 - gcn_loss: 0.930815577507019\n",
      "Batch 116 - Training Loss: 1.8423078060150146\n",
      "Batch 116 - loss_ce: 0.029130859300494194\n",
      "Batch 116 - loss_bbox: 0.01767505146563053\n",
      "Batch 116 - loss_giou: 0.38041093945503235\n",
      "Batch 116 - cardinality_error: 23.0\n",
      "Batch 116 - gcn_loss: 0.9639798402786255\n",
      "Batch 117 - Training Loss: 2.207357883453369\n",
      "Batch 117 - loss_ce: 0.10815717279911041\n",
      "Batch 117 - loss_bbox: 0.052536673843860626\n",
      "Batch 117 - loss_giou: 0.4550994038581848\n",
      "Batch 117 - cardinality_error: 30.25\n",
      "Batch 117 - gcn_loss: 0.9263186454772949\n",
      "Batch 118 - Training Loss: 1.6298795938491821\n",
      "Batch 118 - loss_ce: 0.04733273386955261\n",
      "Batch 118 - loss_bbox: 0.01688271015882492\n",
      "Batch 118 - loss_giou: 0.295916885137558\n",
      "Batch 118 - cardinality_error: 71.75\n",
      "Batch 118 - gcn_loss: 0.9062995314598083\n",
      "Batch 119 - Training Loss: 2.171020030975342\n",
      "Batch 119 - loss_ce: 0.18812191486358643\n",
      "Batch 119 - loss_bbox: 0.042445454746484756\n",
      "Batch 119 - loss_giou: 0.40445002913475037\n",
      "Batch 119 - cardinality_error: 32.75\n",
      "Batch 119 - gcn_loss: 0.9617708325386047\n",
      "Batch 120 - Training Loss: 1.5759937763214111\n",
      "Batch 120 - loss_ce: 0.06541511416435242\n",
      "Batch 120 - loss_bbox: 0.0188303142786026\n",
      "Batch 120 - loss_giou: 0.28499501943588257\n",
      "Batch 120 - cardinality_error: 71.0\n",
      "Batch 120 - gcn_loss: 0.8464370965957642\n",
      "Batch 121 - Training Loss: 2.233436107635498\n",
      "Batch 121 - loss_ce: 0.13695961236953735\n",
      "Batch 121 - loss_bbox: 0.057100534439086914\n",
      "Batch 121 - loss_giou: 0.42532673478126526\n",
      "Batch 121 - cardinality_error: 21.5\n",
      "Batch 121 - gcn_loss: 0.9603204131126404\n",
      "Batch 122 - Training Loss: 1.6531095504760742\n",
      "Batch 122 - loss_ce: 0.06844732910394669\n",
      "Batch 122 - loss_bbox: 0.020444560796022415\n",
      "Batch 122 - loss_giou: 0.31293025612831116\n",
      "Batch 122 - cardinality_error: 81.5\n",
      "Batch 122 - gcn_loss: 0.8565788865089417\n",
      "Batch 123 - Training Loss: 2.0432181358337402\n",
      "Batch 123 - loss_ce: 0.05710459128022194\n",
      "Batch 123 - loss_bbox: 0.045744482427835464\n",
      "Batch 123 - loss_giou: 0.4162251055240631\n",
      "Batch 123 - cardinality_error: 31.25\n",
      "Batch 123 - gcn_loss: 0.924940824508667\n",
      "Batch 124 - Training Loss: 2.1567940711975098\n",
      "Batch 124 - loss_ce: 0.06982620805501938\n",
      "Batch 124 - loss_bbox: 0.04028681665658951\n",
      "Batch 124 - loss_giou: 0.4006737470626831\n",
      "Batch 124 - cardinality_error: 19.0\n",
      "Batch 124 - gcn_loss: 1.0841864347457886\n",
      "Batch 125 - Training Loss: 2.01641845703125\n",
      "Batch 125 - loss_ce: 0.2644435465335846\n",
      "Batch 125 - loss_bbox: 0.03204381465911865\n",
      "Batch 125 - loss_giou: 0.3451336920261383\n",
      "Batch 125 - cardinality_error: 42.75\n",
      "Batch 125 - gcn_loss: 0.9014885425567627\n",
      "Batch 126 - Training Loss: 1.6350363492965698\n",
      "Batch 126 - loss_ce: 0.07927174121141434\n",
      "Batch 126 - loss_bbox: 0.017937740311026573\n",
      "Batch 126 - loss_giou: 0.22070825099945068\n",
      "Batch 126 - cardinality_error: 100.5\n",
      "Batch 126 - gcn_loss: 1.0246593952178955\n",
      "Batch 127 - Training Loss: 2.3005752563476562\n",
      "Batch 127 - loss_ce: 0.09494683146476746\n",
      "Batch 127 - loss_bbox: 0.05175269767642021\n",
      "Batch 127 - loss_giou: 0.47531649470329285\n",
      "Batch 127 - cardinality_error: 18.25\n",
      "Batch 127 - gcn_loss: 0.9962318539619446\n",
      "Batch 128 - Training Loss: 1.8716635704040527\n",
      "Batch 128 - loss_ce: 0.027028270065784454\n",
      "Batch 128 - loss_bbox: 0.042483434081077576\n",
      "Batch 128 - loss_giou: 0.4146360754966736\n",
      "Batch 128 - cardinality_error: 41.5\n",
      "Batch 128 - gcn_loss: 0.8029459714889526\n",
      "Batch 129 - Training Loss: 1.7353872060775757\n",
      "Batch 129 - loss_ce: 0.05543075501918793\n",
      "Batch 129 - loss_bbox: 0.02428901195526123\n",
      "Batch 129 - loss_giou: 0.32878777384757996\n",
      "Batch 129 - cardinality_error: 43.5\n",
      "Batch 129 - gcn_loss: 0.9009358286857605\n",
      "Batch 130 - Training Loss: 1.807817816734314\n",
      "Batch 130 - loss_ce: 0.21142393350601196\n",
      "Batch 130 - loss_bbox: 0.025147221982479095\n",
      "Batch 130 - loss_giou: 0.28559044003486633\n",
      "Batch 130 - cardinality_error: 25.25\n",
      "Batch 130 - gcn_loss: 0.8994768857955933\n",
      "Batch 131 - Training Loss: 2.185634136199951\n",
      "Batch 131 - loss_ce: 0.11198847740888596\n",
      "Batch 131 - loss_bbox: 0.038390062749385834\n",
      "Batch 131 - loss_giou: 0.4730317294597626\n",
      "Batch 131 - cardinality_error: 27.5\n",
      "Batch 131 - gcn_loss: 0.9356318116188049\n",
      "Batch 132 - Training Loss: 1.575925588607788\n",
      "Batch 132 - loss_ce: 0.06667619943618774\n",
      "Batch 132 - loss_bbox: 0.023594994097948074\n",
      "Batch 132 - loss_giou: 0.2902206778526306\n",
      "Batch 132 - cardinality_error: 72.25\n",
      "Batch 132 - gcn_loss: 0.8108331561088562\n",
      "Batch 133 - Training Loss: 2.547417163848877\n",
      "Batch 133 - loss_ce: 0.17736802995204926\n",
      "Batch 133 - loss_bbox: 0.07857019454240799\n",
      "Batch 133 - loss_giou: 0.5363888144493103\n",
      "Batch 133 - cardinality_error: 21.75\n",
      "Batch 133 - gcn_loss: 0.9044205546379089\n",
      "Batch 134 - Training Loss: 1.8073668479919434\n",
      "Batch 134 - loss_ce: 0.03310832381248474\n",
      "Batch 134 - loss_bbox: 0.02300652302801609\n",
      "Batch 134 - loss_giou: 0.401624858379364\n",
      "Batch 134 - cardinality_error: 40.5\n",
      "Batch 134 - gcn_loss: 0.8559762835502625\n",
      "Batch 135 - Training Loss: 1.6277148723602295\n",
      "Batch 135 - loss_ce: 0.11081049591302872\n",
      "Batch 135 - loss_bbox: 0.014549994841217995\n",
      "Batch 135 - loss_giou: 0.2732159495353699\n",
      "Batch 135 - cardinality_error: 62.75\n",
      "Batch 135 - gcn_loss: 0.8977225422859192\n",
      "Batch 136 - Training Loss: 1.8847856521606445\n",
      "Batch 136 - loss_ce: 0.1691489815711975\n",
      "Batch 136 - loss_bbox: 0.03020990453660488\n",
      "Batch 136 - loss_giou: 0.32640141248703003\n",
      "Batch 136 - cardinality_error: 24.5\n",
      "Batch 136 - gcn_loss: 0.9117843508720398\n",
      "Batch 137 - Training Loss: 1.8698477745056152\n",
      "Batch 137 - loss_ce: 0.09932584315538406\n",
      "Batch 137 - loss_bbox: 0.024152016267180443\n",
      "Batch 137 - loss_giou: 0.38378670811653137\n",
      "Batch 137 - cardinality_error: 31.0\n",
      "Batch 137 - gcn_loss: 0.8821883797645569\n",
      "Batch 138 - Training Loss: 1.8680616617202759\n",
      "Batch 138 - loss_ce: 0.16626888513565063\n",
      "Batch 138 - loss_bbox: 0.029574526473879814\n",
      "Batch 138 - loss_giou: 0.3461568355560303\n",
      "Batch 138 - cardinality_error: 23.0\n",
      "Batch 138 - gcn_loss: 0.8616064786911011\n",
      "Batch 139 - Training Loss: 1.8313746452331543\n",
      "Batch 139 - loss_ce: 0.2146514654159546\n",
      "Batch 139 - loss_bbox: 0.03754739090800285\n",
      "Batch 139 - loss_giou: 0.3033953309059143\n",
      "Batch 139 - cardinality_error: 32.5\n",
      "Batch 139 - gcn_loss: 0.8221954703330994\n",
      "Batch 140 - Training Loss: 1.8697516918182373\n",
      "Batch 140 - loss_ce: 0.18787749111652374\n",
      "Batch 140 - loss_bbox: 0.030687807127833366\n",
      "Batch 140 - loss_giou: 0.3030756413936615\n",
      "Batch 140 - cardinality_error: 26.75\n",
      "Batch 140 - gcn_loss: 0.9222838878631592\n",
      "Batch 141 - Training Loss: 1.8026561737060547\n",
      "Batch 141 - loss_ce: 0.1936575174331665\n",
      "Batch 141 - loss_bbox: 0.026568079367280006\n",
      "Batch 141 - loss_giou: 0.2872373163700104\n",
      "Batch 141 - cardinality_error: 34.5\n",
      "Batch 141 - gcn_loss: 0.9016836285591125\n",
      "Batch 142 - Training Loss: 1.62730073928833\n",
      "Batch 142 - loss_ce: 0.020401770249009132\n",
      "Batch 142 - loss_bbox: 0.028214644640684128\n",
      "Batch 142 - loss_giou: 0.33833837509155273\n",
      "Batch 142 - cardinality_error: 63.0\n",
      "Batch 142 - gcn_loss: 0.7891489267349243\n",
      "Batch 143 - Training Loss: 2.0384883880615234\n",
      "Batch 143 - loss_ce: 0.09554390609264374\n",
      "Batch 143 - loss_bbox: 0.038803521543741226\n",
      "Batch 143 - loss_giou: 0.4673600196838379\n",
      "Batch 143 - cardinality_error: 30.0\n",
      "Batch 143 - gcn_loss: 0.8142067790031433\n",
      "Batch 144 - Training Loss: 1.2988941669464111\n",
      "Batch 144 - loss_ce: 0.024563897401094437\n",
      "Batch 144 - loss_bbox: 0.013207841664552689\n",
      "Batch 144 - loss_giou: 0.24617555737495422\n",
      "Batch 144 - cardinality_error: 115.0\n",
      "Batch 144 - gcn_loss: 0.7159398794174194\n",
      "Batch 145 - Training Loss: 1.4300627708435059\n",
      "Batch 145 - loss_ce: 0.009073453024029732\n",
      "Batch 145 - loss_bbox: 0.01411847397685051\n",
      "Batch 145 - loss_giou: 0.29751908779144287\n",
      "Batch 145 - cardinality_error: 38.75\n",
      "Batch 145 - gcn_loss: 0.7553587555885315\n",
      "Batch 146 - Training Loss: 1.612424612045288\n",
      "Batch 146 - loss_ce: 0.030039768666028976\n",
      "Batch 146 - loss_bbox: 0.02462162636220455\n",
      "Batch 146 - loss_giou: 0.32063397765159607\n",
      "Batch 146 - cardinality_error: 48.75\n",
      "Batch 146 - gcn_loss: 0.8180087208747864\n",
      "Batch 147 - Training Loss: 1.8024702072143555\n",
      "Batch 147 - loss_ce: 0.08817258477210999\n",
      "Batch 147 - loss_bbox: 0.023859888315200806\n",
      "Batch 147 - loss_giou: 0.3652830421924591\n",
      "Batch 147 - cardinality_error: 26.0\n",
      "Batch 147 - gcn_loss: 0.8644320368766785\n",
      "Batch 148 - Training Loss: 1.8962678909301758\n",
      "Batch 148 - loss_ce: 0.09566052258014679\n",
      "Batch 148 - loss_bbox: 0.03313826769590378\n",
      "Batch 148 - loss_giou: 0.4120945632457733\n",
      "Batch 148 - cardinality_error: 27.75\n",
      "Batch 148 - gcn_loss: 0.8107268214225769\n",
      "Batch 149 - Training Loss: 1.8690071105957031\n",
      "Batch 149 - loss_ce: 0.06968104094266891\n",
      "Batch 149 - loss_bbox: 0.05242956802248955\n",
      "Batch 149 - loss_giou: 0.356818825006485\n",
      "Batch 149 - cardinality_error: 27.75\n",
      "Batch 149 - gcn_loss: 0.8235405087471008\n",
      "Batch 150 - Training Loss: 2.0824875831604004\n",
      "Batch 150 - loss_ce: 0.18837517499923706\n",
      "Batch 150 - loss_bbox: 0.03705836832523346\n",
      "Batch 150 - loss_giou: 0.41950538754463196\n",
      "Batch 150 - cardinality_error: 29.0\n",
      "Batch 150 - gcn_loss: 0.8698098063468933\n",
      "Batch 151 - Training Loss: 1.652719259262085\n",
      "Batch 151 - loss_ce: 0.06837201863527298\n",
      "Batch 151 - loss_bbox: 0.02180957794189453\n",
      "Batch 151 - loss_giou: 0.3472020924091339\n",
      "Batch 151 - cardinality_error: 38.0\n",
      "Batch 151 - gcn_loss: 0.7808951735496521\n",
      "Batch 152 - Training Loss: 1.9060988426208496\n",
      "Batch 152 - loss_ce: 0.04302171990275383\n",
      "Batch 152 - loss_bbox: 0.028346339240670204\n",
      "Batch 152 - loss_giou: 0.3834317624568939\n",
      "Batch 152 - cardinality_error: 25.5\n",
      "Batch 152 - gcn_loss: 0.954481840133667\n",
      "Batch 153 - Training Loss: 1.8951897621154785\n",
      "Batch 153 - loss_ce: 0.1601114273071289\n",
      "Batch 153 - loss_bbox: 0.04345191642642021\n",
      "Batch 153 - loss_giou: 0.34827977418899536\n",
      "Batch 153 - cardinality_error: 17.25\n",
      "Batch 153 - gcn_loss: 0.8212592005729675\n",
      "Batch 154 - Training Loss: 2.078484296798706\n",
      "Batch 154 - loss_ce: 0.11480612307786942\n",
      "Batch 154 - loss_bbox: 0.04577661678195\n",
      "Batch 154 - loss_giou: 0.4394356906414032\n",
      "Batch 154 - cardinality_error: 27.25\n",
      "Batch 154 - gcn_loss: 0.8559237122535706\n",
      "Batch 155 - Training Loss: 1.780991554260254\n",
      "Batch 155 - loss_ce: 0.07101073861122131\n",
      "Batch 155 - loss_bbox: 0.028216736391186714\n",
      "Batch 155 - loss_giou: 0.3722824156284332\n",
      "Batch 155 - cardinality_error: 25.25\n",
      "Batch 155 - gcn_loss: 0.8243322968482971\n",
      "Batch 156 - Training Loss: 2.3253304958343506\n",
      "Batch 156 - loss_ce: 0.051113810390233994\n",
      "Batch 156 - loss_bbox: 0.09362831711769104\n",
      "Batch 156 - loss_giou: 0.5332120656967163\n",
      "Batch 156 - cardinality_error: 14.5\n",
      "Batch 156 - gcn_loss: 0.7396509051322937\n",
      "Batch 157 - Training Loss: 2.0532474517822266\n",
      "Batch 157 - loss_ce: 0.0905526652932167\n",
      "Batch 157 - loss_bbox: 0.052453573793172836\n",
      "Batch 157 - loss_giou: 0.45306578278541565\n",
      "Batch 157 - cardinality_error: 13.25\n",
      "Batch 157 - gcn_loss: 0.7942951917648315\n",
      "Batch 158 - Training Loss: 2.2208757400512695\n",
      "Batch 158 - loss_ce: 0.10031455010175705\n",
      "Batch 158 - loss_bbox: 0.06600309908390045\n",
      "Batch 158 - loss_giou: 0.4796053171157837\n",
      "Batch 158 - cardinality_error: 24.5\n",
      "Batch 158 - gcn_loss: 0.8313350081443787\n",
      "Batch 159 - Training Loss: 1.5147525072097778\n",
      "Batch 159 - loss_ce: 0.1943773478269577\n",
      "Batch 159 - loss_bbox: 0.027160050347447395\n",
      "Batch 159 - loss_giou: 0.2274346649646759\n",
      "Batch 159 - cardinality_error: 19.25\n",
      "Batch 159 - gcn_loss: 0.7297055721282959\n",
      "Batch 160 - Training Loss: 2.4664173126220703\n",
      "Batch 160 - loss_ce: 0.1436835676431656\n",
      "Batch 160 - loss_bbox: 0.11564511060714722\n",
      "Batch 160 - loss_giou: 0.4827999770641327\n",
      "Batch 160 - cardinality_error: 25.75\n",
      "Batch 160 - gcn_loss: 0.7789083123207092\n",
      "Batch 161 - Training Loss: 1.7834174633026123\n",
      "Batch 161 - loss_ce: 0.06695152819156647\n",
      "Batch 161 - loss_bbox: 0.02748657390475273\n",
      "Batch 161 - loss_giou: 0.3639753460884094\n",
      "Batch 161 - cardinality_error: 27.5\n",
      "Batch 161 - gcn_loss: 0.8510823249816895\n",
      "Batch 162 - Training Loss: 1.9801942110061646\n",
      "Batch 162 - loss_ce: 0.09726990014314651\n",
      "Batch 162 - loss_bbox: 0.043563637882471085\n",
      "Batch 162 - loss_giou: 0.42898499965667725\n",
      "Batch 162 - cardinality_error: 18.75\n",
      "Batch 162 - gcn_loss: 0.8071361780166626\n",
      "Batch 163 - Training Loss: 2.359602451324463\n",
      "Batch 163 - loss_ce: 0.20818960666656494\n",
      "Batch 163 - loss_bbox: 0.05179998278617859\n",
      "Batch 163 - loss_giou: 0.5018589496612549\n",
      "Batch 163 - cardinality_error: 24.5\n",
      "Batch 163 - gcn_loss: 0.8886948823928833\n",
      "Batch 164 - Training Loss: 1.9680331945419312\n",
      "Batch 164 - loss_ce: 0.14502297341823578\n",
      "Batch 164 - loss_bbox: 0.032813604921102524\n",
      "Batch 164 - loss_giou: 0.42561301589012146\n",
      "Batch 164 - cardinality_error: 40.0\n",
      "Batch 164 - gcn_loss: 0.8077161312103271\n",
      "Batch 165 - Training Loss: 2.004058599472046\n",
      "Batch 165 - loss_ce: 0.18047139048576355\n",
      "Batch 165 - loss_bbox: 0.03737952187657356\n",
      "Batch 165 - loss_giou: 0.3888794183731079\n",
      "Batch 165 - cardinality_error: 21.25\n",
      "Batch 165 - gcn_loss: 0.8589308857917786\n",
      "Batch 166 - Training Loss: 1.5689871311187744\n",
      "Batch 166 - loss_ce: 0.1855177879333496\n",
      "Batch 166 - loss_bbox: 0.01719013787806034\n",
      "Batch 166 - loss_giou: 0.22057676315307617\n",
      "Batch 166 - cardinality_error: 21.5\n",
      "Batch 166 - gcn_loss: 0.8563651442527771\n",
      "Batch 167 - Training Loss: 1.6677247285842896\n",
      "Batch 167 - loss_ce: 0.1433248370885849\n",
      "Batch 167 - loss_bbox: 0.029501542448997498\n",
      "Batch 167 - loss_giou: 0.33282116055488586\n",
      "Batch 167 - cardinality_error: 51.0\n",
      "Batch 167 - gcn_loss: 0.711249828338623\n",
      "Batch 168 - Training Loss: 1.7203971147537231\n",
      "Batch 168 - loss_ce: 0.08600625395774841\n",
      "Batch 168 - loss_bbox: 0.03769794851541519\n",
      "Batch 168 - loss_giou: 0.38900312781333923\n",
      "Batch 168 - cardinality_error: 55.25\n",
      "Batch 168 - gcn_loss: 0.6678948402404785\n",
      "Batch 169 - Training Loss: 1.739656925201416\n",
      "Batch 169 - loss_ce: 0.05303831771016121\n",
      "Batch 169 - loss_bbox: 0.04322870820760727\n",
      "Batch 169 - loss_giou: 0.3949037194252014\n",
      "Batch 169 - cardinality_error: 34.0\n",
      "Batch 169 - gcn_loss: 0.6806676387786865\n",
      "Batch 170 - Training Loss: 1.8394927978515625\n",
      "Batch 170 - loss_ce: 0.08599142730236053\n",
      "Batch 170 - loss_bbox: 0.03726890683174133\n",
      "Batch 170 - loss_giou: 0.3714093565940857\n",
      "Batch 170 - cardinality_error: 25.5\n",
      "Batch 170 - gcn_loss: 0.8243381977081299\n",
      "Batch 171 - Training Loss: 1.7529464960098267\n",
      "Batch 171 - loss_ce: 0.15337622165679932\n",
      "Batch 171 - loss_bbox: 0.02666756696999073\n",
      "Batch 171 - loss_giou: 0.33922338485717773\n",
      "Batch 171 - cardinality_error: 26.5\n",
      "Batch 171 - gcn_loss: 0.7877856492996216\n",
      "Batch 172 - Training Loss: 1.9020795822143555\n",
      "Batch 172 - loss_ce: 0.17278020083904266\n",
      "Batch 172 - loss_bbox: 0.03458132594823837\n",
      "Batch 172 - loss_giou: 0.39000973105430603\n",
      "Batch 172 - cardinality_error: 23.75\n",
      "Batch 172 - gcn_loss: 0.7763732075691223\n",
      "Batch 173 - Training Loss: 1.9344310760498047\n",
      "Batch 173 - loss_ce: 0.20222526788711548\n",
      "Batch 173 - loss_bbox: 0.03283350542187691\n",
      "Batch 173 - loss_giou: 0.402252733707428\n",
      "Batch 173 - cardinality_error: 29.0\n",
      "Batch 173 - gcn_loss: 0.7635328769683838\n",
      "Batch 174 - Training Loss: 1.471808910369873\n",
      "Batch 174 - loss_ce: 0.06436331570148468\n",
      "Batch 174 - loss_bbox: 0.019949156790971756\n",
      "Batch 174 - loss_giou: 0.2939158082008362\n",
      "Batch 174 - cardinality_error: 59.75\n",
      "Batch 174 - gcn_loss: 0.7198681831359863\n",
      "Batch 175 - Training Loss: 1.5858656167984009\n",
      "Batch 175 - loss_ce: 0.10097282379865646\n",
      "Batch 175 - loss_bbox: 0.019979840144515038\n",
      "Batch 175 - loss_giou: 0.27929428219795227\n",
      "Batch 175 - cardinality_error: 42.25\n",
      "Batch 175 - gcn_loss: 0.8264050483703613\n",
      "Batch 176 - Training Loss: 1.9355027675628662\n",
      "Batch 176 - loss_ce: 0.09160981327295303\n",
      "Batch 176 - loss_bbox: 0.0411803163588047\n",
      "Batch 176 - loss_giou: 0.4078325927257538\n",
      "Batch 176 - cardinality_error: 12.0\n",
      "Batch 176 - gcn_loss: 0.8223262429237366\n",
      "Batch 177 - Training Loss: 1.9528136253356934\n",
      "Batch 177 - loss_ce: 0.1450420320034027\n",
      "Batch 177 - loss_bbox: 0.03927008435130119\n",
      "Batch 177 - loss_giou: 0.41859638690948486\n",
      "Batch 177 - cardinality_error: 28.75\n",
      "Batch 177 - gcn_loss: 0.7742283940315247\n",
      "Batch 178 - Training Loss: 2.149563789367676\n",
      "Batch 178 - loss_ce: 0.10598605126142502\n",
      "Batch 178 - loss_bbox: 0.04530639201402664\n",
      "Batch 178 - loss_giou: 0.5200307369232178\n",
      "Batch 178 - cardinality_error: 22.25\n",
      "Batch 178 - gcn_loss: 0.7769842147827148\n",
      "Batch 179 - Training Loss: 2.3939197063446045\n",
      "Batch 179 - loss_ce: 0.10513349622488022\n",
      "Batch 179 - loss_bbox: 0.08603490144014359\n",
      "Batch 179 - loss_giou: 0.5493412017822266\n",
      "Batch 179 - cardinality_error: 24.0\n",
      "Batch 179 - gcn_loss: 0.7599292397499084\n",
      "Batch 180 - Training Loss: 1.89359450340271\n",
      "Batch 180 - loss_ce: 0.19898660480976105\n",
      "Batch 180 - loss_bbox: 0.04242841526865959\n",
      "Batch 180 - loss_giou: 0.40243908762931824\n",
      "Batch 180 - cardinality_error: 24.75\n",
      "Batch 180 - gcn_loss: 0.6775875687599182\n",
      "Batch 181 - Training Loss: 2.082857131958008\n",
      "Batch 181 - loss_ce: 0.08092573285102844\n",
      "Batch 181 - loss_bbox: 0.054598119109869\n",
      "Batch 181 - loss_giou: 0.48197582364082336\n",
      "Batch 181 - cardinality_error: 18.75\n",
      "Batch 181 - gcn_loss: 0.7649890780448914\n",
      "Batch 182 - Training Loss: 1.4027221202850342\n",
      "Batch 182 - loss_ce: 0.03629568964242935\n",
      "Batch 182 - loss_bbox: 0.027130497619509697\n",
      "Batch 182 - loss_giou: 0.3106490969657898\n",
      "Batch 182 - cardinality_error: 94.5\n",
      "Batch 182 - gcn_loss: 0.6094757318496704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tangy\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
