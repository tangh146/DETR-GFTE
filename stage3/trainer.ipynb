{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNLightning(\n",
       "  (gnet): GraphNetwork(\n",
       "    (conv1): GCNConv(256, 128)\n",
       "    (conv2): GCNConv(128, 128)\n",
       "    (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (lin_final): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model import GNLightning\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = GNLightning(\n",
    "    d_model=128,\n",
    "    lr=1e-3,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    train_path=r'path to the output of running gcn2stage3 on the output of ptn2gcn with split=train',\n",
    "    val_path=r'path to the output of running gcn2stage3 on the output of ptn2gcn with split=val')\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# logger = WandbLogger(project='parallel_tables', name='stage3_convcount2hiddim128')\n",
    "\n",
    "# Set up checkpointing and trainer\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation_loss\",\n",
    "    filename=\"detr-{epoch:02d}-{validation_loss:.2f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    "    dirpath=r'..\\checkpoints'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    log_every_n_steps=5,\n",
    "    # logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    val_check_interval=0.3,  # Run validation 2 times per epoch\n",
    "    devices=1,\n",
    "    accelerator=\"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type         | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | gnet      | GraphNetwork | 82.7 K | train\n",
      "1 | criterion | NLLLoss      | 0      | train\n",
      "---------------------------------------------------\n",
      "82.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "82.7 K    Total params\n",
      "0.331     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b618edfda0fe4a579ec26a2d47199bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccfd014277640fda2dba4ce4896cbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 - loss: 1.065484881401062\n",
      "Batch 1 - loss: 0.926393985748291\n",
      "Batch 2 - loss: 0.8399792909622192\n",
      "Batch 3 - loss: 0.7894802689552307\n",
      "Batch 4 - loss: 0.8228007555007935\n",
      "Batch 5 - loss: 0.7994129061698914\n",
      "Batch 6 - loss: 0.7941599488258362\n",
      "Batch 7 - loss: 0.7265436053276062\n",
      "Batch 8 - loss: 0.761640191078186\n",
      "Batch 9 - loss: 0.7577390074729919\n",
      "Batch 10 - loss: 0.7718204259872437\n",
      "Batch 11 - loss: 0.7746196985244751\n",
      "Batch 12 - loss: 0.7634571194648743\n",
      "Batch 13 - loss: 0.757892906665802\n",
      "Batch 14 - loss: 0.7596964240074158\n",
      "Batch 15 - loss: 0.7248194217681885\n",
      "Batch 16 - loss: 0.7430897951126099\n",
      "Batch 17 - loss: 0.76212477684021\n",
      "Batch 18 - loss: 0.7553330659866333\n",
      "Batch 19 - loss: 0.8066062927246094\n",
      "Batch 20 - loss: 0.7236633896827698\n",
      "Batch 21 - loss: 0.7568620443344116\n",
      "Batch 22 - loss: 0.7608654499053955\n",
      "Batch 23 - loss: 0.7570408582687378\n",
      "Batch 24 - loss: 0.7136027812957764\n",
      "Batch 25 - loss: 0.7650535106658936\n",
      "Batch 26 - loss: 0.7313839197158813\n",
      "Batch 27 - loss: 0.7494292855262756\n",
      "Batch 28 - loss: 0.7288106083869934\n",
      "Batch 29 - loss: 0.7658644318580627\n",
      "Batch 30 - loss: 0.7524856328964233\n",
      "Batch 31 - loss: 0.738821804523468\n",
      "Batch 32 - loss: 0.7674314975738525\n",
      "Batch 33 - loss: 0.7364054918289185\n",
      "Batch 34 - loss: 0.741759717464447\n",
      "Batch 35 - loss: 0.7511734366416931\n",
      "Batch 36 - loss: 0.7692511081695557\n",
      "Batch 37 - loss: 0.726135790348053\n",
      "Batch 38 - loss: 0.7253000736236572\n",
      "Batch 39 - loss: 0.7328947186470032\n",
      "Batch 40 - loss: 0.7478499412536621\n",
      "Batch 41 - loss: 0.7149842977523804\n",
      "Batch 42 - loss: 0.722571074962616\n",
      "Batch 43 - loss: 0.7316840887069702\n",
      "Batch 44 - loss: 0.7150707840919495\n",
      "Batch 45 - loss: 0.7543365955352783\n",
      "Batch 46 - loss: 0.7205604910850525\n",
      "Batch 47 - loss: 0.7331217527389526\n",
      "Batch 48 - loss: 0.748197615146637\n",
      "Batch 49 - loss: 0.7114090919494629\n",
      "Batch 50 - loss: 0.7404487729072571\n",
      "Batch 51 - loss: 0.7178891897201538\n",
      "Batch 52 - loss: 0.7427839040756226\n",
      "Batch 53 - loss: 0.7318752408027649\n",
      "Batch 54 - loss: 0.7751083374023438\n",
      "Batch 55 - loss: 0.7586484551429749\n",
      "Batch 56 - loss: 0.734879732131958\n",
      "Batch 57 - loss: 0.7357128262519836\n",
      "Batch 58 - loss: 0.7653570771217346\n",
      "Batch 59 - loss: 0.7462574243545532\n",
      "Batch 60 - loss: 0.7331531047821045\n",
      "Batch 61 - loss: 0.7209972739219666\n",
      "Batch 62 - loss: 0.7540658712387085\n",
      "Batch 63 - loss: 0.7358208894729614\n",
      "Batch 64 - loss: 0.71905517578125\n",
      "Batch 65 - loss: 0.7337480187416077\n",
      "Batch 66 - loss: 0.7620139122009277\n",
      "Batch 67 - loss: 0.7349881529808044\n",
      "Batch 68 - loss: 0.6870927214622498\n",
      "Batch 69 - loss: 0.7811538577079773\n",
      "Batch 70 - loss: 0.7202620506286621\n",
      "Batch 71 - loss: 0.7248460650444031\n",
      "Batch 72 - loss: 0.748362123966217\n",
      "Batch 73 - loss: 0.730851948261261\n",
      "Batch 74 - loss: 0.7438687086105347\n",
      "Batch 75 - loss: 0.7204216122627258\n",
      "Batch 76 - loss: 0.7662351727485657\n",
      "Batch 77 - loss: 0.7345846891403198\n",
      "Batch 78 - loss: 0.7476181387901306\n",
      "Batch 79 - loss: 0.7821173667907715\n",
      "Batch 80 - loss: 0.7737091183662415\n",
      "Batch 81 - loss: 0.731964647769928\n",
      "Batch 82 - loss: 0.7262253761291504\n",
      "Batch 83 - loss: 0.7385630011558533\n",
      "Batch 84 - loss: 0.73598313331604\n",
      "Batch 85 - loss: 0.6969667077064514\n",
      "Batch 86 - loss: 0.7485024929046631\n",
      "Batch 87 - loss: 0.7359533905982971\n",
      "Batch 88 - loss: 0.7122049331665039\n",
      "Batch 89 - loss: 0.7513248920440674\n",
      "Batch 90 - loss: 0.7193285226821899\n",
      "Batch 91 - loss: 0.7181015014648438\n",
      "Batch 92 - loss: 0.738142728805542\n",
      "Batch 93 - loss: 0.7452507019042969\n",
      "Batch 94 - loss: 0.7693468332290649\n",
      "Batch 95 - loss: 0.7079022526741028\n",
      "Batch 96 - loss: 0.7135927081108093\n",
      "Batch 97 - loss: 0.699157178401947\n",
      "Batch 98 - loss: 0.722127377986908\n",
      "Batch 99 - loss: 0.7349526882171631\n",
      "Batch 100 - loss: 0.7361053824424744\n",
      "Batch 101 - loss: 0.7238686084747314\n",
      "Batch 102 - loss: 0.7212615609169006\n",
      "Batch 103 - loss: 0.7213435173034668\n",
      "Batch 104 - loss: 0.7218627333641052\n",
      "Batch 105 - loss: 0.7478090524673462\n",
      "Batch 106 - loss: 0.7472034096717834\n",
      "Batch 107 - loss: 0.761613130569458\n",
      "Batch 108 - loss: 0.7308816313743591\n",
      "Batch 109 - loss: 0.7393940091133118\n",
      "Batch 110 - loss: 0.7782703042030334\n",
      "Batch 111 - loss: 0.7516611814498901\n",
      "Batch 112 - loss: 0.7246784567832947\n",
      "Batch 113 - loss: 0.7233087420463562\n",
      "Batch 114 - loss: 0.7190731763839722\n",
      "Batch 115 - loss: 0.7118968963623047\n",
      "Batch 116 - loss: 0.7172182202339172\n",
      "Batch 117 - loss: 0.7390777468681335\n",
      "Batch 118 - loss: 0.7147701978683472\n",
      "Batch 119 - loss: 0.7491047382354736\n",
      "Batch 120 - loss: 0.7080397009849548\n",
      "Batch 121 - loss: 0.7206792831420898\n",
      "Batch 122 - loss: 0.7395350337028503\n",
      "Batch 123 - loss: 0.706924319267273\n",
      "Batch 124 - loss: 0.7338684797286987\n",
      "Batch 125 - loss: 0.7404136657714844\n",
      "Batch 126 - loss: 0.7589637041091919\n",
      "Batch 127 - loss: 0.7497349977493286\n",
      "Batch 128 - loss: 0.7196087837219238\n",
      "Batch 129 - loss: 0.7416175007820129\n",
      "Batch 130 - loss: 0.739021360874176\n",
      "Batch 131 - loss: 0.7840980291366577\n",
      "Batch 132 - loss: 0.7640736103057861\n",
      "Batch 133 - loss: 0.747440755367279\n",
      "Batch 134 - loss: 0.7435079216957092\n",
      "Batch 135 - loss: 0.7365466356277466\n",
      "Batch 136 - loss: 0.7322487831115723\n",
      "Batch 137 - loss: 0.7600534558296204\n",
      "Batch 138 - loss: 0.7356154322624207\n",
      "Batch 139 - loss: 0.7229251265525818\n",
      "Batch 140 - loss: 0.7788249850273132\n",
      "Batch 141 - loss: 0.7247185111045837\n",
      "Batch 142 - loss: 0.6940017342567444\n",
      "Batch 143 - loss: 0.7518545985221863\n",
      "Batch 144 - loss: 0.721569299697876\n",
      "Batch 145 - loss: 0.765907347202301\n",
      "Batch 146 - loss: 0.7397955060005188\n",
      "Batch 147 - loss: 0.7078009843826294\n",
      "Batch 148 - loss: 0.7075468897819519\n",
      "Batch 149 - loss: 0.7523614764213562\n",
      "Batch 150 - loss: 0.7401657700538635\n",
      "Batch 151 - loss: 0.7220075726509094\n",
      "Batch 152 - loss: 0.734685480594635\n",
      "Batch 153 - loss: 0.7525188326835632\n",
      "Batch 154 - loss: 0.752871572971344\n",
      "Batch 155 - loss: 0.7441866397857666\n",
      "Batch 156 - loss: 0.7294087409973145\n",
      "Batch 157 - loss: 0.7113677263259888\n",
      "Batch 158 - loss: 0.7263365387916565\n",
      "Batch 159 - loss: 0.7672949433326721\n",
      "Batch 160 - loss: 0.7253699898719788\n",
      "Batch 161 - loss: 0.7263052463531494\n",
      "Batch 162 - loss: 0.7319737672805786\n",
      "Batch 163 - loss: 0.718396782875061\n",
      "Batch 164 - loss: 0.7459095120429993\n",
      "Batch 165 - loss: 0.7135036587715149\n",
      "Batch 166 - loss: 0.769737720489502\n",
      "Batch 167 - loss: 0.7732021808624268\n",
      "Batch 168 - loss: 0.7414805293083191\n",
      "Batch 169 - loss: 0.7583546042442322\n",
      "Batch 170 - loss: 0.7397089600563049\n",
      "Batch 171 - loss: 0.7321751713752747\n",
      "Batch 172 - loss: 0.7426275014877319\n",
      "Batch 173 - loss: 0.7598775625228882\n",
      "Batch 174 - loss: 0.7277971506118774\n",
      "Batch 175 - loss: 0.7331299781799316\n",
      "Batch 176 - loss: 0.7421403527259827\n",
      "Batch 177 - loss: 0.738470733165741\n",
      "Batch 178 - loss: 0.7178242206573486\n",
      "Batch 179 - loss: 0.7255023121833801\n",
      "Batch 180 - loss: 0.7257660031318665\n",
      "Batch 181 - loss: 0.729006826877594\n",
      "Batch 182 - loss: 0.726563036441803\n",
      "Batch 183 - loss: 0.7472112774848938\n",
      "Batch 184 - loss: 0.7217625379562378\n",
      "Batch 185 - loss: 0.7334809899330139\n",
      "Batch 186 - loss: 0.7541682720184326\n",
      "Batch 187 - loss: 0.7253677248954773\n",
      "Batch 188 - loss: 0.7447454929351807\n",
      "Batch 189 - loss: 0.6947274804115295\n",
      "Batch 190 - loss: 0.7468514442443848\n",
      "Batch 191 - loss: 0.7362339496612549\n",
      "Batch 192 - loss: 0.7316160202026367\n",
      "Batch 193 - loss: 0.7246739864349365\n",
      "Batch 194 - loss: 0.7952938079833984\n",
      "Batch 195 - loss: 0.7033775448799133\n",
      "Batch 196 - loss: 0.7453882098197937\n",
      "Batch 197 - loss: 0.7442817091941833\n",
      "Batch 198 - loss: 0.7105004787445068\n",
      "Batch 199 - loss: 0.7329875826835632\n",
      "Batch 200 - loss: 0.7525838017463684\n",
      "Batch 201 - loss: 0.7248934507369995\n",
      "Batch 202 - loss: 0.7496361136436462\n",
      "Batch 203 - loss: 0.7543272376060486\n",
      "Batch 204 - loss: 0.7154341340065002\n",
      "Batch 205 - loss: 0.7518650889396667\n",
      "Batch 206 - loss: 0.7460735440254211\n",
      "Batch 207 - loss: 0.7441121339797974\n",
      "Batch 208 - loss: 0.7394972443580627\n",
      "Batch 209 - loss: 0.7459226846694946\n",
      "Batch 210 - loss: 0.7376525402069092\n",
      "Batch 211 - loss: 0.7513240575790405\n",
      "Batch 212 - loss: 0.6983593702316284\n",
      "Batch 213 - loss: 0.738623321056366\n",
      "Batch 214 - loss: 0.7486904263496399\n",
      "Batch 215 - loss: 0.7301574349403381\n",
      "Batch 216 - loss: 0.7758359313011169\n",
      "Batch 217 - loss: 0.7390080094337463\n",
      "Batch 218 - loss: 0.7310718894004822\n",
      "Batch 219 - loss: 0.7193784713745117\n",
      "Batch 220 - loss: 0.7144220471382141\n",
      "Batch 221 - loss: 0.718128502368927\n",
      "Batch 222 - loss: 0.7490893006324768\n",
      "Batch 223 - loss: 0.7467079758644104\n",
      "Batch 224 - loss: 0.7284023761749268\n",
      "Batch 225 - loss: 0.7312795519828796\n",
      "Batch 226 - loss: 0.7782992720603943\n",
      "Batch 227 - loss: 0.713351845741272\n",
      "Batch 228 - loss: 0.7464261651039124\n",
      "Batch 229 - loss: 0.7593174576759338\n",
      "Batch 230 - loss: 0.7238296866416931\n",
      "Batch 231 - loss: 0.7465072870254517\n",
      "Batch 232 - loss: 0.7446143627166748\n",
      "Batch 233 - loss: 0.6874412298202515\n",
      "Batch 234 - loss: 0.7718203067779541\n",
      "Batch 235 - loss: 0.7452542185783386\n",
      "Batch 236 - loss: 0.7377105355262756\n",
      "Batch 237 - loss: 0.7587862014770508\n",
      "Batch 238 - loss: 0.7496011853218079\n",
      "Batch 239 - loss: 0.7450936436653137\n",
      "Batch 240 - loss: 0.7102755904197693\n",
      "Batch 241 - loss: 0.7461881637573242\n",
      "Batch 242 - loss: 0.744003415107727\n",
      "Batch 243 - loss: 0.7329961657524109\n",
      "Batch 244 - loss: 0.7241055965423584\n",
      "Batch 245 - loss: 0.7246189117431641\n",
      "Batch 246 - loss: 0.7158102989196777\n",
      "Batch 247 - loss: 0.7255483269691467\n",
      "Batch 248 - loss: 0.7333396077156067\n",
      "Batch 249 - loss: 0.7345446944236755\n",
      "Batch 250 - loss: 0.7074847221374512\n",
      "Batch 251 - loss: 0.7820305824279785\n",
      "Batch 252 - loss: 0.7067608833312988\n",
      "Batch 253 - loss: 0.744978666305542\n",
      "Batch 254 - loss: 0.7173243165016174\n",
      "Batch 255 - loss: 0.6849489212036133\n",
      "Batch 256 - loss: 0.7621178030967712\n",
      "Batch 257 - loss: 0.750542402267456\n",
      "Batch 258 - loss: 0.7157106995582581\n",
      "Batch 259 - loss: 0.7517462968826294\n",
      "Batch 260 - loss: 0.7201800346374512\n",
      "Batch 261 - loss: 0.7226101756095886\n",
      "Batch 262 - loss: 0.734312891960144\n",
      "Batch 263 - loss: 0.7421571016311646\n",
      "Batch 264 - loss: 0.7198824286460876\n",
      "Batch 265 - loss: 0.7265177369117737\n",
      "Batch 266 - loss: 0.7786636352539062\n",
      "Batch 267 - loss: 0.7361263036727905\n",
      "Batch 268 - loss: 0.6962251663208008\n",
      "Batch 269 - loss: 0.7333557605743408\n",
      "Batch 270 - loss: 0.7261245846748352\n",
      "Batch 271 - loss: 0.7422863245010376\n",
      "Batch 272 - loss: 0.7539917826652527\n",
      "Batch 273 - loss: 0.7686887383460999\n",
      "Batch 274 - loss: 0.7019662261009216\n",
      "Batch 275 - loss: 0.714123010635376\n",
      "Batch 276 - loss: 0.7239115834236145\n",
      "Batch 277 - loss: 0.7253941297531128\n",
      "Batch 278 - loss: 0.718929648399353\n",
      "Batch 279 - loss: 0.7356095910072327\n",
      "Batch 280 - loss: 0.7187137007713318\n",
      "Batch 281 - loss: 0.7150740027427673\n",
      "Batch 282 - loss: 0.7136049866676331\n",
      "Batch 283 - loss: 0.7000449299812317\n",
      "Batch 284 - loss: 0.7388960719108582\n",
      "Batch 285 - loss: 0.7097892165184021\n",
      "Batch 286 - loss: 0.7680468559265137\n",
      "Batch 287 - loss: 0.7558135986328125\n",
      "Batch 288 - loss: 0.7367792725563049\n",
      "Batch 289 - loss: 0.7223809957504272\n",
      "Batch 290 - loss: 0.734666109085083\n",
      "Batch 291 - loss: 0.7076386213302612\n",
      "Batch 292 - loss: 0.731075644493103\n",
      "Batch 293 - loss: 0.7432780265808105\n",
      "Batch 294 - loss: 0.7174403667449951\n",
      "Batch 295 - loss: 0.7529398798942566\n",
      "Batch 296 - loss: 0.7395971417427063\n",
      "Batch 297 - loss: 0.7162050604820251\n",
      "Batch 298 - loss: 0.731564462184906\n",
      "Batch 299 - loss: 0.692807674407959\n",
      "Batch 300 - loss: 0.7394485473632812\n",
      "Batch 301 - loss: 0.7071948051452637\n",
      "Batch 302 - loss: 0.7100746631622314\n",
      "Batch 303 - loss: 0.741942286491394\n",
      "Batch 304 - loss: 0.6939014196395874\n",
      "Batch 305 - loss: 0.718040406703949\n",
      "Batch 306 - loss: 0.710030734539032\n",
      "Batch 307 - loss: 0.7234396934509277\n",
      "Batch 308 - loss: 0.7306256294250488\n",
      "Batch 309 - loss: 0.7229093313217163\n",
      "Batch 310 - loss: 0.7492634654045105\n",
      "Batch 311 - loss: 0.7328680753707886\n",
      "Batch 312 - loss: 0.7257042527198792\n",
      "Batch 313 - loss: 0.6814971566200256\n",
      "Batch 314 - loss: 0.706200897693634\n",
      "Batch 315 - loss: 0.6962293386459351\n",
      "Batch 316 - loss: 0.6977733969688416\n",
      "Batch 317 - loss: 0.6809347867965698\n",
      "Batch 318 - loss: 0.7048811316490173\n",
      "Batch 319 - loss: 0.7211716175079346\n",
      "Batch 320 - loss: 0.670166015625\n",
      "Batch 321 - loss: 0.6904158592224121\n",
      "Batch 322 - loss: 0.7051567435264587\n",
      "Batch 323 - loss: 0.6782181859016418\n",
      "Batch 324 - loss: 0.7127640843391418\n",
      "Batch 325 - loss: 0.7238548994064331\n",
      "Batch 326 - loss: 0.6836464405059814\n",
      "Batch 327 - loss: 0.674695611000061\n",
      "Batch 328 - loss: 0.6963474750518799\n",
      "Batch 329 - loss: 0.6836882829666138\n",
      "Batch 330 - loss: 0.7321882247924805\n",
      "Batch 331 - loss: 0.6635993123054504\n",
      "Batch 332 - loss: 0.6933608055114746\n",
      "Batch 333 - loss: 0.6693227887153625\n",
      "Batch 334 - loss: 0.6760131120681763\n",
      "Batch 335 - loss: 0.7057083249092102\n",
      "Batch 336 - loss: 0.6850472092628479\n",
      "Batch 337 - loss: 0.6726052165031433\n",
      "Batch 338 - loss: 0.6724153161048889\n",
      "Batch 339 - loss: 0.6681994199752808\n",
      "Batch 340 - loss: 0.7050334811210632\n",
      "Batch 341 - loss: 0.6716791391372681\n",
      "Batch 342 - loss: 0.681352972984314\n",
      "Batch 343 - loss: 0.6859749555587769\n",
      "Batch 344 - loss: 0.6821481585502625\n",
      "Batch 345 - loss: 0.6435912251472473\n",
      "Batch 346 - loss: 0.6461309790611267\n",
      "Batch 347 - loss: 0.6763675212860107\n",
      "Batch 348 - loss: 0.7102542519569397\n",
      "Batch 349 - loss: 0.6972899436950684\n",
      "Batch 350 - loss: 0.663377046585083\n",
      "Batch 351 - loss: 0.69874107837677\n",
      "Batch 352 - loss: 0.6703730821609497\n",
      "Batch 353 - loss: 0.6694052815437317\n",
      "Batch 354 - loss: 0.6541563272476196\n",
      "Batch 355 - loss: 0.7424737811088562\n",
      "Batch 356 - loss: 0.6737112402915955\n",
      "Batch 357 - loss: 0.6730545163154602\n",
      "Batch 358 - loss: 0.7170392870903015\n",
      "Batch 359 - loss: 0.7074344158172607\n",
      "Batch 360 - loss: 0.6560176610946655\n",
      "Batch 361 - loss: 0.6678817868232727\n",
      "Batch 362 - loss: 0.6913330554962158\n",
      "Batch 363 - loss: 0.6937307119369507\n",
      "Batch 364 - loss: 0.7029961347579956\n",
      "Batch 365 - loss: 0.6816914081573486\n",
      "Batch 366 - loss: 0.6639553308486938\n",
      "Batch 367 - loss: 0.6560724973678589\n",
      "Batch 368 - loss: 0.6621398329734802\n",
      "Batch 369 - loss: 0.689844012260437\n",
      "Batch 370 - loss: 0.7295921444892883\n",
      "Batch 371 - loss: 0.6842448711395264\n",
      "Batch 372 - loss: 0.6789348125457764\n",
      "Batch 373 - loss: 0.6740655899047852\n",
      "Batch 374 - loss: 0.72893887758255\n",
      "Batch 375 - loss: 0.6479194164276123\n",
      "Batch 376 - loss: 0.6678007245063782\n",
      "Batch 377 - loss: 0.7046346068382263\n",
      "Batch 378 - loss: 0.6559699773788452\n",
      "Batch 379 - loss: 0.6685824394226074\n",
      "Batch 380 - loss: 0.6663967967033386\n",
      "Batch 381 - loss: 0.6849572062492371\n",
      "Batch 382 - loss: 0.6711314916610718\n",
      "Batch 383 - loss: 0.6797577142715454\n",
      "Batch 384 - loss: 0.6854328513145447\n",
      "Batch 385 - loss: 0.6563706994056702\n",
      "Batch 386 - loss: 0.6527789235115051\n",
      "Batch 387 - loss: 0.696067214012146\n",
      "Batch 388 - loss: 0.6471964716911316\n",
      "Batch 389 - loss: 0.643804132938385\n",
      "Batch 390 - loss: 0.6657379865646362\n",
      "Batch 391 - loss: 0.6944473385810852\n",
      "Batch 392 - loss: 0.6528066992759705\n",
      "Batch 393 - loss: 0.7065207362174988\n",
      "Batch 394 - loss: 0.6366254687309265\n",
      "Batch 395 - loss: 0.7208130359649658\n",
      "Batch 396 - loss: 0.6656724214553833\n",
      "Batch 397 - loss: 0.6836881637573242\n",
      "Batch 398 - loss: 0.6479565501213074\n",
      "Batch 399 - loss: 0.6556248664855957\n",
      "Batch 400 - loss: 0.683742105960846\n",
      "Batch 401 - loss: 0.673961877822876\n",
      "Batch 402 - loss: 0.6864095330238342\n",
      "Batch 403 - loss: 0.6748608946800232\n",
      "Batch 404 - loss: 0.6856032609939575\n",
      "Batch 405 - loss: 0.6831691861152649\n",
      "Batch 406 - loss: 0.6667646765708923\n",
      "Batch 407 - loss: 0.6735382676124573\n",
      "Batch 408 - loss: 0.7036512494087219\n",
      "Batch 409 - loss: 0.6481246948242188\n",
      "Batch 410 - loss: 0.6915813684463501\n",
      "Batch 411 - loss: 0.6785762310028076\n",
      "Batch 412 - loss: 0.6444927453994751\n",
      "Batch 413 - loss: 0.6883273720741272\n",
      "Batch 414 - loss: 0.6763734221458435\n",
      "Batch 415 - loss: 0.6460590362548828\n",
      "Batch 416 - loss: 0.6936797499656677\n",
      "Batch 417 - loss: 0.6583518385887146\n",
      "Batch 418 - loss: 0.626623809337616\n",
      "Batch 419 - loss: 0.6379417777061462\n",
      "Batch 420 - loss: 0.6555377244949341\n",
      "Batch 421 - loss: 0.6251401901245117\n",
      "Batch 422 - loss: 0.6747653484344482\n",
      "Batch 423 - loss: 0.6673117876052856\n",
      "Batch 424 - loss: 0.686647891998291\n",
      "Batch 425 - loss: 0.6354531049728394\n",
      "Batch 426 - loss: 0.6873993277549744\n",
      "Batch 427 - loss: 0.6594991683959961\n",
      "Batch 428 - loss: 0.7007495760917664\n",
      "Batch 429 - loss: 0.6266691088676453\n",
      "Batch 430 - loss: 0.692931592464447\n",
      "Batch 431 - loss: 0.645194947719574\n",
      "Batch 432 - loss: 0.6497102975845337\n",
      "Batch 433 - loss: 0.6578767895698547\n",
      "Batch 434 - loss: 0.6580825448036194\n",
      "Batch 435 - loss: 0.6619255542755127\n",
      "Batch 436 - loss: 0.6568639874458313\n",
      "Batch 437 - loss: 0.6456741690635681\n",
      "Batch 438 - loss: 0.6542096138000488\n",
      "Batch 439 - loss: 0.6826953291893005\n",
      "Batch 440 - loss: 0.7159584760665894\n",
      "Batch 441 - loss: 0.6258981823921204\n",
      "Batch 442 - loss: 0.6662227511405945\n",
      "Batch 443 - loss: 0.6760552525520325\n",
      "Batch 444 - loss: 0.6910620331764221\n",
      "Batch 445 - loss: 0.622643768787384\n",
      "Batch 446 - loss: 0.6781836748123169\n",
      "Batch 447 - loss: 0.6663450002670288\n",
      "Batch 448 - loss: 0.6263205409049988\n",
      "Batch 449 - loss: 0.6917064189910889\n",
      "Batch 450 - loss: 0.6674551963806152\n",
      "Batch 451 - loss: 0.6705403327941895\n",
      "Batch 452 - loss: 0.7035085558891296\n",
      "Batch 453 - loss: 0.6200449466705322\n",
      "Batch 454 - loss: 0.642148494720459\n",
      "Batch 455 - loss: 0.6609589457511902\n",
      "Batch 456 - loss: 0.6592661142349243\n",
      "Batch 457 - loss: 0.6854809522628784\n",
      "Batch 458 - loss: 0.675818145275116\n",
      "Batch 459 - loss: 0.6945455074310303\n",
      "Batch 460 - loss: 0.6795297265052795\n",
      "Batch 461 - loss: 0.6554021239280701\n",
      "Batch 462 - loss: 0.6566442251205444\n",
      "Batch 463 - loss: 0.6568379402160645\n",
      "Batch 464 - loss: 0.6377129554748535\n",
      "Batch 465 - loss: 0.6697874665260315\n",
      "Batch 466 - loss: 0.63671875\n",
      "Batch 467 - loss: 0.6767908930778503\n",
      "Batch 468 - loss: 0.6445905566215515\n",
      "Batch 469 - loss: 0.6681219935417175\n",
      "Batch 470 - loss: 0.6330724358558655\n",
      "Batch 471 - loss: 0.6734198331832886\n",
      "Batch 472 - loss: 0.6840439438819885\n",
      "Batch 473 - loss: 0.6445618867874146\n",
      "Batch 474 - loss: 0.6786990761756897\n",
      "Batch 475 - loss: 0.6688880324363708\n",
      "Batch 476 - loss: 0.6711941957473755\n",
      "Batch 477 - loss: 0.6621799468994141\n",
      "Batch 478 - loss: 0.6845306158065796\n",
      "Batch 479 - loss: 0.6277178525924683\n",
      "Batch 480 - loss: 0.6482630968093872\n",
      "Batch 481 - loss: 0.6170117259025574\n",
      "Batch 482 - loss: 0.6724212765693665\n",
      "Batch 483 - loss: 0.6954116821289062\n",
      "Batch 484 - loss: 0.6450893878936768\n",
      "Batch 485 - loss: 0.6977535486221313\n",
      "Batch 486 - loss: 0.6581214666366577\n",
      "Batch 487 - loss: 0.6713705658912659\n",
      "Batch 488 - loss: 0.6407850980758667\n",
      "Batch 489 - loss: 0.652171790599823\n",
      "Batch 490 - loss: 0.6408138871192932\n",
      "Batch 491 - loss: 0.6390615105628967\n",
      "Batch 492 - loss: 0.6532316207885742\n",
      "Batch 493 - loss: 0.643235981464386\n",
      "Batch 494 - loss: 0.637582004070282\n",
      "Batch 495 - loss: 0.6485172510147095\n",
      "Batch 496 - loss: 0.6829487085342407\n",
      "Batch 497 - loss: 0.6565556526184082\n",
      "Batch 498 - loss: 0.6465080976486206\n",
      "Batch 499 - loss: 0.6340646743774414\n",
      "Batch 500 - loss: 0.6691881418228149\n",
      "Batch 501 - loss: 0.6795089244842529\n",
      "Batch 502 - loss: 0.6771640777587891\n",
      "Batch 503 - loss: 0.6426477432250977\n",
      "Batch 504 - loss: 0.6412742733955383\n",
      "Batch 505 - loss: 0.6350144147872925\n",
      "Batch 506 - loss: 0.6408328413963318\n",
      "Batch 507 - loss: 0.6491312384605408\n",
      "Batch 508 - loss: 0.6722235679626465\n",
      "Batch 509 - loss: 0.635977566242218\n",
      "Batch 510 - loss: 0.6458677053451538\n",
      "Batch 511 - loss: 0.6143832206726074\n",
      "Batch 512 - loss: 0.6582346558570862\n",
      "Batch 513 - loss: 0.6415016055107117\n",
      "Batch 514 - loss: 0.6733289957046509\n",
      "Batch 515 - loss: 0.6286264657974243\n",
      "Batch 516 - loss: 0.6258548498153687\n",
      "Batch 517 - loss: 0.653343677520752\n",
      "Batch 518 - loss: 0.6548027396202087\n",
      "Batch 519 - loss: 0.6451209783554077\n",
      "Batch 520 - loss: 0.6463586091995239\n",
      "Batch 521 - loss: 0.6366294622421265\n",
      "Batch 522 - loss: 0.6503470540046692\n",
      "Batch 523 - loss: 0.6438682675361633\n",
      "Batch 524 - loss: 0.6482046842575073\n",
      "Batch 525 - loss: 0.6050661206245422\n",
      "Batch 526 - loss: 0.6530723571777344\n",
      "Batch 527 - loss: 0.6401335597038269\n",
      "Batch 528 - loss: 0.6091960668563843\n",
      "Batch 529 - loss: 0.6144710183143616\n",
      "Batch 530 - loss: 0.6683878898620605\n",
      "Batch 531 - loss: 0.6612577438354492\n",
      "Batch 532 - loss: 0.6521871089935303\n",
      "Batch 533 - loss: 0.592003345489502\n",
      "Batch 534 - loss: 0.6321550607681274\n",
      "Batch 535 - loss: 0.6598699688911438\n",
      "Batch 536 - loss: 0.6195347905158997\n",
      "Batch 537 - loss: 0.6574979424476624\n",
      "Batch 538 - loss: 0.6282261610031128\n",
      "Batch 539 - loss: 0.6117585897445679\n",
      "Batch 540 - loss: 0.6283777952194214\n",
      "Batch 541 - loss: 0.627147376537323\n",
      "Batch 542 - loss: 0.6471347212791443\n",
      "Batch 543 - loss: 0.6649294495582581\n",
      "Batch 544 - loss: 0.6370447874069214\n",
      "Batch 545 - loss: 0.6161429286003113\n",
      "Batch 546 - loss: 0.6142414212226868\n",
      "Batch 547 - loss: 0.6229581236839294\n",
      "Batch 548 - loss: 0.6390127539634705\n",
      "Batch 549 - loss: 0.6093499064445496\n",
      "Batch 550 - loss: 0.6448627710342407\n",
      "Batch 551 - loss: 0.6022444367408752\n",
      "Batch 552 - loss: 0.6653748154640198\n",
      "Batch 553 - loss: 0.6364737749099731\n",
      "Batch 554 - loss: 0.681901752948761\n",
      "Batch 555 - loss: 0.6238236427307129\n",
      "Batch 556 - loss: 0.6131783127784729\n",
      "Batch 557 - loss: 0.6223912239074707\n",
      "Batch 558 - loss: 0.6317419409751892\n",
      "Batch 559 - loss: 0.5897850394248962\n",
      "Batch 560 - loss: 0.5862569212913513\n",
      "Batch 561 - loss: 0.6353648900985718\n",
      "Batch 562 - loss: 0.66762775182724\n",
      "Batch 563 - loss: 0.6249018311500549\n",
      "Batch 564 - loss: 0.5989091992378235\n",
      "Batch 565 - loss: 0.6096091866493225\n",
      "Batch 566 - loss: 0.6359111070632935\n",
      "Batch 567 - loss: 0.6341211795806885\n",
      "Batch 568 - loss: 0.6556512117385864\n",
      "Batch 569 - loss: 0.6292083859443665\n",
      "Batch 570 - loss: 0.620985746383667\n",
      "Batch 571 - loss: 0.6165748238563538\n",
      "Batch 572 - loss: 0.5996724963188171\n",
      "Batch 573 - loss: 0.6135841608047485\n",
      "Batch 574 - loss: 0.6225067377090454\n",
      "Batch 575 - loss: 0.614249050617218\n",
      "Batch 576 - loss: 0.6141857504844666\n",
      "Batch 577 - loss: 0.5761091113090515\n",
      "Batch 578 - loss: 0.6177469491958618\n",
      "Batch 579 - loss: 0.6310855150222778\n",
      "Batch 580 - loss: 0.6279565095901489\n",
      "Batch 581 - loss: 0.6221413016319275\n",
      "Batch 582 - loss: 0.6209089159965515\n",
      "Batch 583 - loss: 0.6051790714263916\n",
      "Batch 584 - loss: 0.6409676671028137\n",
      "Batch 585 - loss: 0.5624825954437256\n",
      "Batch 586 - loss: 0.6027015447616577\n",
      "Batch 587 - loss: 0.6338596940040588\n",
      "Batch 588 - loss: 0.6510456204414368\n",
      "Batch 589 - loss: 0.6245335340499878\n",
      "Batch 590 - loss: 0.6130334138870239\n",
      "Batch 591 - loss: 0.6345395445823669\n",
      "Batch 592 - loss: 0.6222968101501465\n",
      "Batch 593 - loss: 0.6048190593719482\n",
      "Batch 594 - loss: 0.6258311867713928\n",
      "Batch 595 - loss: 0.6068232655525208\n",
      "Batch 596 - loss: 0.5933094024658203\n",
      "Batch 597 - loss: 0.6457574963569641\n",
      "Batch 598 - loss: 0.5834208726882935\n",
      "Batch 599 - loss: 0.5752313137054443\n",
      "Batch 600 - loss: 0.5804704427719116\n",
      "Batch 601 - loss: 0.5493273138999939\n",
      "Batch 602 - loss: 0.6228682398796082\n",
      "Batch 603 - loss: 0.6144033670425415\n",
      "Batch 604 - loss: 0.6291688680648804\n",
      "Batch 605 - loss: 0.6174772381782532\n",
      "Batch 606 - loss: 0.5957290530204773\n",
      "Batch 607 - loss: 0.5718392729759216\n",
      "Batch 608 - loss: 0.6617478728294373\n",
      "Batch 609 - loss: 0.5620163679122925\n",
      "Batch 610 - loss: 0.6057820320129395\n",
      "Batch 611 - loss: 0.6160063147544861\n",
      "Batch 612 - loss: 0.5796790719032288\n",
      "Batch 613 - loss: 0.6453340649604797\n",
      "Batch 614 - loss: 0.6127505302429199\n",
      "Batch 615 - loss: 0.5748957395553589\n",
      "Batch 616 - loss: 0.6221951246261597\n",
      "Batch 617 - loss: 0.6265661716461182\n",
      "Batch 618 - loss: 0.5617201924324036\n",
      "Batch 619 - loss: 0.5715771317481995\n",
      "Batch 620 - loss: 0.5494062900543213\n",
      "Batch 621 - loss: 0.6094090938568115\n",
      "Batch 622 - loss: 0.5966728925704956\n",
      "Batch 623 - loss: 0.5539670586585999\n",
      "Batch 624 - loss: 0.6207987070083618\n",
      "Batch 625 - loss: 0.5768357515335083\n",
      "Batch 626 - loss: 0.5261316895484924\n",
      "Batch 627 - loss: 0.5911454558372498\n",
      "Batch 628 - loss: 0.6518469452857971\n",
      "Batch 629 - loss: 0.5932090878486633\n",
      "Batch 630 - loss: 0.6435266137123108\n",
      "Batch 631 - loss: 0.5843655467033386\n",
      "Batch 632 - loss: 0.5860117077827454\n",
      "Batch 633 - loss: 0.6096898317337036\n",
      "Batch 634 - loss: 0.6527502536773682\n",
      "Batch 635 - loss: 0.6394746899604797\n",
      "Batch 636 - loss: 0.5875512957572937\n",
      "Batch 637 - loss: 0.6312234997749329\n",
      "Batch 638 - loss: 0.581925094127655\n",
      "Batch 639 - loss: 0.606286883354187\n",
      "Batch 640 - loss: 0.6356315016746521\n",
      "Batch 641 - loss: 0.5840117931365967\n",
      "Batch 642 - loss: 0.5852988958358765\n",
      "Batch 643 - loss: 0.5918706655502319\n",
      "Batch 644 - loss: 0.5802621245384216\n",
      "Batch 645 - loss: 0.5434723496437073\n",
      "Batch 646 - loss: 0.6023333668708801\n",
      "Batch 647 - loss: 0.6210495233535767\n",
      "Batch 648 - loss: 0.5607643723487854\n",
      "Batch 649 - loss: 0.6078585386276245\n",
      "Batch 650 - loss: 0.5830734968185425\n",
      "Batch 651 - loss: 0.5879170894622803\n",
      "Batch 652 - loss: 0.5823355317115784\n",
      "Batch 653 - loss: 0.5918026566505432\n",
      "Batch 654 - loss: 0.5853864550590515\n",
      "Batch 655 - loss: 0.5851815342903137\n",
      "Batch 656 - loss: 0.6015226244926453\n",
      "Batch 657 - loss: 0.5668182373046875\n",
      "Batch 658 - loss: 0.5660243630409241\n",
      "Batch 659 - loss: 0.6156635880470276\n",
      "Batch 660 - loss: 0.6019769906997681\n",
      "Batch 661 - loss: 0.5220710039138794\n",
      "Batch 662 - loss: 0.6609012484550476\n",
      "Batch 663 - loss: 0.5958949327468872\n",
      "Batch 664 - loss: 0.6120172142982483\n",
      "Batch 665 - loss: 0.6335371136665344\n",
      "Batch 666 - loss: 0.553945004940033\n",
      "Batch 667 - loss: 0.5725271105766296\n",
      "Batch 668 - loss: 0.6143012642860413\n",
      "Batch 669 - loss: 0.5646456480026245\n",
      "Batch 670 - loss: 0.6049330234527588\n",
      "Batch 671 - loss: 0.5860034227371216\n",
      "Batch 672 - loss: 0.6328831911087036\n",
      "Batch 673 - loss: 0.5680907368659973\n",
      "Batch 674 - loss: 0.6150132417678833\n",
      "Batch 675 - loss: 0.650079071521759\n",
      "Batch 676 - loss: 0.5798842310905457\n",
      "Batch 677 - loss: 0.559272825717926\n",
      "Batch 678 - loss: 0.618110179901123\n",
      "Batch 679 - loss: 0.58141028881073\n",
      "Batch 680 - loss: 0.5839584469795227\n",
      "Batch 681 - loss: 0.5584684014320374\n",
      "Batch 682 - loss: 0.581574022769928\n",
      "Batch 683 - loss: 0.658732533454895\n",
      "Batch 684 - loss: 0.6229929327964783\n",
      "Batch 685 - loss: 0.5245804190635681\n",
      "Batch 686 - loss: 0.5960420370101929\n",
      "Batch 687 - loss: 0.5897447466850281\n",
      "Batch 688 - loss: 0.6134335398674011\n",
      "Batch 689 - loss: 0.6270391345024109\n",
      "Batch 690 - loss: 0.6118202805519104\n",
      "Batch 691 - loss: 0.607452929019928\n",
      "Batch 692 - loss: 0.5672807693481445\n",
      "Batch 693 - loss: 0.6347675323486328\n",
      "Batch 694 - loss: 0.6469782590866089\n",
      "Batch 695 - loss: 0.5681605339050293\n",
      "Batch 696 - loss: 0.6665436029434204\n",
      "Batch 697 - loss: 0.5831778645515442\n",
      "Batch 698 - loss: 0.6222613453865051\n",
      "Batch 699 - loss: 0.6458317041397095\n",
      "Batch 700 - loss: 0.5525596737861633\n",
      "Batch 701 - loss: 0.6135147213935852\n",
      "Batch 702 - loss: 0.6430959105491638\n",
      "Batch 703 - loss: 0.5755901336669922\n",
      "Batch 704 - loss: 0.5841644406318665\n",
      "Batch 705 - loss: 0.616645336151123\n",
      "Batch 706 - loss: 0.6043273210525513\n",
      "Batch 707 - loss: 0.5857109427452087\n",
      "Batch 708 - loss: 0.586740255355835\n",
      "Batch 709 - loss: 0.6247313022613525\n",
      "Batch 710 - loss: 0.5825788974761963\n",
      "Batch 711 - loss: 0.6184378862380981\n",
      "Batch 712 - loss: 0.6045323610305786\n",
      "Batch 713 - loss: 0.5941529273986816\n",
      "Batch 714 - loss: 0.5955294966697693\n",
      "Batch 715 - loss: 0.5888819098472595\n",
      "Batch 716 - loss: 0.6651564240455627\n",
      "Batch 717 - loss: 0.6096072196960449\n",
      "Batch 718 - loss: 0.49715685844421387\n",
      "Batch 719 - loss: 0.6126646399497986\n",
      "Batch 720 - loss: 0.590011477470398\n",
      "Batch 721 - loss: 0.6171164512634277\n",
      "Batch 722 - loss: 0.6061670780181885\n",
      "Batch 723 - loss: 0.5939427018165588\n",
      "Batch 724 - loss: 0.575124204158783\n",
      "Batch 725 - loss: 0.6211024522781372\n",
      "Batch 726 - loss: 0.572426438331604\n",
      "Batch 727 - loss: 0.5973292589187622\n",
      "Batch 728 - loss: 0.6291387677192688\n",
      "Batch 729 - loss: 0.5981045365333557\n",
      "Batch 730 - loss: 0.5460541248321533\n",
      "Batch 731 - loss: 0.6156460046768188\n",
      "Batch 732 - loss: 0.603550910949707\n",
      "Batch 733 - loss: 0.5985878109931946\n",
      "Batch 734 - loss: 0.5795713067054749\n",
      "Batch 735 - loss: 0.5889875888824463\n",
      "Batch 736 - loss: 0.5628858804702759\n",
      "Batch 737 - loss: 0.6778764724731445\n",
      "Batch 738 - loss: 0.6097021102905273\n",
      "Batch 739 - loss: 0.5791615843772888\n",
      "Batch 740 - loss: 0.5669382810592651\n",
      "Batch 741 - loss: 0.5575318932533264\n",
      "Batch 742 - loss: 0.5503213405609131\n",
      "Batch 743 - loss: 0.5864919424057007\n",
      "Batch 744 - loss: 0.5891326665878296\n",
      "Batch 745 - loss: 0.6382715702056885\n",
      "Batch 746 - loss: 0.5948510766029358\n",
      "Batch 747 - loss: 0.5434259176254272\n",
      "Batch 748 - loss: 0.5921189785003662\n",
      "Batch 749 - loss: 0.5671820640563965\n",
      "Batch 750 - loss: 0.6605117917060852\n",
      "Batch 751 - loss: 0.614768922328949\n",
      "Batch 752 - loss: 0.6075847744941711\n",
      "Batch 753 - loss: 0.597967267036438\n",
      "Batch 754 - loss: 0.5956323146820068\n",
      "Batch 755 - loss: 0.5597954988479614\n",
      "Batch 756 - loss: 0.5850133895874023\n",
      "Batch 757 - loss: 0.5462998151779175\n",
      "Batch 758 - loss: 0.5432752370834351\n",
      "Batch 759 - loss: 0.55423504114151\n",
      "Batch 760 - loss: 0.5805885195732117\n",
      "Batch 761 - loss: 0.6033797860145569\n",
      "Batch 762 - loss: 0.5645174980163574\n",
      "Batch 763 - loss: 0.5590121150016785\n",
      "Batch 764 - loss: 0.5594988465309143\n",
      "Batch 765 - loss: 0.5663257837295532\n",
      "Batch 766 - loss: 0.583171546459198\n",
      "Batch 767 - loss: 0.5426348447799683\n",
      "Batch 768 - loss: 0.5389929413795471\n",
      "Batch 769 - loss: 0.6574755907058716\n",
      "Batch 770 - loss: 0.5652436017990112\n",
      "Batch 771 - loss: 0.554326057434082\n",
      "Batch 772 - loss: 0.5744039416313171\n",
      "Batch 773 - loss: 0.6392257213592529\n",
      "Batch 774 - loss: 0.5982735753059387\n",
      "Batch 775 - loss: 0.5660092234611511\n",
      "Batch 776 - loss: 0.5883404016494751\n",
      "Batch 777 - loss: 0.6622954607009888\n",
      "Batch 778 - loss: 0.571496307849884\n",
      "Batch 779 - loss: 0.6283811926841736\n",
      "Batch 780 - loss: 0.6068422794342041\n",
      "Batch 781 - loss: 0.5966349840164185\n",
      "Batch 782 - loss: 0.6490217447280884\n",
      "Batch 783 - loss: 0.5890377163887024\n",
      "Batch 784 - loss: 0.5409868955612183\n",
      "Batch 785 - loss: 0.7196153998374939\n",
      "Batch 786 - loss: 0.5387030839920044\n",
      "Batch 787 - loss: 0.6348828077316284\n",
      "Batch 788 - loss: 0.5883181095123291\n",
      "Batch 789 - loss: 0.5775132179260254\n",
      "Batch 790 - loss: 0.5632030367851257\n",
      "Batch 791 - loss: 0.5948168635368347\n",
      "Batch 792 - loss: 0.5498300194740295\n",
      "Batch 793 - loss: 0.5562145709991455\n",
      "Batch 794 - loss: 0.5659796595573425\n",
      "Batch 795 - loss: 0.5950192809104919\n",
      "Batch 796 - loss: 0.5984019637107849\n",
      "Batch 797 - loss: 0.5576197504997253\n",
      "Batch 798 - loss: 0.5814264416694641\n",
      "Batch 799 - loss: 0.6474300026893616\n",
      "Batch 800 - loss: 0.5541468858718872\n",
      "Batch 801 - loss: 0.5627931356430054\n",
      "Batch 802 - loss: 0.6059169769287109\n",
      "Batch 803 - loss: 0.5615501403808594\n",
      "Batch 804 - loss: 0.5634559392929077\n",
      "Batch 805 - loss: 0.6035107970237732\n",
      "Batch 806 - loss: 0.5656785368919373\n",
      "Batch 807 - loss: 0.6286991238594055\n",
      "Batch 808 - loss: 0.6423829793930054\n",
      "Batch 809 - loss: 0.574724555015564\n",
      "Batch 810 - loss: 0.5466944575309753\n",
      "Batch 811 - loss: 0.606950581073761\n",
      "Batch 812 - loss: 0.5692391395568848\n",
      "Batch 813 - loss: 0.6024003028869629\n",
      "Batch 814 - loss: 0.5658554434776306\n",
      "Batch 815 - loss: 0.5490251183509827\n",
      "Batch 816 - loss: 0.5950679779052734\n",
      "Batch 817 - loss: 0.5913906097412109\n",
      "Batch 818 - loss: 0.5767349600791931\n",
      "Batch 819 - loss: 0.5979933142662048\n",
      "Batch 820 - loss: 0.5949683785438538\n",
      "Batch 821 - loss: 0.5929288864135742\n",
      "Batch 822 - loss: 0.5364955067634583\n",
      "Batch 823 - loss: 0.584818422794342\n",
      "Batch 824 - loss: 0.5731247067451477\n",
      "Batch 825 - loss: 0.5940895676612854\n",
      "Batch 826 - loss: 0.5750095248222351\n",
      "Batch 827 - loss: 0.6377235651016235\n",
      "Batch 828 - loss: 0.5257071852684021\n",
      "Batch 829 - loss: 0.6081938743591309\n",
      "Batch 830 - loss: 0.5599305629730225\n",
      "Batch 831 - loss: 0.5430188179016113\n",
      "Batch 832 - loss: 0.5719754099845886\n",
      "Batch 833 - loss: 0.6509457230567932\n",
      "Batch 834 - loss: 0.5895451903343201\n",
      "Batch 835 - loss: 0.5911321640014648\n",
      "Batch 836 - loss: 0.5990865230560303\n",
      "Batch 837 - loss: 0.6017042994499207\n",
      "Batch 838 - loss: 0.585839569568634\n",
      "Batch 839 - loss: 0.5358980298042297\n",
      "Batch 840 - loss: 0.5659973621368408\n",
      "Batch 841 - loss: 0.6301262974739075\n",
      "Batch 842 - loss: 0.5894727110862732\n",
      "Batch 843 - loss: 0.580772340297699\n",
      "Batch 844 - loss: 0.548204243183136\n",
      "Batch 845 - loss: 0.6089658737182617\n",
      "Batch 846 - loss: 0.6122153401374817\n",
      "Batch 847 - loss: 0.547573983669281\n",
      "Batch 848 - loss: 0.5283706188201904\n",
      "Batch 849 - loss: 0.613518476486206\n",
      "Batch 850 - loss: 0.5777581334114075\n",
      "Batch 851 - loss: 0.5539451837539673\n",
      "Batch 852 - loss: 0.5826998949050903\n",
      "Batch 853 - loss: 0.6073958277702332\n",
      "Batch 854 - loss: 0.6494109034538269\n",
      "Batch 855 - loss: 0.6215707063674927\n",
      "Batch 856 - loss: 0.6202028393745422\n",
      "Batch 857 - loss: 0.6109217405319214\n",
      "Batch 858 - loss: 0.6200019121170044\n",
      "Batch 859 - loss: 0.538821280002594\n",
      "Batch 860 - loss: 0.5726372003555298\n",
      "Batch 861 - loss: 0.6478895545005798\n",
      "Batch 862 - loss: 0.6248731017112732\n",
      "Batch 863 - loss: 0.6328493356704712\n",
      "Batch 864 - loss: 0.598939836025238\n",
      "Batch 865 - loss: 0.5402018427848816\n",
      "Batch 866 - loss: 0.542151153087616\n",
      "Batch 867 - loss: 0.5161314606666565\n",
      "Batch 868 - loss: 0.5907455682754517\n",
      "Batch 869 - loss: 0.5869717597961426\n",
      "Batch 870 - loss: 0.5873168706893921\n",
      "Batch 871 - loss: 0.5826551914215088\n",
      "Batch 872 - loss: 0.5206952691078186\n",
      "Batch 873 - loss: 0.6068990230560303\n",
      "Batch 874 - loss: 0.5819699168205261\n",
      "Batch 875 - loss: 0.570273756980896\n",
      "Batch 876 - loss: 0.5812442302703857\n",
      "Batch 877 - loss: 0.6222360134124756\n",
      "Batch 878 - loss: 0.5134427547454834\n",
      "Batch 879 - loss: 0.6011333465576172\n",
      "Batch 880 - loss: 0.5866637825965881\n",
      "Batch 881 - loss: 0.5693551898002625\n",
      "Batch 882 - loss: 0.5644150376319885\n",
      "Batch 883 - loss: 0.6209532618522644\n",
      "Batch 884 - loss: 0.5998212099075317\n",
      "Batch 885 - loss: 0.5912983417510986\n",
      "Batch 886 - loss: 0.5173115730285645\n",
      "Batch 887 - loss: 0.6936966776847839\n",
      "Batch 888 - loss: 0.5254992842674255\n",
      "Batch 889 - loss: 0.5987003445625305\n",
      "Batch 890 - loss: 0.5861475467681885\n",
      "Batch 891 - loss: 0.6066324710845947\n",
      "Batch 892 - loss: 0.6350218057632446\n",
      "Batch 893 - loss: 0.5872521996498108\n",
      "Batch 894 - loss: 0.5844960808753967\n",
      "Batch 895 - loss: 0.5809613466262817\n",
      "Batch 896 - loss: 0.5927303433418274\n",
      "Batch 897 - loss: 0.5777042508125305\n",
      "Batch 898 - loss: 0.5639519691467285\n",
      "Batch 899 - loss: 0.5916882157325745\n",
      "Batch 900 - loss: 0.5610566735267639\n",
      "Batch 901 - loss: 0.5757960081100464\n",
      "Batch 902 - loss: 0.6259121298789978\n",
      "Batch 903 - loss: 0.5013256072998047\n",
      "Batch 904 - loss: 0.5806760191917419\n",
      "Batch 905 - loss: 0.5726239681243896\n",
      "Batch 906 - loss: 0.556492805480957\n",
      "Batch 907 - loss: 0.5973324179649353\n",
      "Batch 908 - loss: 0.5518554449081421\n",
      "Batch 909 - loss: 0.5679412484169006\n",
      "Batch 910 - loss: 0.5631264448165894\n",
      "Batch 911 - loss: 0.5729873180389404\n",
      "Batch 912 - loss: 0.5325251817703247\n",
      "Batch 913 - loss: 0.5682011246681213\n",
      "Batch 914 - loss: 0.6104176640510559\n",
      "Batch 915 - loss: 0.548530101776123\n",
      "Batch 916 - loss: 0.5285100936889648\n",
      "Batch 917 - loss: 0.6047903299331665\n",
      "Batch 918 - loss: 0.5457264184951782\n",
      "Batch 919 - loss: 0.5751577019691467\n",
      "Batch 920 - loss: 0.4789508879184723\n",
      "Batch 921 - loss: 0.5488263368606567\n",
      "Batch 922 - loss: 0.6415895223617554\n",
      "Batch 923 - loss: 0.5355079770088196\n",
      "Batch 924 - loss: 0.5750949382781982\n",
      "Batch 925 - loss: 0.5794530510902405\n",
      "Batch 926 - loss: 0.5152051448822021\n",
      "Batch 927 - loss: 0.5690800547599792\n",
      "Batch 928 - loss: 0.5482601523399353\n",
      "Batch 929 - loss: 0.5463833212852478\n",
      "Batch 930 - loss: 0.567784309387207\n",
      "Batch 931 - loss: 0.5751428008079529\n",
      "Batch 932 - loss: 0.5728477239608765\n",
      "Batch 933 - loss: 0.5425190925598145\n",
      "Batch 934 - loss: 0.530555009841919\n",
      "Batch 935 - loss: 0.5733002424240112\n",
      "Batch 936 - loss: 0.5501366257667542\n",
      "Batch 937 - loss: 0.5438741445541382\n",
      "Batch 938 - loss: 0.5264844298362732\n",
      "Batch 939 - loss: 0.5610922574996948\n",
      "Batch 940 - loss: 0.5422565937042236\n",
      "Batch 941 - loss: 0.5703601241111755\n",
      "Batch 942 - loss: 0.5733223557472229\n",
      "Batch 943 - loss: 0.6066188216209412\n",
      "Batch 944 - loss: 0.5130453705787659\n",
      "Batch 945 - loss: 0.5888717770576477\n",
      "Batch 946 - loss: 0.5283129811286926\n",
      "Batch 947 - loss: 0.5851802825927734\n",
      "Batch 948 - loss: 0.562105655670166\n",
      "Batch 949 - loss: 0.5408150553703308\n",
      "Batch 950 - loss: 0.5175637006759644\n",
      "Batch 951 - loss: 0.5858640074729919\n",
      "Batch 952 - loss: 0.5330350995063782\n",
      "Batch 953 - loss: 0.5887060165405273\n",
      "Batch 954 - loss: 0.5299185514450073\n",
      "Batch 955 - loss: 0.569732129573822\n",
      "Batch 956 - loss: 0.5814721584320068\n",
      "Batch 957 - loss: 0.5894551277160645\n",
      "Batch 958 - loss: 0.566361665725708\n",
      "Batch 959 - loss: 0.5370110273361206\n",
      "Batch 960 - loss: 0.5146149396896362\n",
      "Batch 961 - loss: 0.5551275610923767\n",
      "Batch 962 - loss: 0.6072322130203247\n",
      "Batch 963 - loss: 0.5932850241661072\n",
      "Batch 964 - loss: 0.6250684261322021\n",
      "Batch 965 - loss: 0.5321594476699829\n",
      "Batch 966 - loss: 0.5535790324211121\n",
      "Batch 967 - loss: 0.5580247044563293\n",
      "Batch 968 - loss: 0.5621241331100464\n",
      "Batch 969 - loss: 0.6004041433334351\n",
      "Batch 970 - loss: 0.5542008876800537\n",
      "Batch 971 - loss: 0.5951665043830872\n",
      "Batch 972 - loss: 0.5544999837875366\n",
      "Batch 973 - loss: 0.6005744934082031\n",
      "Batch 974 - loss: 0.6467165350914001\n",
      "Batch 975 - loss: 0.5703465938568115\n",
      "Batch 976 - loss: 0.542242169380188\n",
      "Batch 977 - loss: 0.5964928865432739\n",
      "Batch 978 - loss: 0.5743666291236877\n",
      "Batch 979 - loss: 0.6025946736335754\n",
      "Batch 980 - loss: 0.5856313109397888\n",
      "Batch 981 - loss: 0.5829806327819824\n",
      "Batch 982 - loss: 0.5769855380058289\n",
      "Batch 983 - loss: 0.5757680535316467\n",
      "Batch 984 - loss: 0.5391464829444885\n",
      "Batch 985 - loss: 0.573312520980835\n",
      "Batch 986 - loss: 0.550446629524231\n",
      "Batch 987 - loss: 0.6074250936508179\n",
      "Batch 988 - loss: 0.5580043792724609\n",
      "Batch 989 - loss: 0.5573928356170654\n",
      "Batch 990 - loss: 0.561797559261322\n",
      "Batch 991 - loss: 0.6226752996444702\n",
      "Batch 992 - loss: 0.5610983967781067\n",
      "Batch 993 - loss: 0.5746004581451416\n",
      "Batch 994 - loss: 0.5348265767097473\n",
      "Batch 995 - loss: 0.5573799014091492\n",
      "Batch 996 - loss: 0.5154269337654114\n",
      "Batch 997 - loss: 0.616352379322052\n",
      "Batch 998 - loss: 0.5307411551475525\n",
      "Batch 999 - loss: 0.554121196269989\n",
      "Batch 1000 - loss: 0.5107105374336243\n",
      "Batch 1001 - loss: 0.5652353167533875\n",
      "Batch 1002 - loss: 0.5286937355995178\n",
      "Batch 1003 - loss: 0.5519559979438782\n",
      "Batch 1004 - loss: 0.5745647549629211\n",
      "Batch 1005 - loss: 0.5522634983062744\n",
      "Batch 1006 - loss: 0.5392659902572632\n",
      "Batch 1007 - loss: 0.5343407988548279\n",
      "Batch 1008 - loss: 0.5580758452415466\n",
      "Batch 1009 - loss: 0.5471868515014648\n",
      "Batch 1010 - loss: 0.5857855677604675\n",
      "Batch 1011 - loss: 0.6262888312339783\n",
      "Batch 1012 - loss: 0.5585858225822449\n",
      "Batch 1013 - loss: 0.5545047521591187\n",
      "Batch 1014 - loss: 0.5602626800537109\n",
      "Batch 1015 - loss: 0.5221459269523621\n",
      "Batch 1016 - loss: 0.6042699217796326\n",
      "Batch 1017 - loss: 0.5706617832183838\n",
      "Batch 1018 - loss: 0.5473838448524475\n",
      "Batch 1019 - loss: 0.5444918870925903\n",
      "Batch 1020 - loss: 0.5567499995231628\n",
      "Batch 1021 - loss: 0.5786987543106079\n",
      "Batch 1022 - loss: 0.5466343760490417\n",
      "Batch 1023 - loss: 0.5510175824165344\n",
      "Batch 1024 - loss: 0.5739825963973999\n",
      "Batch 1025 - loss: 0.5536702275276184\n",
      "Batch 1026 - loss: 0.6284173130989075\n",
      "Batch 1027 - loss: 0.5847082734107971\n",
      "Batch 1028 - loss: 0.539942741394043\n",
      "Batch 1029 - loss: 0.5530020594596863\n",
      "Batch 1030 - loss: 0.5494352579116821\n",
      "Batch 1031 - loss: 0.5747168064117432\n",
      "Batch 1032 - loss: 0.5839571356773376\n",
      "Batch 1033 - loss: 0.5919034481048584\n",
      "Batch 1034 - loss: 0.5629301071166992\n",
      "Batch 1035 - loss: 0.553647518157959\n",
      "Batch 1036 - loss: 0.5753560066223145\n",
      "Batch 1037 - loss: 0.56846684217453\n",
      "Batch 1038 - loss: 0.5399175882339478\n",
      "Batch 1039 - loss: 0.504591166973114\n",
      "Batch 1040 - loss: 0.5621501207351685\n",
      "Batch 1041 - loss: 0.5214380621910095\n",
      "Batch 1042 - loss: 0.5753243565559387\n",
      "Batch 1043 - loss: 0.563352108001709\n",
      "Batch 1044 - loss: 0.5759611129760742\n",
      "Batch 1045 - loss: 0.5088787078857422\n",
      "Batch 1046 - loss: 0.5530763864517212\n",
      "Batch 1047 - loss: 0.5534250140190125\n",
      "Batch 1048 - loss: 0.548486590385437\n",
      "Batch 1049 - loss: 0.5541549921035767\n",
      "Batch 1050 - loss: 0.5120753049850464\n",
      "Batch 1051 - loss: 0.5132937431335449\n",
      "Batch 1052 - loss: 0.5056188106536865\n",
      "Batch 1053 - loss: 0.6170058846473694\n",
      "Batch 1054 - loss: 0.6060253977775574\n",
      "Batch 1055 - loss: 0.6109591722488403\n",
      "Batch 1056 - loss: 0.5778358578681946\n",
      "Batch 1057 - loss: 0.5377389788627625\n",
      "Batch 1058 - loss: 0.5657769441604614\n",
      "Batch 1059 - loss: 0.5697328448295593\n",
      "Batch 1060 - loss: 0.5621487498283386\n",
      "Batch 1061 - loss: 0.5508973598480225\n",
      "Batch 1062 - loss: 0.5170019268989563\n",
      "Batch 1063 - loss: 0.6232624053955078\n",
      "Batch 1064 - loss: 0.5381054282188416\n",
      "Batch 1065 - loss: 0.6099807024002075\n",
      "Batch 1066 - loss: 0.5879656672477722\n",
      "Batch 1067 - loss: 0.5805777907371521\n",
      "Batch 1068 - loss: 0.5984820127487183\n",
      "Batch 1069 - loss: 0.5581691265106201\n",
      "Batch 1070 - loss: 0.6024593114852905\n",
      "Batch 1071 - loss: 0.5717038512229919\n",
      "Batch 1072 - loss: 0.5951114296913147\n",
      "Batch 1073 - loss: 0.5912253260612488\n",
      "Batch 1074 - loss: 0.5413558483123779\n",
      "Batch 1075 - loss: 0.550501823425293\n",
      "Batch 1076 - loss: 0.547989547252655\n",
      "Batch 1077 - loss: 0.5332462191581726\n",
      "Batch 1078 - loss: 0.584511399269104\n",
      "Batch 1079 - loss: 0.511238157749176\n",
      "Batch 1080 - loss: 0.5505841374397278\n",
      "Batch 1081 - loss: 0.589978039264679\n",
      "Batch 1082 - loss: 0.5511411428451538\n",
      "Batch 1083 - loss: 0.5639608502388\n",
      "Batch 1084 - loss: 0.5404853224754333\n",
      "Batch 1085 - loss: 0.5684577226638794\n",
      "Batch 1086 - loss: 0.5417823195457458\n",
      "Batch 1087 - loss: 0.5162041783332825\n",
      "Batch 1088 - loss: 0.4704596996307373\n",
      "Batch 1089 - loss: 0.5969629883766174\n",
      "Batch 1090 - loss: 0.5258965492248535\n",
      "Batch 1091 - loss: 0.5790356993675232\n",
      "Batch 1092 - loss: 0.5569621324539185\n",
      "Batch 1093 - loss: 0.5192273259162903\n",
      "Batch 1094 - loss: 0.6711055636405945\n",
      "Batch 1095 - loss: 0.5952876806259155\n",
      "Batch 1096 - loss: 0.5514070391654968\n",
      "Batch 1097 - loss: 0.5794785022735596\n",
      "Batch 1098 - loss: 0.5955507755279541\n",
      "Batch 1099 - loss: 0.5597146153450012\n",
      "Batch 1100 - loss: 0.5740242600440979\n",
      "Batch 1101 - loss: 0.5980066657066345\n",
      "Batch 1102 - loss: 0.555363655090332\n",
      "Batch 1103 - loss: 0.49896129965782166\n",
      "Batch 1104 - loss: 0.5919195413589478\n",
      "Batch 1105 - loss: 0.5751604437828064\n",
      "Batch 1106 - loss: 0.5386074185371399\n",
      "Batch 1107 - loss: 0.6433367133140564\n",
      "Batch 1108 - loss: 0.5353019833564758\n",
      "Batch 1109 - loss: 0.6035096049308777\n",
      "Batch 1110 - loss: 0.562553882598877\n",
      "Batch 1111 - loss: 0.5600023865699768\n",
      "Batch 1112 - loss: 0.6220400333404541\n",
      "Batch 1113 - loss: 0.632803738117218\n",
      "Batch 1114 - loss: 0.5598515868186951\n",
      "Batch 1115 - loss: 0.5641870498657227\n",
      "Batch 1116 - loss: 0.5711780190467834\n",
      "Batch 1117 - loss: 0.5462386012077332\n",
      "Batch 1118 - loss: 0.566870391368866\n",
      "Batch 1119 - loss: 0.5845177173614502\n",
      "Batch 1120 - loss: 0.5603638887405396\n",
      "Batch 1121 - loss: 0.6707221269607544\n",
      "Batch 1122 - loss: 0.5993788838386536\n",
      "Batch 1123 - loss: 0.5181707143783569\n",
      "Batch 1124 - loss: 0.5745232105255127\n",
      "Batch 1125 - loss: 0.644310474395752\n",
      "Batch 1126 - loss: 0.5731263160705566\n",
      "Batch 1127 - loss: 0.5663965940475464\n",
      "Batch 1128 - loss: 0.5306531190872192\n",
      "Batch 1129 - loss: 0.5429149866104126\n",
      "Batch 1130 - loss: 0.5325348973274231\n",
      "Batch 1131 - loss: 0.5720112323760986\n",
      "Batch 1132 - loss: 0.5677437782287598\n",
      "Batch 1133 - loss: 0.5775824189186096\n",
      "Batch 1134 - loss: 0.5328245759010315\n",
      "Batch 1135 - loss: 0.5475496649742126\n",
      "Batch 1136 - loss: 0.6095790863037109\n",
      "Batch 1137 - loss: 0.5187008380889893\n",
      "Batch 1138 - loss: 0.5534629821777344\n",
      "Batch 1139 - loss: 0.5412104725837708\n",
      "Batch 1140 - loss: 0.5399812459945679\n",
      "Batch 1141 - loss: 0.5491551160812378\n",
      "Batch 1142 - loss: 0.5003471970558167\n",
      "Batch 1143 - loss: 0.5176122784614563\n",
      "Batch 1144 - loss: 0.5087032914161682\n",
      "Batch 1145 - loss: 0.5841779112815857\n",
      "Batch 1146 - loss: 0.5570507049560547\n",
      "Batch 1147 - loss: 0.5558456182479858\n",
      "Batch 1148 - loss: 0.5581627488136292\n",
      "Batch 1149 - loss: 0.5840843319892883\n",
      "Batch 1150 - loss: 0.6046442985534668\n",
      "Batch 1151 - loss: 0.5742706060409546\n",
      "Batch 1152 - loss: 0.5898064970970154\n",
      "Batch 1153 - loss: 0.5655023455619812\n",
      "Batch 1154 - loss: 0.5347180366516113\n",
      "Batch 1155 - loss: 0.5516388416290283\n",
      "Batch 1156 - loss: 0.5591962337493896\n",
      "Batch 1157 - loss: 0.5589214563369751\n",
      "Batch 1158 - loss: 0.6208581328392029\n",
      "Batch 1159 - loss: 0.5833083987236023\n",
      "Batch 1160 - loss: 0.5828818082809448\n",
      "Batch 1161 - loss: 0.4995534121990204\n",
      "Batch 1162 - loss: 0.6015012264251709\n",
      "Batch 1163 - loss: 0.5917306542396545\n",
      "Batch 1164 - loss: 0.588534414768219\n",
      "Batch 1165 - loss: 0.5411379337310791\n",
      "Batch 1166 - loss: 0.5589940547943115\n",
      "Batch 1167 - loss: 0.5568383932113647\n",
      "Batch 1168 - loss: 0.5909173488616943\n",
      "Batch 1169 - loss: 0.5791217088699341\n",
      "Batch 1170 - loss: 0.5846372842788696\n",
      "Batch 1171 - loss: 0.5808262825012207\n",
      "Batch 1172 - loss: 0.5409561991691589\n",
      "Batch 1173 - loss: 0.5737423896789551\n",
      "Batch 1174 - loss: 0.5843534469604492\n",
      "Batch 1175 - loss: 0.5708937644958496\n",
      "Batch 1176 - loss: 0.570288360118866\n",
      "Batch 1177 - loss: 0.5478244423866272\n",
      "Batch 1178 - loss: 0.5726176500320435\n",
      "Batch 1179 - loss: 0.5615737438201904\n",
      "Batch 1180 - loss: 0.5783072113990784\n",
      "Batch 1181 - loss: 0.5488795042037964\n",
      "Batch 1182 - loss: 0.5483049154281616\n",
      "Batch 1183 - loss: 0.5428757071495056\n",
      "Batch 1184 - loss: 0.5422128438949585\n",
      "Batch 1185 - loss: 0.6180363893508911\n",
      "Batch 1186 - loss: 0.5469667911529541\n",
      "Batch 1187 - loss: 0.5658146739006042\n",
      "Batch 1188 - loss: 0.5574939250946045\n",
      "Batch 1189 - loss: 0.5967612266540527\n",
      "Batch 1190 - loss: 0.6011305451393127\n",
      "Batch 1191 - loss: 0.5255689024925232\n",
      "Batch 1192 - loss: 0.6284717917442322\n",
      "Batch 1193 - loss: 0.5726478099822998\n",
      "Batch 1194 - loss: 0.5744638442993164\n",
      "Batch 1195 - loss: 0.5656027793884277\n",
      "Batch 1196 - loss: 0.5431632995605469\n",
      "Batch 1197 - loss: 0.533754289150238\n",
      "Batch 1198 - loss: 0.5759305357933044\n",
      "Batch 1199 - loss: 0.5867443680763245\n",
      "Batch 1200 - loss: 0.5665407776832581\n",
      "Batch 1201 - loss: 0.5117447972297668\n",
      "Batch 1202 - loss: 0.5122449994087219\n",
      "Batch 1203 - loss: 0.6004548668861389\n",
      "Batch 1204 - loss: 0.5563430786132812\n",
      "Batch 1205 - loss: 0.601123034954071\n",
      "Batch 1206 - loss: 0.5369488000869751\n",
      "Batch 1207 - loss: 0.590843915939331\n",
      "Batch 1208 - loss: 0.5780068039894104\n",
      "Batch 1209 - loss: 0.5573667287826538\n",
      "Batch 1210 - loss: 0.5630204081535339\n",
      "Batch 1211 - loss: 0.5732076168060303\n",
      "Batch 1212 - loss: 0.555285632610321\n",
      "Batch 1213 - loss: 0.5771470665931702\n",
      "Batch 1214 - loss: 0.5265645384788513\n",
      "Batch 1215 - loss: 0.5046945810317993\n",
      "Batch 1216 - loss: 0.6022214889526367\n",
      "Batch 1217 - loss: 0.5528885722160339\n",
      "Batch 1218 - loss: 0.5249822735786438\n",
      "Batch 1219 - loss: 0.5820761322975159\n",
      "Batch 1220 - loss: 0.524807870388031\n",
      "Batch 1221 - loss: 0.5266799330711365\n",
      "Batch 1222 - loss: 0.6097093820571899\n",
      "Batch 1223 - loss: 0.5433710813522339\n",
      "Batch 1224 - loss: 0.528326153755188\n",
      "Batch 1225 - loss: 0.5964464545249939\n",
      "Batch 1226 - loss: 0.5865269303321838\n",
      "Batch 1227 - loss: 0.5112853050231934\n",
      "Batch 1228 - loss: 0.5584712028503418\n",
      "Batch 1229 - loss: 0.5630824565887451\n",
      "Batch 1230 - loss: 0.6089549660682678\n",
      "Batch 1231 - loss: 0.5473331809043884\n",
      "Batch 1232 - loss: 0.5934528708457947\n",
      "Batch 1233 - loss: 0.6346864104270935\n",
      "Batch 1234 - loss: 0.49320757389068604\n",
      "Batch 1235 - loss: 0.5690269470214844\n",
      "Batch 1236 - loss: 0.5635389685630798\n",
      "Batch 1237 - loss: 0.5144875049591064\n",
      "Batch 1238 - loss: 0.580513596534729\n",
      "Batch 1239 - loss: 0.5108289122581482\n",
      "Batch 1240 - loss: 0.5962947010993958\n",
      "Batch 1241 - loss: 0.5503451824188232\n",
      "Batch 1242 - loss: 0.5607264041900635\n",
      "Batch 1243 - loss: 0.5735071897506714\n",
      "Batch 1244 - loss: 0.5057247877120972\n",
      "Batch 1245 - loss: 0.6100302338600159\n",
      "Batch 1246 - loss: 0.6174188852310181\n",
      "Batch 1247 - loss: 0.5992867350578308\n",
      "Batch 1248 - loss: 0.6453297734260559\n",
      "Batch 1249 - loss: 0.5418663620948792\n",
      "Batch 1250 - loss: 0.616409182548523\n",
      "Batch 1251 - loss: 0.6005913615226746\n",
      "Batch 1252 - loss: 0.5772511959075928\n",
      "Batch 1253 - loss: 0.5795899033546448\n",
      "Batch 1254 - loss: 0.5585969090461731\n",
      "Batch 1255 - loss: 0.558337926864624\n",
      "Batch 1256 - loss: 0.5399227738380432\n",
      "Batch 1257 - loss: 0.5182989239692688\n",
      "Batch 1258 - loss: 0.5498458743095398\n",
      "Batch 1259 - loss: 0.5782710313796997\n",
      "Batch 1260 - loss: 0.546147346496582\n",
      "Batch 1261 - loss: 0.6237093210220337\n",
      "Batch 1262 - loss: 0.552798867225647\n",
      "Batch 1263 - loss: 0.516521692276001\n",
      "Batch 1264 - loss: 0.5622164607048035\n",
      "Batch 1265 - loss: 0.5754350423812866\n",
      "Batch 1266 - loss: 0.5404002070426941\n",
      "Batch 1267 - loss: 0.5524590015411377\n",
      "Batch 1268 - loss: 0.4905470013618469\n",
      "Batch 1269 - loss: 0.5783190131187439\n",
      "Batch 1270 - loss: 0.5144436955451965\n",
      "Batch 1271 - loss: 0.5772451758384705\n",
      "Batch 1272 - loss: 0.5404568910598755\n",
      "Batch 1273 - loss: 0.5998653769493103\n",
      "Batch 1274 - loss: 0.5479881167411804\n",
      "Batch 1275 - loss: 0.6051527261734009\n",
      "Batch 1276 - loss: 0.5602062344551086\n",
      "Batch 1277 - loss: 0.5355256795883179\n",
      "Batch 1278 - loss: 0.537043571472168\n",
      "Batch 1279 - loss: 0.5529819130897522\n",
      "Batch 1280 - loss: 0.5228039026260376\n",
      "Batch 1281 - loss: 0.5790166258811951\n",
      "Batch 1282 - loss: 0.5715661644935608\n",
      "Batch 1283 - loss: 0.5671790838241577\n",
      "Batch 1284 - loss: 0.553206741809845\n",
      "Batch 1285 - loss: 0.5232125520706177\n",
      "Batch 1286 - loss: 0.5499109029769897\n",
      "Batch 1287 - loss: 0.5623259544372559\n",
      "Batch 1288 - loss: 0.5442489981651306\n",
      "Batch 1289 - loss: 0.6365094184875488\n",
      "Batch 1290 - loss: 0.5437506437301636\n",
      "Batch 1291 - loss: 0.5924960970878601\n",
      "Batch 1292 - loss: 0.5846958160400391\n",
      "Batch 1293 - loss: 0.5090860724449158\n",
      "Batch 1294 - loss: 0.5730961561203003\n",
      "Batch 1295 - loss: 0.574578046798706\n",
      "Batch 1296 - loss: 0.5609377026557922\n",
      "Batch 1297 - loss: 0.5940954089164734\n",
      "Batch 1298 - loss: 0.6057080626487732\n",
      "Batch 1299 - loss: 0.5227595567703247\n",
      "Batch 1300 - loss: 0.5267186760902405\n",
      "Batch 1301 - loss: 0.5537837147712708\n",
      "Batch 1302 - loss: 0.5648154020309448\n",
      "Batch 1303 - loss: 0.5675090551376343\n",
      "Batch 1304 - loss: 0.6413415670394897\n",
      "Batch 1305 - loss: 0.5856613516807556\n",
      "Batch 1306 - loss: 0.6010684370994568\n",
      "Batch 1307 - loss: 0.5785536766052246\n",
      "Batch 1308 - loss: 0.5459496378898621\n",
      "Batch 1309 - loss: 0.5747953653335571\n",
      "Batch 1310 - loss: 0.5301132202148438\n",
      "Batch 1311 - loss: 0.548159658908844\n",
      "Batch 1312 - loss: 0.5153772830963135\n",
      "Batch 1313 - loss: 0.5729438662528992\n",
      "Batch 1314 - loss: 0.5636416077613831\n",
      "Batch 1315 - loss: 0.5561310052871704\n",
      "Batch 1316 - loss: 0.5498831272125244\n",
      "Batch 1317 - loss: 0.5513322949409485\n",
      "Batch 1318 - loss: 0.6124374866485596\n",
      "Batch 1319 - loss: 0.5336489081382751\n",
      "Batch 1320 - loss: 0.5806878805160522\n",
      "Batch 1321 - loss: 0.5706743001937866\n",
      "Batch 1322 - loss: 0.5485430955886841\n",
      "Batch 1323 - loss: 0.5316511392593384\n",
      "Batch 1324 - loss: 0.5775487422943115\n",
      "Batch 1325 - loss: 0.5897825360298157\n",
      "Batch 1326 - loss: 0.5150044560432434\n",
      "Batch 1327 - loss: 0.5801268219947815\n",
      "Batch 1328 - loss: 0.5405158400535583\n",
      "Batch 1329 - loss: 0.5216339826583862\n",
      "Batch 1330 - loss: 0.4785316586494446\n",
      "Batch 1331 - loss: 0.5653432607650757\n",
      "Batch 1332 - loss: 0.5396426916122437\n",
      "Batch 1333 - loss: 0.5262433886528015\n",
      "Batch 1334 - loss: 0.581183910369873\n",
      "Batch 1335 - loss: 0.583328127861023\n",
      "Batch 1336 - loss: 0.5295072197914124\n",
      "Batch 1337 - loss: 0.5186840891838074\n",
      "Batch 1338 - loss: 0.5388340353965759\n",
      "Batch 1339 - loss: 0.5448846220970154\n",
      "Batch 1340 - loss: 0.5404922366142273\n",
      "Batch 1341 - loss: 0.5671797394752502\n",
      "Batch 1342 - loss: 0.5621263384819031\n",
      "Batch 1343 - loss: 0.5391346216201782\n",
      "Batch 1344 - loss: 0.5433447360992432\n",
      "Batch 1345 - loss: 0.5998508334159851\n",
      "Batch 1346 - loss: 0.5521402359008789\n",
      "Batch 1347 - loss: 0.5596632361412048\n",
      "Batch 1348 - loss: 0.534073531627655\n",
      "Batch 1349 - loss: 0.5461984872817993\n",
      "Batch 1350 - loss: 0.5733574032783508\n",
      "Batch 1351 - loss: 0.5085182785987854\n",
      "Batch 1352 - loss: 0.6016785502433777\n",
      "Batch 1353 - loss: 0.5598708987236023\n",
      "Batch 1354 - loss: 0.5410495400428772\n",
      "Batch 1355 - loss: 0.5810121297836304\n",
      "Batch 1356 - loss: 0.612743079662323\n",
      "Batch 1357 - loss: 0.6389653086662292\n",
      "Batch 1358 - loss: 0.576625406742096\n",
      "Batch 1359 - loss: 0.615878164768219\n",
      "Batch 1360 - loss: 0.5885100960731506\n",
      "Batch 1361 - loss: 0.5012946128845215\n",
      "Batch 1362 - loss: 0.562727153301239\n",
      "Batch 1363 - loss: 0.5420494079589844\n",
      "Batch 1364 - loss: 0.5694032311439514\n",
      "Batch 1365 - loss: 0.5707850456237793\n",
      "Batch 1366 - loss: 0.5388909578323364\n",
      "Batch 1367 - loss: 0.5702131986618042\n",
      "Batch 1368 - loss: 0.486639142036438\n",
      "Batch 1369 - loss: 0.5090949535369873\n",
      "Batch 1370 - loss: 0.5564305782318115\n",
      "Batch 1371 - loss: 0.5554293394088745\n",
      "Batch 1372 - loss: 0.5546936988830566\n",
      "Batch 1373 - loss: 0.5820460319519043\n",
      "Batch 1374 - loss: 0.5890848636627197\n",
      "Batch 1375 - loss: 0.5305935144424438\n",
      "Batch 1376 - loss: 0.556168794631958\n",
      "Batch 1377 - loss: 0.522301435470581\n",
      "Batch 1378 - loss: 0.5379399061203003\n",
      "Batch 1379 - loss: 0.5329453945159912\n",
      "Batch 1380 - loss: 0.5517638921737671\n",
      "Batch 1381 - loss: 0.5458160638809204\n",
      "Batch 1382 - loss: 0.4612756371498108\n",
      "Batch 1383 - loss: 0.5129148364067078\n",
      "Batch 1384 - loss: 0.5508700609207153\n",
      "Batch 1385 - loss: 0.6175466775894165\n",
      "Batch 1386 - loss: 0.5104228854179382\n",
      "Batch 1387 - loss: 0.5296367406845093\n",
      "Batch 1388 - loss: 0.5190451145172119\n",
      "Batch 1389 - loss: 0.5671747326850891\n",
      "Batch 1390 - loss: 0.5445851683616638\n",
      "Batch 1391 - loss: 0.5892152190208435\n",
      "Batch 1392 - loss: 0.5204617977142334\n",
      "Batch 1393 - loss: 0.5525433421134949\n",
      "Batch 1394 - loss: 0.5340185165405273\n",
      "Batch 1395 - loss: 0.5613119006156921\n",
      "Batch 1396 - loss: 0.5547480583190918\n",
      "Batch 1397 - loss: 0.5378711819648743\n",
      "Batch 1398 - loss: 0.5318259000778198\n",
      "Batch 1399 - loss: 0.6001015901565552\n",
      "Batch 1400 - loss: 0.5374352931976318\n",
      "Batch 1401 - loss: 0.5227453708648682\n",
      "Batch 1402 - loss: 0.533839225769043\n",
      "Batch 1403 - loss: 0.5503358840942383\n",
      "Batch 1404 - loss: 0.5666331648826599\n",
      "Batch 1405 - loss: 0.5688052773475647\n",
      "Batch 1406 - loss: 0.5446298718452454\n",
      "Batch 1407 - loss: 0.6013743281364441\n",
      "Batch 1408 - loss: 0.6030979156494141\n",
      "Batch 1409 - loss: 0.5389646887779236\n",
      "Batch 1410 - loss: 0.5602909922599792\n",
      "Batch 1411 - loss: 0.5445380210876465\n",
      "Batch 1412 - loss: 0.5364654064178467\n",
      "Batch 1413 - loss: 0.5321656465530396\n",
      "Batch 1414 - loss: 0.569414496421814\n",
      "Batch 1415 - loss: 0.5593491792678833\n",
      "Batch 1416 - loss: 0.5997599959373474\n",
      "Batch 1417 - loss: 0.5842577219009399\n",
      "Batch 1418 - loss: 0.5931123495101929\n",
      "Batch 1419 - loss: 0.538007915019989\n",
      "Batch 1420 - loss: 0.541511058807373\n",
      "Batch 1421 - loss: 0.5010147094726562\n",
      "Batch 1422 - loss: 0.5542524456977844\n",
      "Batch 1423 - loss: 0.5266538858413696\n",
      "Batch 1424 - loss: 0.5179542303085327\n",
      "Batch 1425 - loss: 0.531089186668396\n",
      "Batch 1426 - loss: 0.5323627591133118\n",
      "Batch 1427 - loss: 0.5236486792564392\n",
      "Batch 1428 - loss: 0.5421082973480225\n",
      "Batch 1429 - loss: 0.5825849771499634\n",
      "Batch 1430 - loss: 0.5655021667480469\n",
      "Batch 1431 - loss: 0.5232993364334106\n",
      "Batch 1432 - loss: 0.5648735761642456\n",
      "Batch 1433 - loss: 0.6019136905670166\n",
      "Batch 1434 - loss: 0.5947301983833313\n",
      "Batch 1435 - loss: 0.5276800394058228\n",
      "Batch 1436 - loss: 0.6442341804504395\n",
      "Batch 1437 - loss: 0.6144420504570007\n",
      "Batch 1438 - loss: 0.6269373893737793\n",
      "Batch 1439 - loss: 0.5453744530677795\n",
      "Batch 1440 - loss: 0.7927524447441101\n",
      "Batch 1441 - loss: 0.5625476837158203\n",
      "Batch 1442 - loss: 0.5630894303321838\n",
      "Batch 1443 - loss: 0.5990829467773438\n",
      "Batch 1444 - loss: 0.5155512094497681\n",
      "Batch 1445 - loss: 0.504761815071106\n",
      "Batch 1446 - loss: 0.560796320438385\n",
      "Batch 1447 - loss: 0.4586545526981354\n",
      "Batch 1448 - loss: 0.5675013065338135\n",
      "Batch 1449 - loss: 0.5587206482887268\n",
      "Batch 1450 - loss: 0.6136900186538696\n",
      "Batch 1451 - loss: 0.6012275815010071\n",
      "Batch 1452 - loss: 0.5474221110343933\n",
      "Batch 1453 - loss: 0.5535355806350708\n",
      "Batch 1454 - loss: 0.5165227651596069\n",
      "Batch 1455 - loss: 0.5614872574806213\n",
      "Batch 1456 - loss: 0.5798813700675964\n",
      "Batch 1457 - loss: 0.5458084940910339\n",
      "Batch 1458 - loss: 0.52982497215271\n",
      "Batch 1459 - loss: 0.5564807653427124\n",
      "Batch 1460 - loss: 0.5316081643104553\n",
      "Batch 1461 - loss: 0.6009005308151245\n",
      "Batch 1462 - loss: 0.5416942238807678\n",
      "Batch 1463 - loss: 0.527746856212616\n",
      "Batch 1464 - loss: 0.5958124995231628\n",
      "Batch 1465 - loss: 0.547306478023529\n",
      "Batch 1466 - loss: 0.5334286689758301\n",
      "Batch 1467 - loss: 0.5686372518539429\n",
      "Batch 1468 - loss: 0.5255377292633057\n",
      "Batch 1469 - loss: 0.5514090061187744\n",
      "Batch 1470 - loss: 0.5124257802963257\n",
      "Batch 1471 - loss: 0.5456468462944031\n",
      "Batch 1472 - loss: 0.5720310211181641\n",
      "Batch 1473 - loss: 0.5361295342445374\n",
      "Batch 1474 - loss: 0.5074185132980347\n",
      "Batch 1475 - loss: 0.5430559515953064\n",
      "Batch 1476 - loss: 0.5297247767448425\n",
      "Batch 1477 - loss: 0.5473437309265137\n",
      "Batch 1478 - loss: 0.5561356544494629\n",
      "Batch 1479 - loss: 0.5527979731559753\n",
      "Batch 1480 - loss: 0.5532505512237549\n",
      "Batch 1481 - loss: 0.5441328287124634\n",
      "Batch 1482 - loss: 0.5421308875083923\n",
      "Batch 1483 - loss: 0.6265581846237183\n",
      "Batch 1484 - loss: 0.5568650960922241\n",
      "Batch 1485 - loss: 0.5351874232292175\n",
      "Batch 1486 - loss: 0.5385579466819763\n",
      "Batch 1487 - loss: 0.5419700145721436\n",
      "Batch 1488 - loss: 0.5585858821868896\n",
      "Batch 1489 - loss: 0.6206462383270264\n",
      "Batch 1490 - loss: 0.4788830578327179\n",
      "Batch 1491 - loss: 0.48706603050231934\n",
      "Batch 1492 - loss: 0.6225141882896423\n",
      "Batch 1493 - loss: 0.5585513710975647\n",
      "Batch 1494 - loss: 0.6016204357147217\n",
      "Batch 1495 - loss: 0.6137131452560425\n",
      "Batch 1496 - loss: 0.5392999053001404\n",
      "Batch 1497 - loss: 0.521180272102356\n",
      "Batch 1498 - loss: 0.6012250185012817\n",
      "Batch 1499 - loss: 0.5573033690452576\n",
      "Batch 1500 - loss: 0.5546255111694336\n",
      "Batch 1501 - loss: 0.5804952383041382\n",
      "Batch 1502 - loss: 0.5661420822143555\n",
      "Batch 1503 - loss: 0.5242927670478821\n",
      "Batch 1504 - loss: 0.5244638323783875\n",
      "Batch 1505 - loss: 0.5187469720840454\n",
      "Batch 1506 - loss: 0.5202592015266418\n",
      "Batch 1507 - loss: 0.5106608271598816\n",
      "Batch 1508 - loss: 0.5108612775802612\n",
      "Batch 1509 - loss: 0.5648223757743835\n",
      "Batch 1510 - loss: 0.5530379414558411\n",
      "Batch 1511 - loss: 0.6924031376838684\n",
      "Batch 1512 - loss: 0.5269462466239929\n",
      "Batch 1513 - loss: 0.5927435755729675\n",
      "Batch 1514 - loss: 0.524491012096405\n",
      "Batch 1515 - loss: 0.5859589576721191\n",
      "Batch 1516 - loss: 0.576109766960144\n",
      "Batch 1517 - loss: 0.5476763248443604\n",
      "Batch 1518 - loss: 0.5890792608261108\n",
      "Batch 1519 - loss: 0.5670551061630249\n",
      "Batch 1520 - loss: 0.5760336518287659\n",
      "Batch 1521 - loss: 0.5286744832992554\n",
      "Batch 1522 - loss: 0.520041286945343\n",
      "Batch 1523 - loss: 0.5597072243690491\n",
      "Batch 1524 - loss: 0.5119406580924988\n",
      "Batch 1525 - loss: 0.5675626993179321\n",
      "Batch 1526 - loss: 0.5325531959533691\n",
      "Batch 1527 - loss: 0.5562214255332947\n",
      "Batch 1528 - loss: 0.6275556683540344\n",
      "Batch 1529 - loss: 0.5650854706764221\n",
      "Batch 1530 - loss: 0.6202157735824585\n",
      "Batch 1531 - loss: 0.49186161160469055\n",
      "Batch 1532 - loss: 0.5484143495559692\n",
      "Batch 1533 - loss: 0.4910615384578705\n",
      "Batch 1534 - loss: 0.5531272292137146\n",
      "Batch 1535 - loss: 0.5555367469787598\n",
      "Batch 1536 - loss: 0.49605226516723633\n",
      "Batch 1537 - loss: 0.5636079907417297\n",
      "Batch 1538 - loss: 0.5735981464385986\n",
      "Batch 1539 - loss: 0.5373116731643677\n",
      "Batch 1540 - loss: 0.5263883471488953\n",
      "Batch 1541 - loss: 0.5528161525726318\n",
      "Batch 1542 - loss: 0.6253570914268494\n",
      "Batch 1543 - loss: 0.5298042893409729\n",
      "Batch 1544 - loss: 0.5780653953552246\n",
      "Batch 1545 - loss: 0.5439192652702332\n",
      "Batch 1546 - loss: 0.5496942400932312\n",
      "Batch 1547 - loss: 0.5694273114204407\n",
      "Batch 1548 - loss: 0.5486804842948914\n",
      "Batch 1549 - loss: 0.5272232890129089\n",
      "Batch 1550 - loss: 0.5300387144088745\n",
      "Batch 1551 - loss: 0.5705901384353638\n",
      "Batch 1552 - loss: 0.5493858456611633\n",
      "Batch 1553 - loss: 0.5340049862861633\n",
      "Batch 1554 - loss: 0.49947887659072876\n",
      "Batch 1555 - loss: 0.6101822257041931\n",
      "Batch 1556 - loss: 0.6131342649459839\n",
      "Batch 1557 - loss: 0.543768584728241\n",
      "Batch 1558 - loss: 0.49553409218788147\n",
      "Batch 1559 - loss: 0.5922513604164124\n",
      "Batch 1560 - loss: 0.5485053658485413\n",
      "Batch 1561 - loss: 0.5312011241912842\n",
      "Batch 1562 - loss: 0.5570834279060364\n",
      "Batch 1563 - loss: 0.6193050742149353\n",
      "Batch 1564 - loss: 0.5912082195281982\n",
      "Batch 1565 - loss: 0.5701481103897095\n",
      "Batch 1566 - loss: 0.5325796008110046\n",
      "Batch 1567 - loss: 0.5730655789375305\n",
      "Batch 1568 - loss: 0.5072950720787048\n",
      "Batch 1569 - loss: 0.5389643311500549\n",
      "Batch 1570 - loss: 0.540027916431427\n",
      "Batch 1571 - loss: 0.6347527503967285\n",
      "Batch 1572 - loss: 0.5347478985786438\n",
      "Batch 1573 - loss: 0.5154293775558472\n",
      "Batch 1574 - loss: 0.5640208125114441\n",
      "Batch 1575 - loss: 0.5187776684761047\n",
      "Batch 1576 - loss: 0.5782322883605957\n",
      "Batch 1577 - loss: 0.5390356183052063\n",
      "Batch 1578 - loss: 0.5195847749710083\n",
      "Batch 1579 - loss: 0.5806045532226562\n",
      "Batch 1580 - loss: 0.6081755757331848\n",
      "Batch 1581 - loss: 0.5942692160606384\n",
      "Batch 1582 - loss: 0.5793725848197937\n",
      "Batch 1583 - loss: 0.4822802245616913\n",
      "Batch 1584 - loss: 0.5128658413887024\n",
      "Batch 1585 - loss: 0.5104381442070007\n",
      "Batch 1586 - loss: 0.5806127190589905\n",
      "Batch 1587 - loss: 0.5089735388755798\n",
      "Batch 1588 - loss: 0.5150920152664185\n",
      "Batch 1589 - loss: 0.5755053162574768\n",
      "Batch 1590 - loss: 0.5043786764144897\n",
      "Batch 1591 - loss: 0.5385613441467285\n",
      "Batch 1592 - loss: 0.5509401559829712\n",
      "Batch 1593 - loss: 0.6352022290229797\n",
      "Batch 1594 - loss: 0.6075968742370605\n",
      "Batch 1595 - loss: 0.5240114331245422\n",
      "Batch 1596 - loss: 0.49826711416244507\n",
      "Batch 1597 - loss: 0.5723523497581482\n",
      "Batch 1598 - loss: 0.5917782783508301\n",
      "Batch 1599 - loss: 0.5860365629196167\n",
      "Batch 1600 - loss: 0.5149328112602234\n",
      "Batch 1601 - loss: 0.5666053891181946\n",
      "Batch 1602 - loss: 0.5272483825683594\n",
      "Batch 1603 - loss: 0.5633559823036194\n",
      "Batch 1604 - loss: 0.5595462918281555\n",
      "Batch 1605 - loss: 0.5710881948471069\n",
      "Batch 1606 - loss: 0.5219733715057373\n",
      "Batch 1607 - loss: 0.5755884051322937\n",
      "Batch 1608 - loss: 0.5978870391845703\n",
      "Batch 1609 - loss: 0.5885878205299377\n",
      "Batch 1610 - loss: 0.608796238899231\n",
      "Batch 1611 - loss: 0.574684202671051\n",
      "Batch 1612 - loss: 0.5634590983390808\n",
      "Batch 1613 - loss: 0.5483300089836121\n",
      "Batch 1614 - loss: 0.51713627576828\n",
      "Batch 1615 - loss: 0.5360455513000488\n",
      "Batch 1616 - loss: 0.5235625505447388\n",
      "Batch 1617 - loss: 0.5220134854316711\n",
      "Batch 1618 - loss: 0.5081062316894531\n",
      "Batch 1619 - loss: 0.5344832539558411\n",
      "Batch 1620 - loss: 0.5367791056632996\n",
      "Batch 1621 - loss: 0.6307492852210999\n",
      "Batch 1622 - loss: 0.559677243232727\n",
      "Batch 1623 - loss: 0.5335613489151001\n",
      "Batch 1624 - loss: 0.5611974000930786\n",
      "Batch 1625 - loss: 0.5374768376350403\n",
      "Batch 1626 - loss: 0.5724992156028748\n",
      "Batch 1627 - loss: 0.5384371876716614\n",
      "Batch 1628 - loss: 0.5342220067977905\n",
      "Batch 1629 - loss: 0.5653277635574341\n",
      "Batch 1630 - loss: 0.5896516442298889\n",
      "Batch 1631 - loss: 0.5402347445487976\n",
      "Batch 1632 - loss: 0.5827744603157043\n",
      "Batch 1633 - loss: 0.5278947353363037\n",
      "Batch 1634 - loss: 0.5864661335945129\n",
      "Batch 1635 - loss: 0.49673035740852356\n",
      "Batch 1636 - loss: 0.4833242893218994\n",
      "Batch 1637 - loss: 0.5966713428497314\n",
      "Batch 1638 - loss: 0.555557131767273\n",
      "Batch 1639 - loss: 0.5218919515609741\n",
      "Batch 1640 - loss: 0.5486939549446106\n",
      "Batch 1641 - loss: 0.5116834044456482\n",
      "Batch 1642 - loss: 0.553375244140625\n",
      "Batch 1643 - loss: 0.6324054598808289\n",
      "Batch 1644 - loss: 0.5374318957328796\n",
      "Batch 1645 - loss: 0.592953085899353\n",
      "Batch 1646 - loss: 0.5210050344467163\n",
      "Batch 1647 - loss: 0.5452623963356018\n",
      "Batch 1648 - loss: 0.4664730429649353\n",
      "Batch 1649 - loss: 0.5779552459716797\n",
      "Batch 1650 - loss: 0.5726567506790161\n",
      "Batch 1651 - loss: 0.5294254422187805\n",
      "Batch 1652 - loss: 0.5492360591888428\n",
      "Batch 1653 - loss: 0.5413369536399841\n",
      "Batch 1654 - loss: 0.4840640127658844\n",
      "Batch 1655 - loss: 0.6028743982315063\n",
      "Batch 1656 - loss: 0.575093686580658\n",
      "Batch 1657 - loss: 0.5479537844657898\n",
      "Batch 1658 - loss: 0.5591534972190857\n",
      "Batch 1659 - loss: 0.5554693341255188\n",
      "Batch 1660 - loss: 0.6480041742324829\n",
      "Batch 1661 - loss: 0.49834656715393066\n",
      "Batch 1662 - loss: 0.5248229503631592\n",
      "Batch 1663 - loss: 0.5803144574165344\n",
      "Batch 1664 - loss: 0.5491611361503601\n",
      "Batch 1665 - loss: 0.5066637992858887\n",
      "Batch 1666 - loss: 0.5455596446990967\n",
      "Batch 1667 - loss: 0.7437573075294495\n",
      "Batch 1668 - loss: 0.5784645676612854\n",
      "Batch 1669 - loss: 0.506669819355011\n",
      "Batch 1670 - loss: 0.5415371656417847\n",
      "Batch 1671 - loss: 0.5573877096176147\n",
      "Batch 1672 - loss: 0.5880546569824219\n",
      "Batch 1673 - loss: 0.5589818954467773\n",
      "Batch 1674 - loss: 0.5438671112060547\n",
      "Batch 1675 - loss: 0.5119633078575134\n",
      "Batch 1676 - loss: 0.5182207822799683\n",
      "Batch 1677 - loss: 0.5401307940483093\n",
      "Batch 1678 - loss: 0.5539276003837585\n",
      "Batch 1679 - loss: 0.5589802265167236\n",
      "Batch 1680 - loss: 0.609859824180603\n",
      "Batch 1681 - loss: 0.5591972470283508\n",
      "Batch 1682 - loss: 0.5318198800086975\n",
      "Batch 1683 - loss: 0.5439022183418274\n",
      "Batch 1684 - loss: 0.5588075518608093\n",
      "Batch 1685 - loss: 0.5560413002967834\n",
      "Batch 1686 - loss: 0.6276112198829651\n",
      "Batch 1687 - loss: 0.53372722864151\n",
      "Batch 1688 - loss: 0.5064486265182495\n",
      "Batch 1689 - loss: 0.556972086429596\n",
      "Batch 1690 - loss: 0.475557416677475\n",
      "Batch 1691 - loss: 0.6070986986160278\n",
      "Batch 1692 - loss: 0.5206199884414673\n",
      "Batch 1693 - loss: 0.5562477707862854\n",
      "Batch 1694 - loss: 0.514097273349762\n",
      "Batch 1695 - loss: 0.609015941619873\n",
      "Batch 1696 - loss: 0.5703530311584473\n",
      "Batch 1697 - loss: 0.5183075666427612\n",
      "Batch 1698 - loss: 0.5596210360527039\n",
      "Batch 1699 - loss: 0.5520049929618835\n",
      "Batch 1700 - loss: 0.49109092354774475\n",
      "Batch 1701 - loss: 0.5807249546051025\n",
      "Batch 1702 - loss: 0.5836349725723267\n",
      "Batch 1703 - loss: 0.5378568172454834\n",
      "Batch 1704 - loss: 0.5001618266105652\n",
      "Batch 1705 - loss: 0.4952714741230011\n",
      "Batch 1706 - loss: 0.5296813249588013\n",
      "Batch 1707 - loss: 0.5098605751991272\n",
      "Batch 1708 - loss: 0.5874937772750854\n",
      "Batch 1709 - loss: 0.5180209279060364\n",
      "Batch 1710 - loss: 0.5856840014457703\n",
      "Batch 1711 - loss: 0.596267819404602\n",
      "Batch 1712 - loss: 0.563062310218811\n",
      "Batch 1713 - loss: 0.5688109993934631\n",
      "Batch 1714 - loss: 0.6191928386688232\n",
      "Batch 1715 - loss: 0.5131006836891174\n",
      "Batch 1716 - loss: 0.5578365325927734\n",
      "Batch 1717 - loss: 0.493197500705719\n",
      "Batch 1718 - loss: 0.501444399356842\n",
      "Batch 1719 - loss: 0.5311843156814575\n",
      "Batch 1720 - loss: 0.5599401593208313\n",
      "Batch 1721 - loss: 0.5623834133148193\n",
      "Batch 1722 - loss: 0.5174311399459839\n",
      "Batch 1723 - loss: 0.523293137550354\n",
      "Batch 1724 - loss: 0.6129031777381897\n",
      "Batch 1725 - loss: 0.556232750415802\n",
      "Batch 1726 - loss: 0.5540717840194702\n",
      "Batch 1727 - loss: 0.5828732252120972\n",
      "Batch 1728 - loss: 0.5279548764228821\n",
      "Batch 1729 - loss: 0.5578393936157227\n",
      "Batch 1730 - loss: 0.5338575839996338\n",
      "Batch 1731 - loss: 0.5190962553024292\n",
      "Batch 1732 - loss: 0.5406988859176636\n",
      "Batch 1733 - loss: 0.5378701686859131\n",
      "Batch 1734 - loss: 0.5508924126625061\n",
      "Batch 1735 - loss: 0.6000416874885559\n",
      "Batch 1736 - loss: 0.6117196083068848\n",
      "Batch 1737 - loss: 0.5042781233787537\n",
      "Batch 1738 - loss: 0.4988550543785095\n",
      "Batch 1739 - loss: 0.5861598253250122\n",
      "Batch 1740 - loss: 0.5334442257881165\n",
      "Batch 1741 - loss: 0.5529633164405823\n",
      "Batch 1742 - loss: 0.5754843354225159\n",
      "Batch 1743 - loss: 0.5727237462997437\n",
      "Batch 1744 - loss: 0.5652273297309875\n",
      "Batch 1745 - loss: 0.5608485341072083\n",
      "Batch 1746 - loss: 0.5931615829467773\n",
      "Batch 1747 - loss: 0.5654508471488953\n",
      "Batch 1748 - loss: 0.5540173053741455\n",
      "Batch 1749 - loss: 0.5544213056564331\n",
      "Batch 1750 - loss: 0.491417795419693\n",
      "Batch 1751 - loss: 0.5071302652359009\n",
      "Batch 1752 - loss: 0.5998737812042236\n",
      "Batch 1753 - loss: 0.5392411947250366\n",
      "Batch 1754 - loss: 0.5978280305862427\n",
      "Batch 1755 - loss: 0.5359328389167786\n",
      "Batch 1756 - loss: 0.5519267916679382\n",
      "Batch 1757 - loss: 0.4915013015270233\n",
      "Batch 1758 - loss: 0.529105007648468\n",
      "Batch 1759 - loss: 0.49815961718559265\n",
      "Batch 1760 - loss: 0.5692146420478821\n",
      "Batch 1761 - loss: 0.616840124130249\n",
      "Batch 1762 - loss: 0.5963341593742371\n",
      "Batch 1763 - loss: 0.5361590385437012\n",
      "Batch 1764 - loss: 0.6026414036750793\n",
      "Batch 1765 - loss: 0.549187183380127\n",
      "Batch 1766 - loss: 0.4979515075683594\n",
      "Batch 1767 - loss: 0.5605088472366333\n",
      "Batch 1768 - loss: 0.5851670503616333\n",
      "Batch 1769 - loss: 0.523966908454895\n",
      "Batch 1770 - loss: 0.5359242558479309\n",
      "Batch 1771 - loss: 0.5116618275642395\n",
      "Batch 1772 - loss: 0.5043675899505615\n",
      "Batch 1773 - loss: 0.48053690791130066\n",
      "Batch 1774 - loss: 0.571118950843811\n",
      "Batch 1775 - loss: 0.5312083959579468\n",
      "Batch 1776 - loss: 0.5476778745651245\n",
      "Batch 1777 - loss: 0.47687554359436035\n",
      "Batch 1778 - loss: 0.5366500020027161\n",
      "Batch 1779 - loss: 0.5830138325691223\n",
      "Batch 1780 - loss: 0.5166993737220764\n",
      "Batch 1781 - loss: 0.5505757927894592\n",
      "Batch 1782 - loss: 0.529725968837738\n",
      "Batch 1783 - loss: 0.5911835432052612\n",
      "Batch 1784 - loss: 0.5247659683227539\n",
      "Batch 1785 - loss: 0.571164608001709\n",
      "Batch 1786 - loss: 0.585173487663269\n",
      "Batch 1787 - loss: 0.5714386701583862\n",
      "Batch 1788 - loss: 0.5667925477027893\n",
      "Batch 1789 - loss: 0.5707446336746216\n",
      "Batch 1790 - loss: 0.55594801902771\n",
      "Batch 1791 - loss: 0.5274040102958679\n",
      "Batch 1792 - loss: 0.5603304505348206\n",
      "Batch 1793 - loss: 0.5672922134399414\n",
      "Batch 1794 - loss: 0.49171826243400574\n",
      "Batch 1795 - loss: 0.6112936735153198\n",
      "Batch 1796 - loss: 0.5770569443702698\n",
      "Batch 1797 - loss: 0.5974878668785095\n",
      "Batch 1798 - loss: 0.49345433712005615\n",
      "Batch 1799 - loss: 0.5630097985267639\n",
      "Batch 1800 - loss: 0.5628607273101807\n",
      "Batch 1801 - loss: 0.5990604758262634\n",
      "Batch 1802 - loss: 0.533759355545044\n",
      "Batch 1803 - loss: 0.5281175971031189\n",
      "Batch 1804 - loss: 0.4897962212562561\n",
      "Batch 1805 - loss: 0.5424925684928894\n",
      "Batch 1806 - loss: 0.5570176839828491\n",
      "Batch 1807 - loss: 0.5019921064376831\n",
      "Batch 1808 - loss: 0.5294631123542786\n",
      "Batch 1809 - loss: 0.49974343180656433\n",
      "Batch 1810 - loss: 0.5174441933631897\n",
      "Batch 1811 - loss: 0.5208885073661804\n",
      "Batch 1812 - loss: 0.5518258213996887\n",
      "Batch 1813 - loss: 0.5462087988853455\n",
      "Batch 1814 - loss: 0.5746759176254272\n",
      "Batch 1815 - loss: 0.5506865978240967\n",
      "Batch 1816 - loss: 0.5911524891853333\n",
      "Batch 1817 - loss: 0.49418777227401733\n",
      "Batch 1818 - loss: 0.5160232186317444\n",
      "Batch 1819 - loss: 0.5875421166419983\n",
      "Batch 1820 - loss: 0.5466941595077515\n",
      "Batch 1821 - loss: 0.5201782584190369\n",
      "Batch 1822 - loss: 0.6024779677391052\n",
      "Batch 1823 - loss: 0.5523563027381897\n",
      "Batch 1824 - loss: 0.5661712884902954\n",
      "Batch 1825 - loss: 0.6011207103729248\n",
      "Batch 1826 - loss: 0.5426366329193115\n",
      "Batch 1827 - loss: 0.5117392539978027\n",
      "Batch 1828 - loss: 0.6029446125030518\n",
      "Batch 1829 - loss: 0.5424076318740845\n",
      "Batch 1830 - loss: 0.4923684895038605\n",
      "Batch 1831 - loss: 0.5304974317550659\n",
      "Batch 1832 - loss: 0.5061373710632324\n",
      "Batch 1833 - loss: 0.6370229721069336\n",
      "Batch 1834 - loss: 0.5235247611999512\n",
      "Batch 1835 - loss: 0.5443893074989319\n",
      "Batch 1836 - loss: 0.5934345722198486\n",
      "Batch 1837 - loss: 0.5464083552360535\n",
      "Batch 1838 - loss: 0.49593210220336914\n",
      "Batch 1839 - loss: 0.5158734917640686\n",
      "Batch 1840 - loss: 0.5049277544021606\n",
      "Batch 1841 - loss: 0.5769323110580444\n",
      "Batch 1842 - loss: 0.5241768956184387\n",
      "Batch 1843 - loss: 0.45980995893478394\n",
      "Batch 1844 - loss: 0.6395663022994995\n",
      "Batch 1845 - loss: 0.5163981318473816\n",
      "Batch 1846 - loss: 0.605270266532898\n",
      "Batch 1847 - loss: 0.546597957611084\n",
      "Batch 1848 - loss: 0.545285165309906\n",
      "Batch 1849 - loss: 0.5766317844390869\n",
      "Batch 1850 - loss: 0.5407838821411133\n",
      "Batch 1851 - loss: 0.573485255241394\n",
      "Batch 1852 - loss: 0.5202586054801941\n",
      "Batch 1853 - loss: 0.541131317615509\n",
      "Batch 1854 - loss: 0.5511336922645569\n",
      "Batch 1855 - loss: 0.5395090579986572\n",
      "Batch 1856 - loss: 0.5330610871315002\n",
      "Batch 1857 - loss: 0.5140706896781921\n",
      "Batch 1858 - loss: 0.5601869225502014\n",
      "Batch 1859 - loss: 0.5579792857170105\n",
      "Batch 1860 - loss: 0.5566060543060303\n",
      "Batch 1861 - loss: 0.5292943716049194\n",
      "Batch 1862 - loss: 0.5659874081611633\n",
      "Batch 1863 - loss: 0.6163751482963562\n",
      "Batch 1864 - loss: 0.5090508460998535\n",
      "Batch 1865 - loss: 0.5719934105873108\n",
      "Batch 1866 - loss: 0.5507832169532776\n",
      "Batch 1867 - loss: 0.5589708089828491\n",
      "Batch 1868 - loss: 0.5191146731376648\n",
      "Batch 1869 - loss: 0.5022871494293213\n",
      "Batch 1870 - loss: 0.5145826935768127\n",
      "Batch 1871 - loss: 0.5665648579597473\n",
      "Batch 1872 - loss: 0.5019742250442505\n",
      "Batch 1873 - loss: 0.5350733399391174\n",
      "Batch 1874 - loss: 0.5244739651679993\n",
      "Batch 1875 - loss: 0.5835918188095093\n",
      "Batch 1876 - loss: 0.5439665913581848\n",
      "Batch 1877 - loss: 0.5579411387443542\n",
      "Batch 1878 - loss: 0.5456954836845398\n",
      "Batch 1879 - loss: 0.5161609649658203\n",
      "Batch 1880 - loss: 0.5381806492805481\n",
      "Batch 1881 - loss: 0.596871554851532\n",
      "Batch 1882 - loss: 0.5226700305938721\n",
      "Batch 1883 - loss: 0.5242869257926941\n",
      "Batch 1884 - loss: 0.5355933904647827\n",
      "Batch 1885 - loss: 0.5433476567268372\n",
      "Batch 1886 - loss: 0.4958202838897705\n",
      "Batch 1887 - loss: 0.5859182476997375\n",
      "Batch 1888 - loss: 0.5532580614089966\n",
      "Batch 1889 - loss: 0.5200129151344299\n",
      "Batch 1890 - loss: 0.5160093903541565\n",
      "Batch 1891 - loss: 0.5593516826629639\n",
      "Batch 1892 - loss: 0.5150864720344543\n",
      "Batch 1893 - loss: 0.5496634840965271\n",
      "Batch 1894 - loss: 0.5654711723327637\n",
      "Batch 1895 - loss: 0.568046510219574\n",
      "Batch 1896 - loss: 0.588031530380249\n",
      "Batch 1897 - loss: 0.5499382615089417\n",
      "Batch 1898 - loss: 0.5823956727981567\n",
      "Batch 1899 - loss: 0.561169445514679\n",
      "Batch 1900 - loss: 0.5178551077842712\n",
      "Batch 1901 - loss: 0.5467641949653625\n",
      "Batch 1902 - loss: 0.521358072757721\n",
      "Batch 1903 - loss: 0.5301867723464966\n",
      "Batch 1904 - loss: 0.5800603032112122\n",
      "Batch 1905 - loss: 0.5982702374458313\n",
      "Batch 1906 - loss: 0.562930166721344\n",
      "Batch 1907 - loss: 0.560110867023468\n",
      "Batch 1908 - loss: 0.496124267578125\n",
      "Batch 1909 - loss: 0.5013156533241272\n",
      "Batch 1910 - loss: 0.5654088854789734\n",
      "Batch 1911 - loss: 0.6077449917793274\n",
      "Batch 1912 - loss: 0.5830051898956299\n",
      "Batch 1913 - loss: 0.6053601503372192\n",
      "Batch 1914 - loss: 0.6112514734268188\n",
      "Batch 1915 - loss: 0.5843507647514343\n",
      "Batch 1916 - loss: 0.5067356824874878\n",
      "Batch 1917 - loss: 0.5406833291053772\n",
      "Batch 1918 - loss: 0.542151927947998\n",
      "Batch 1919 - loss: 0.5812573432922363\n",
      "Batch 1920 - loss: 0.5732713937759399\n",
      "Batch 1921 - loss: 0.524208128452301\n",
      "Batch 1922 - loss: 0.47969311475753784\n",
      "Batch 1923 - loss: 0.5075894594192505\n",
      "Batch 1924 - loss: 0.5195072889328003\n",
      "Batch 1925 - loss: 0.5735589861869812\n",
      "Batch 1926 - loss: 0.536186158657074\n",
      "Batch 1927 - loss: 0.5513626337051392\n",
      "Batch 1928 - loss: 0.5539637207984924\n",
      "Batch 1929 - loss: 0.5970789790153503\n",
      "Batch 1930 - loss: 0.48490089178085327\n",
      "Batch 1931 - loss: 0.566795289516449\n",
      "Batch 1932 - loss: 0.5476214289665222\n",
      "Batch 1933 - loss: 0.5968803763389587\n",
      "Batch 1934 - loss: 0.5481916069984436\n",
      "Batch 1935 - loss: 0.5332802534103394\n",
      "Batch 1936 - loss: 0.5184193849563599\n",
      "Batch 1937 - loss: 0.5874714255332947\n",
      "Batch 1938 - loss: 0.5726031064987183\n",
      "Batch 1939 - loss: 0.5769627690315247\n",
      "Batch 1940 - loss: 0.5642527341842651\n",
      "Batch 1941 - loss: 0.596373438835144\n",
      "Batch 1942 - loss: 0.622817873954773\n",
      "Batch 1943 - loss: 0.5203551650047302\n",
      "Batch 1944 - loss: 0.5904244184494019\n",
      "Batch 1945 - loss: 0.5880454182624817\n",
      "Batch 1946 - loss: 0.5574048161506653\n",
      "Batch 1947 - loss: 0.559843122959137\n",
      "Batch 1948 - loss: 0.5474730134010315\n",
      "Batch 1949 - loss: 0.568917989730835\n",
      "Batch 1950 - loss: 0.5495748519897461\n",
      "Batch 1951 - loss: 0.6228018403053284\n",
      "Batch 1952 - loss: 0.5626254677772522\n",
      "Batch 1953 - loss: 0.56490558385849\n",
      "Batch 1954 - loss: 0.5474660992622375\n",
      "Batch 1955 - loss: 0.4658007323741913\n",
      "Batch 1956 - loss: 0.6139492392539978\n",
      "Batch 1957 - loss: 0.5635325908660889\n",
      "Batch 1958 - loss: 0.4888291358947754\n",
      "Batch 1959 - loss: 0.5440502166748047\n",
      "Batch 1960 - loss: 0.5765218734741211\n",
      "Batch 1961 - loss: 0.5187302827835083\n",
      "Batch 1962 - loss: 0.5044671297073364\n",
      "Batch 1963 - loss: 0.5400453209877014\n",
      "Batch 1964 - loss: 0.5719875693321228\n",
      "Batch 1965 - loss: 0.48832401633262634\n",
      "Batch 1966 - loss: 0.5449264049530029\n",
      "Batch 1967 - loss: 0.49512508511543274\n",
      "Batch 1968 - loss: 0.6066119074821472\n",
      "Batch 1969 - loss: 0.5799459218978882\n",
      "Batch 1970 - loss: 0.5908064842224121\n",
      "Batch 1971 - loss: 0.5162899494171143\n",
      "Batch 1972 - loss: 0.4805748164653778\n",
      "Batch 1973 - loss: 0.4901905655860901\n",
      "Batch 1974 - loss: 0.5371237993240356\n",
      "Batch 1975 - loss: 0.5447115898132324\n",
      "Batch 1976 - loss: 0.5652164816856384\n",
      "Batch 1977 - loss: 0.5746238827705383\n",
      "Batch 1978 - loss: 0.5914533138275146\n",
      "Batch 1979 - loss: 0.5685290098190308\n",
      "Batch 1980 - loss: 0.5449371337890625\n",
      "Batch 1981 - loss: 0.5367420315742493\n",
      "Batch 1982 - loss: 0.5507672429084778\n",
      "Batch 1983 - loss: 0.4907047152519226\n",
      "Batch 1984 - loss: 0.5570870637893677\n",
      "Batch 1985 - loss: 0.5242727994918823\n",
      "Batch 1986 - loss: 0.5338097810745239\n",
      "Batch 1987 - loss: 0.5513822436332703\n",
      "Batch 1988 - loss: 0.5302069783210754\n",
      "Batch 1989 - loss: 0.5507124662399292\n",
      "Batch 1990 - loss: 0.582676887512207\n",
      "Batch 1991 - loss: 0.578548789024353\n",
      "Batch 1992 - loss: 0.5121960639953613\n",
      "Batch 1993 - loss: 0.5435071587562561\n",
      "Batch 1994 - loss: 0.573535680770874\n",
      "Batch 1995 - loss: 0.5021785497665405\n",
      "Batch 1996 - loss: 0.5352199077606201\n",
      "Batch 1997 - loss: 0.5261369943618774\n",
      "Batch 1998 - loss: 0.5419686436653137\n",
      "Batch 1999 - loss: 0.5647445917129517\n",
      "Batch 2000 - loss: 0.5121997594833374\n",
      "Batch 2001 - loss: 0.5526555180549622\n",
      "Batch 2002 - loss: 0.5497360229492188\n",
      "Batch 2003 - loss: 0.4865207374095917\n",
      "Batch 2004 - loss: 0.5191000699996948\n",
      "Batch 2005 - loss: 0.5529256463050842\n",
      "Batch 2006 - loss: 0.4858662188053131\n",
      "Batch 2007 - loss: 0.5250037908554077\n",
      "Batch 2008 - loss: 0.609143078327179\n",
      "Batch 2009 - loss: 0.5754407048225403\n",
      "Batch 2010 - loss: 0.5615525841712952\n",
      "Batch 2011 - loss: 0.5510107278823853\n",
      "Batch 2012 - loss: 0.5344303846359253\n",
      "Batch 2013 - loss: 0.5364711284637451\n",
      "Batch 2014 - loss: 0.49908795952796936\n",
      "Batch 2015 - loss: 0.47067129611968994\n",
      "Batch 2016 - loss: 0.4907897710800171\n",
      "Batch 2017 - loss: 0.5438576936721802\n",
      "Batch 2018 - loss: 0.5071093440055847\n",
      "Batch 2019 - loss: 0.5797752737998962\n",
      "Batch 2020 - loss: 0.49105027318000793\n",
      "Batch 2021 - loss: 0.559675931930542\n",
      "Batch 2022 - loss: 0.5448484420776367\n",
      "Batch 2023 - loss: 0.5331359505653381\n",
      "Batch 2024 - loss: 0.559238612651825\n",
      "Batch 2025 - loss: 0.47202667593955994\n",
      "Batch 2026 - loss: 0.6220609545707703\n",
      "Batch 2027 - loss: 0.5313729047775269\n",
      "Batch 2028 - loss: 0.5823403000831604\n",
      "Batch 2029 - loss: 0.5502541661262512\n",
      "Batch 2030 - loss: 0.4984917938709259\n",
      "Batch 2031 - loss: 0.5134665966033936\n",
      "Batch 2032 - loss: 0.58378005027771\n",
      "Batch 2033 - loss: 0.532370388507843\n",
      "Batch 2034 - loss: 0.5049794912338257\n",
      "Batch 2035 - loss: 0.5582861304283142\n",
      "Batch 2036 - loss: 0.5349106192588806\n",
      "Batch 2037 - loss: 0.5323535799980164\n",
      "Batch 2038 - loss: 0.5639699101448059\n",
      "Batch 2039 - loss: 0.5387945175170898\n",
      "Batch 2040 - loss: 0.5716754794120789\n",
      "Batch 2041 - loss: 0.5613591074943542\n",
      "Batch 2042 - loss: 0.5134708285331726\n",
      "Batch 2043 - loss: 0.5382812023162842\n",
      "Batch 2044 - loss: 0.5422775745391846\n",
      "Batch 2045 - loss: 0.5773791670799255\n",
      "Batch 2046 - loss: 0.6041191220283508\n",
      "Batch 2047 - loss: 0.5539771318435669\n",
      "Batch 2048 - loss: 0.6279755234718323\n",
      "Batch 2049 - loss: 0.5090755224227905\n",
      "Batch 2050 - loss: 0.5702791213989258\n",
      "Batch 2051 - loss: 0.5852743983268738\n",
      "Batch 2052 - loss: 0.5419186353683472\n",
      "Batch 2053 - loss: 0.5618086457252502\n",
      "Batch 2054 - loss: 0.5216066241264343\n",
      "Batch 2055 - loss: 0.5893530249595642\n",
      "Batch 2056 - loss: 0.5342382788658142\n",
      "Batch 2057 - loss: 0.5513066649436951\n",
      "Batch 2058 - loss: 0.5328605771064758\n",
      "Batch 2059 - loss: 0.5103431940078735\n",
      "Batch 2060 - loss: 0.5405900478363037\n",
      "Batch 2061 - loss: 0.5829629898071289\n",
      "Batch 2062 - loss: 0.5582902431488037\n",
      "Batch 2063 - loss: 0.5079534649848938\n",
      "Batch 2064 - loss: 0.5944894552230835\n",
      "Batch 2065 - loss: 0.49552473425865173\n",
      "Batch 2066 - loss: 0.5941609740257263\n",
      "Batch 2067 - loss: 0.5460130572319031\n",
      "Batch 2068 - loss: 0.5691954493522644\n",
      "Batch 2069 - loss: 0.5467514395713806\n",
      "Batch 2070 - loss: 0.5260500907897949\n",
      "Batch 2071 - loss: 0.5298992991447449\n",
      "Batch 2072 - loss: 0.5603843331336975\n",
      "Batch 2073 - loss: 0.6245076656341553\n",
      "Batch 2074 - loss: 0.5449395179748535\n",
      "Batch 2075 - loss: 0.4772805869579315\n",
      "Batch 2076 - loss: 0.5279910564422607\n",
      "Batch 2077 - loss: 0.5298089385032654\n",
      "Batch 2078 - loss: 0.5686520934104919\n",
      "Batch 2079 - loss: 0.5671998262405396\n",
      "Batch 2080 - loss: 0.5519106388092041\n",
      "Batch 2081 - loss: 0.5437507629394531\n",
      "Batch 2082 - loss: 0.5473530888557434\n",
      "Batch 2083 - loss: 0.574733555316925\n",
      "Batch 2084 - loss: 0.5418184399604797\n",
      "Batch 2085 - loss: 0.5431807637214661\n",
      "Batch 2086 - loss: 0.5767340660095215\n",
      "Batch 2087 - loss: 0.589854896068573\n",
      "Batch 2088 - loss: 0.509699821472168\n",
      "Batch 2089 - loss: 0.6113154888153076\n",
      "Batch 2090 - loss: 0.532508909702301\n",
      "Batch 2091 - loss: 0.4894798696041107\n",
      "Batch 2092 - loss: 0.5548317432403564\n",
      "Batch 2093 - loss: 0.5326321125030518\n",
      "Batch 2094 - loss: 0.5552363991737366\n",
      "Batch 2095 - loss: 0.5516829490661621\n",
      "Batch 2096 - loss: 0.4940713047981262\n",
      "Batch 2097 - loss: 0.5124385356903076\n",
      "Batch 2098 - loss: 0.5683584809303284\n",
      "Batch 2099 - loss: 0.5397049188613892\n",
      "Batch 2100 - loss: 0.517470121383667\n",
      "Batch 2101 - loss: 0.5199109315872192\n",
      "Batch 2102 - loss: 0.5424896478652954\n",
      "Batch 2103 - loss: 0.5513156652450562\n",
      "Batch 2104 - loss: 0.553534984588623\n",
      "Batch 2105 - loss: 0.5062157511711121\n",
      "Batch 2106 - loss: 0.5232424736022949\n",
      "Batch 2107 - loss: 0.5256171822547913\n",
      "Batch 2108 - loss: 0.528516948223114\n",
      "Batch 2109 - loss: 0.5691652894020081\n",
      "Batch 2110 - loss: 0.48512810468673706\n",
      "Batch 2111 - loss: 0.5472321510314941\n",
      "Batch 2112 - loss: 0.5404057502746582\n",
      "Batch 2113 - loss: 0.5727149844169617\n",
      "Batch 2114 - loss: 0.5777279138565063\n",
      "Batch 2115 - loss: 0.5453919172286987\n",
      "Batch 2116 - loss: 0.5116465091705322\n",
      "Batch 2117 - loss: 0.5428609251976013\n",
      "Batch 2118 - loss: 0.540102481842041\n",
      "Batch 2119 - loss: 0.5041782259941101\n",
      "Batch 2120 - loss: 0.5687337517738342\n",
      "Batch 2121 - loss: 0.5487306118011475\n",
      "Batch 2122 - loss: 0.5773667693138123\n",
      "Batch 2123 - loss: 0.4815969467163086\n",
      "Batch 2124 - loss: 0.4737541973590851\n",
      "Batch 2125 - loss: 0.5258002281188965\n",
      "Batch 2126 - loss: 0.5013370513916016\n",
      "Batch 2127 - loss: 0.5213257670402527\n",
      "Batch 2128 - loss: 0.49505743384361267\n",
      "Batch 2129 - loss: 0.5697540044784546\n",
      "Batch 2130 - loss: 0.5618529319763184\n",
      "Batch 2131 - loss: 0.4709171652793884\n",
      "Batch 2132 - loss: 0.5114964246749878\n",
      "Batch 2133 - loss: 0.5546919107437134\n",
      "Batch 2134 - loss: 0.5218194723129272\n",
      "Batch 2135 - loss: 0.5787025690078735\n",
      "Batch 2136 - loss: 0.5953371524810791\n",
      "Batch 2137 - loss: 0.5597439408302307\n",
      "Batch 2138 - loss: 0.4884568154811859\n",
      "Batch 2139 - loss: 0.5247633457183838\n",
      "Batch 2140 - loss: 0.5346481204032898\n",
      "Batch 2141 - loss: 0.4815933406352997\n",
      "Batch 2142 - loss: 0.5545075535774231\n",
      "Batch 2143 - loss: 0.5264270901679993\n",
      "Batch 2144 - loss: 0.5491308569908142\n",
      "Batch 2145 - loss: 0.6073349118232727\n",
      "Batch 2146 - loss: 0.595517635345459\n",
      "Batch 2147 - loss: 0.5380765199661255\n",
      "Batch 2148 - loss: 0.5964736342430115\n",
      "Batch 2149 - loss: 0.5827072858810425\n",
      "Batch 2150 - loss: 0.5162214040756226\n",
      "Batch 2151 - loss: 0.531743049621582\n",
      "Batch 2152 - loss: 0.5738139152526855\n",
      "Batch 2153 - loss: 0.5342798233032227\n",
      "Batch 2154 - loss: 0.5749656558036804\n",
      "Batch 2155 - loss: 0.5123134255409241\n",
      "Batch 2156 - loss: 0.576360285282135\n",
      "Batch 2157 - loss: 0.5351916551589966\n",
      "Batch 2158 - loss: 0.5570160746574402\n",
      "Batch 2159 - loss: 0.5416865944862366\n",
      "Batch 2160 - loss: 0.5111080408096313\n",
      "Batch 2161 - loss: 0.5117424130439758\n",
      "Batch 2162 - loss: 0.558478832244873\n",
      "Batch 2163 - loss: 0.5020409226417542\n",
      "Batch 2164 - loss: 0.5401894450187683\n",
      "Batch 2165 - loss: 0.5373886823654175\n",
      "Batch 2166 - loss: 0.5339298248291016\n",
      "Batch 2167 - loss: 0.5086880922317505\n",
      "Batch 2168 - loss: 0.5645681023597717\n",
      "Batch 2169 - loss: 0.5681548714637756\n",
      "Batch 2170 - loss: 0.5956894159317017\n",
      "Batch 2171 - loss: 0.5500163435935974\n",
      "Batch 2172 - loss: 0.5836032629013062\n",
      "Batch 2173 - loss: 0.5249207019805908\n",
      "Batch 2174 - loss: 0.518241822719574\n",
      "Batch 2175 - loss: 0.553559422492981\n",
      "Batch 2176 - loss: 0.5331684947013855\n",
      "Batch 2177 - loss: 0.5128546357154846\n",
      "Batch 2178 - loss: 0.5060245394706726\n",
      "Batch 2179 - loss: 0.5490595698356628\n",
      "Batch 2180 - loss: 0.5962290167808533\n",
      "Batch 2181 - loss: 0.5673718452453613\n",
      "Batch 2182 - loss: 0.5204161405563354\n",
      "Batch 2183 - loss: 0.5356547236442566\n",
      "Batch 2184 - loss: 0.49721112847328186\n",
      "Batch 2185 - loss: 0.5521999001502991\n",
      "Batch 2186 - loss: 0.5531925559043884\n",
      "Batch 2187 - loss: 0.5209348201751709\n",
      "Batch 2188 - loss: 0.6039754748344421\n",
      "Batch 2189 - loss: 0.49382737278938293\n",
      "Batch 2190 - loss: 0.5033979415893555\n",
      "Batch 2191 - loss: 0.5171160101890564\n",
      "Batch 2192 - loss: 0.6149248480796814\n",
      "Batch 2193 - loss: 0.5272666811943054\n",
      "Batch 2194 - loss: 0.6101772785186768\n",
      "Batch 2195 - loss: 0.5368680953979492\n",
      "Batch 2196 - loss: 0.5234864354133606\n",
      "Batch 2197 - loss: 0.5427379608154297\n",
      "Batch 2198 - loss: 0.5456172823905945\n",
      "Batch 2199 - loss: 0.5614516139030457\n",
      "Batch 2200 - loss: 0.5224199891090393\n",
      "Batch 2201 - loss: 0.5536670088768005\n",
      "Batch 2202 - loss: 0.5432772040367126\n",
      "Batch 2203 - loss: 0.6057206988334656\n",
      "Batch 2204 - loss: 0.5759061574935913\n",
      "Batch 2205 - loss: 0.5891062021255493\n",
      "Batch 2206 - loss: 0.494170218706131\n",
      "Batch 2207 - loss: 0.5566464066505432\n",
      "Batch 2208 - loss: 0.5705856084823608\n",
      "Batch 2209 - loss: 0.5613053441047668\n",
      "Batch 2210 - loss: 0.5330820083618164\n",
      "Batch 2211 - loss: 0.497660368680954\n",
      "Batch 2212 - loss: 0.5349743962287903\n",
      "Batch 2213 - loss: 0.5151056051254272\n",
      "Batch 2214 - loss: 0.4846685528755188\n",
      "Batch 2215 - loss: 0.513425886631012\n",
      "Batch 2216 - loss: 0.5475929975509644\n",
      "Batch 2217 - loss: 0.504859209060669\n",
      "Batch 2218 - loss: 0.6125463247299194\n",
      "Batch 2219 - loss: 0.5704602003097534\n",
      "Batch 2220 - loss: 0.5226478576660156\n",
      "Batch 2221 - loss: 0.5640344619750977\n",
      "Batch 2222 - loss: 0.49945202469825745\n",
      "Batch 2223 - loss: 0.5947797298431396\n",
      "Batch 2224 - loss: 0.5576345324516296\n",
      "Batch 2225 - loss: 0.5081458687782288\n",
      "Batch 2226 - loss: 0.47274041175842285\n",
      "Batch 2227 - loss: 0.5486562252044678\n",
      "Batch 2228 - loss: 0.5898266434669495\n",
      "Batch 2229 - loss: 0.5405179262161255\n",
      "Batch 2230 - loss: 0.5823057889938354\n",
      "Batch 2231 - loss: 0.5355259776115417\n",
      "Batch 2232 - loss: 0.5598861575126648\n",
      "Batch 2233 - loss: 0.5531489849090576\n",
      "Batch 2234 - loss: 0.5146397352218628\n",
      "Batch 2235 - loss: 0.5525553226470947\n",
      "Batch 2236 - loss: 0.5835149884223938\n",
      "Batch 2237 - loss: 0.5768572092056274\n",
      "Batch 2238 - loss: 0.4744100570678711\n",
      "Batch 2239 - loss: 0.555019199848175\n",
      "Batch 2240 - loss: 0.4981982409954071\n",
      "Batch 2241 - loss: 0.5252694487571716\n",
      "Batch 2242 - loss: 0.5364193320274353\n",
      "Batch 2243 - loss: 0.5021890997886658\n",
      "Batch 2244 - loss: 0.4884648025035858\n",
      "Batch 2245 - loss: 0.5902863144874573\n",
      "Batch 2246 - loss: 0.5552893280982971\n",
      "Batch 2247 - loss: 0.5389779806137085\n",
      "Batch 2248 - loss: 0.5515299439430237\n",
      "Batch 2249 - loss: 0.5650730729103088\n",
      "Batch 2250 - loss: 0.5628353357315063\n",
      "Batch 2251 - loss: 0.5069006085395813\n",
      "Batch 2252 - loss: 0.5354916453361511\n",
      "Batch 2253 - loss: 0.5825642943382263\n",
      "Batch 2254 - loss: 0.5287411212921143\n",
      "Batch 2255 - loss: 0.5008625984191895\n",
      "Batch 2256 - loss: 0.5805703997612\n",
      "Batch 2257 - loss: 0.5596626400947571\n",
      "Batch 2258 - loss: 0.6036770939826965\n",
      "Batch 2259 - loss: 0.5486088395118713\n",
      "Batch 2260 - loss: 0.5233535766601562\n",
      "Batch 2261 - loss: 0.5366957187652588\n",
      "Batch 2262 - loss: 0.5354887247085571\n",
      "Batch 2263 - loss: 0.5669717192649841\n",
      "Batch 2264 - loss: 0.5423973798751831\n",
      "Batch 2265 - loss: 0.5377665758132935\n",
      "Batch 2266 - loss: 0.5658764243125916\n",
      "Batch 2267 - loss: 0.5451457500457764\n",
      "Batch 2268 - loss: 0.587783932685852\n",
      "Batch 2269 - loss: 0.5787642002105713\n",
      "Batch 2270 - loss: 0.5273776054382324\n",
      "Batch 2271 - loss: 0.5179510712623596\n",
      "Batch 2272 - loss: 0.6014133095741272\n",
      "Batch 2273 - loss: 0.540925920009613\n",
      "Batch 2274 - loss: 0.5437132716178894\n",
      "Batch 2275 - loss: 0.5616309642791748\n",
      "Batch 2276 - loss: 0.6031153202056885\n",
      "Batch 2277 - loss: 0.547798752784729\n",
      "Batch 2278 - loss: 0.5503252148628235\n",
      "Batch 2279 - loss: 0.5407844185829163\n",
      "Batch 2280 - loss: 0.535150408744812\n",
      "Batch 2281 - loss: 0.5417353510856628\n",
      "Batch 2282 - loss: 0.5637496113777161\n",
      "Batch 2283 - loss: 0.5904790759086609\n",
      "Batch 2284 - loss: 0.5333165526390076\n",
      "Batch 2285 - loss: 0.5242975354194641\n",
      "Batch 2286 - loss: 0.5226559042930603\n",
      "Batch 2287 - loss: 0.5954302549362183\n",
      "Batch 2288 - loss: 0.5641993880271912\n",
      "Batch 2289 - loss: 0.5601751804351807\n",
      "Batch 2290 - loss: 0.5469017028808594\n",
      "Batch 2291 - loss: 0.5200437903404236\n",
      "Batch 2292 - loss: 0.6325957775115967\n",
      "Batch 2293 - loss: 0.5522607564926147\n",
      "Batch 2294 - loss: 0.575061559677124\n",
      "Batch 2295 - loss: 0.4980827271938324\n",
      "Batch 2296 - loss: 0.5177412033081055\n",
      "Batch 2297 - loss: 0.5344404578208923\n",
      "Batch 2298 - loss: 0.533839762210846\n",
      "Batch 2299 - loss: 0.586033046245575\n",
      "Batch 2300 - loss: 0.5531467199325562\n",
      "Batch 2301 - loss: 0.599421501159668\n",
      "Batch 2302 - loss: 0.5611364245414734\n",
      "Batch 2303 - loss: 0.5593376159667969\n",
      "Batch 2304 - loss: 0.5164482593536377\n",
      "Batch 2305 - loss: 0.5238133668899536\n",
      "Batch 2306 - loss: 0.580682098865509\n",
      "Batch 2307 - loss: 0.517504096031189\n",
      "Batch 2308 - loss: 0.5233058929443359\n",
      "Batch 2309 - loss: 0.4754959046840668\n",
      "Batch 2310 - loss: 0.5363523960113525\n",
      "Batch 2311 - loss: 0.5258965492248535\n",
      "Batch 2312 - loss: 0.5619993805885315\n",
      "Batch 2313 - loss: 0.5256204605102539\n",
      "Batch 2314 - loss: 0.5735480785369873\n",
      "Batch 2315 - loss: 0.5178958773612976\n",
      "Batch 2316 - loss: 0.5250019431114197\n",
      "Batch 2317 - loss: 0.5325884222984314\n",
      "Batch 2318 - loss: 0.5284698605537415\n",
      "Batch 2319 - loss: 0.5530653595924377\n",
      "Batch 2320 - loss: 0.5175686478614807\n",
      "Batch 2321 - loss: 0.4873961806297302\n",
      "Batch 2322 - loss: 0.5001212954521179\n",
      "Batch 2323 - loss: 0.5713709592819214\n",
      "Batch 2324 - loss: 0.5274376273155212\n",
      "Batch 2325 - loss: 0.5597561001777649\n",
      "Batch 2326 - loss: 0.5780792832374573\n",
      "Batch 2327 - loss: 0.5370946526527405\n",
      "Batch 2328 - loss: 0.497914582490921\n",
      "Batch 2329 - loss: 0.5093660950660706\n",
      "Batch 2330 - loss: 0.6007915735244751\n",
      "Batch 2331 - loss: 0.5336905717849731\n",
      "Batch 2332 - loss: 0.5928645133972168\n",
      "Batch 2333 - loss: 0.5620113611221313\n",
      "Batch 2334 - loss: 0.5137238502502441\n",
      "Batch 2335 - loss: 0.5169767141342163\n",
      "Batch 2336 - loss: 0.5672126412391663\n",
      "Batch 2337 - loss: 0.48801296949386597\n",
      "Batch 2338 - loss: 0.5201424956321716\n",
      "Batch 2339 - loss: 0.4993055462837219\n",
      "Batch 2340 - loss: 0.6060380935668945\n",
      "Batch 2341 - loss: 0.5298381447792053\n",
      "Batch 2342 - loss: 0.5342187285423279\n",
      "Batch 2343 - loss: 0.5405520796775818\n",
      "Batch 2344 - loss: 0.5507025718688965\n",
      "Batch 2345 - loss: 0.5718430876731873\n",
      "Batch 2346 - loss: 0.5038595795631409\n",
      "Batch 2347 - loss: 0.5162814855575562\n",
      "Batch 2348 - loss: 0.5095562934875488\n",
      "Batch 2349 - loss: 0.4344143271446228\n",
      "Batch 2350 - loss: 0.522249162197113\n",
      "Batch 2351 - loss: 0.5787138938903809\n",
      "Batch 2352 - loss: 0.5321798324584961\n",
      "Batch 2353 - loss: 0.5521132946014404\n",
      "Batch 2354 - loss: 0.5475937724113464\n",
      "Batch 2355 - loss: 0.5982924699783325\n",
      "Batch 2356 - loss: 0.5442754030227661\n",
      "Batch 2357 - loss: 0.5457075238227844\n",
      "Batch 2358 - loss: 0.596095860004425\n",
      "Batch 2359 - loss: 0.5763476490974426\n",
      "Batch 2360 - loss: 0.550400972366333\n",
      "Batch 2361 - loss: 0.5922016501426697\n",
      "Batch 2362 - loss: 0.6400641798973083\n",
      "Batch 2363 - loss: 0.5856226086616516\n",
      "Batch 2364 - loss: 0.5482822060585022\n",
      "Batch 2365 - loss: 0.5437650084495544\n",
      "Batch 2366 - loss: 0.5830867290496826\n",
      "Batch 2367 - loss: 0.5440618395805359\n",
      "Batch 2368 - loss: 0.5290435552597046\n",
      "Batch 2369 - loss: 0.6144583225250244\n",
      "Batch 2370 - loss: 0.5261023044586182\n",
      "Batch 2371 - loss: 0.5159327983856201\n",
      "Batch 2372 - loss: 0.512415885925293\n",
      "Batch 2373 - loss: 0.5213249921798706\n",
      "Batch 2374 - loss: 0.49072009325027466\n",
      "Batch 2375 - loss: 0.47965532541275024\n",
      "Batch 2376 - loss: 0.4912971556186676\n",
      "Batch 2377 - loss: 0.4915896952152252\n",
      "Batch 2378 - loss: 0.5405755639076233\n",
      "Batch 2379 - loss: 0.5222406983375549\n",
      "Batch 2380 - loss: 0.5805171132087708\n",
      "Batch 2381 - loss: 0.4811207950115204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214d96939da047429c07d940e0cafb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2382 - loss: 0.4765990972518921\n",
      "Batch 2383 - loss: 0.5179214477539062\n",
      "Batch 2384 - loss: 0.5041874647140503\n",
      "Batch 2385 - loss: 0.5589594841003418\n",
      "Batch 2386 - loss: 0.5680336356163025\n",
      "Batch 2387 - loss: 0.5181052088737488\n",
      "Batch 2388 - loss: 0.479451447725296\n",
      "Batch 2389 - loss: 0.5940275192260742\n",
      "Batch 2390 - loss: 0.5061190128326416\n",
      "Batch 2391 - loss: 0.5206473469734192\n",
      "Batch 2392 - loss: 0.4672353267669678\n",
      "Batch 2393 - loss: 0.505113422870636\n",
      "Batch 2394 - loss: 0.537161111831665\n",
      "Batch 2395 - loss: 0.5180109143257141\n",
      "Batch 2396 - loss: 0.5136030912399292\n",
      "Batch 2397 - loss: 0.5770076513290405\n",
      "Batch 2398 - loss: 0.5166182518005371\n",
      "Batch 2399 - loss: 0.6042413711547852\n",
      "Batch 2400 - loss: 0.5520254373550415\n",
      "Batch 2401 - loss: 0.5340320467948914\n",
      "Batch 2402 - loss: 0.5562171339988708\n",
      "Batch 2403 - loss: 0.5684903860092163\n",
      "Batch 2404 - loss: 0.5726345181465149\n",
      "Batch 2405 - loss: 0.5606154203414917\n",
      "Batch 2406 - loss: 0.49733713269233704\n",
      "Batch 2407 - loss: 0.5516929030418396\n",
      "Batch 2408 - loss: 0.5372164249420166\n",
      "Batch 2409 - loss: 0.50957852602005\n",
      "Batch 2410 - loss: 0.5178287029266357\n",
      "Batch 2411 - loss: 0.5434408187866211\n",
      "Batch 2412 - loss: 0.49377086758613586\n",
      "Batch 2413 - loss: 0.5693339705467224\n",
      "Batch 2414 - loss: 0.5350525975227356\n",
      "Batch 2415 - loss: 0.5750489830970764\n",
      "Batch 2416 - loss: 0.536031186580658\n",
      "Batch 2417 - loss: 0.5180553197860718\n",
      "Batch 2418 - loss: 0.5029780864715576\n",
      "Batch 2419 - loss: 0.4769592583179474\n",
      "Batch 2420 - loss: 0.5204247832298279\n",
      "Batch 2421 - loss: 0.5403329133987427\n",
      "Batch 2422 - loss: 0.5849572420120239\n",
      "Batch 2423 - loss: 0.5403531789779663\n",
      "Batch 2424 - loss: 0.5542253851890564\n",
      "Batch 2425 - loss: 0.5087718963623047\n",
      "Batch 2426 - loss: 0.5927263498306274\n",
      "Batch 2427 - loss: 0.5741124153137207\n",
      "Batch 2428 - loss: 0.4726690351963043\n",
      "Batch 2429 - loss: 0.533324658870697\n",
      "Batch 2430 - loss: 0.4894613027572632\n",
      "Batch 2431 - loss: 0.5369815826416016\n",
      "Batch 2432 - loss: 0.5583996772766113\n",
      "Batch 2433 - loss: 0.5534654259681702\n",
      "Batch 2434 - loss: 0.4841289520263672\n",
      "Batch 2435 - loss: 0.5714089870452881\n",
      "Batch 2436 - loss: 0.5196002721786499\n",
      "Batch 2437 - loss: 0.5351452231407166\n",
      "Batch 2438 - loss: 0.5812473297119141\n",
      "Batch 2439 - loss: 0.5447484850883484\n",
      "Batch 2440 - loss: 0.49486300349235535\n",
      "Batch 2441 - loss: 0.48898032307624817\n",
      "Batch 2442 - loss: 0.604949414730072\n",
      "Batch 2443 - loss: 0.5175701379776001\n",
      "Batch 2444 - loss: 0.5611138343811035\n",
      "Batch 2445 - loss: 0.5252948999404907\n",
      "Batch 2446 - loss: 0.4617157280445099\n",
      "Batch 2447 - loss: 0.5416758060455322\n",
      "Batch 2448 - loss: 0.537350058555603\n",
      "Batch 2449 - loss: 0.49357059597969055\n",
      "Batch 2450 - loss: 0.5801328420639038\n",
      "Batch 2451 - loss: 0.5435531735420227\n",
      "Batch 2452 - loss: 0.5812765955924988\n",
      "Batch 2453 - loss: 0.5060234665870667\n",
      "Batch 2454 - loss: 0.5144637823104858\n",
      "Batch 2455 - loss: 0.5384513735771179\n",
      "Batch 2456 - loss: 0.5257249474525452\n",
      "Batch 2457 - loss: 0.49060484766960144\n",
      "Batch 2458 - loss: 0.6066216230392456\n",
      "Batch 2459 - loss: 0.4834289848804474\n",
      "Batch 2460 - loss: 0.5295875668525696\n",
      "Batch 2461 - loss: 0.5328209400177002\n",
      "Batch 2462 - loss: 0.5063216686248779\n",
      "Batch 2463 - loss: 0.5213998556137085\n",
      "Batch 2464 - loss: 0.5379875302314758\n",
      "Batch 2465 - loss: 0.5402932167053223\n",
      "Batch 2466 - loss: 0.5285108685493469\n",
      "Batch 2467 - loss: 0.546882152557373\n",
      "Batch 2468 - loss: 0.5565320253372192\n",
      "Batch 2469 - loss: 0.534330427646637\n",
      "Batch 2470 - loss: 0.5670047402381897\n",
      "Batch 2471 - loss: 0.6242353320121765\n",
      "Batch 2472 - loss: 0.520245373249054\n",
      "Batch 2473 - loss: 0.5821850895881653\n",
      "Batch 2474 - loss: 0.5919222831726074\n",
      "Batch 2475 - loss: 0.5323060154914856\n",
      "Batch 2476 - loss: 0.5402676463127136\n",
      "Batch 2477 - loss: 0.5165414214134216\n",
      "Batch 2478 - loss: 0.559751570224762\n",
      "Batch 2479 - loss: 0.5720756649971008\n",
      "Batch 2480 - loss: 0.5094448328018188\n",
      "Batch 2481 - loss: 0.5324987173080444\n",
      "Batch 2482 - loss: 0.5208829045295715\n",
      "Batch 2483 - loss: 0.5350491404533386\n",
      "Batch 2484 - loss: 0.5214686393737793\n",
      "Batch 2485 - loss: 0.5328280329704285\n",
      "Batch 2486 - loss: 0.5271669030189514\n",
      "Batch 2487 - loss: 0.504716694355011\n",
      "Batch 2488 - loss: 0.5316031575202942\n",
      "Batch 2489 - loss: 0.5744355320930481\n",
      "Batch 2490 - loss: 0.5400713682174683\n",
      "Batch 2491 - loss: 0.4946427345275879\n",
      "Batch 2492 - loss: 0.5266571044921875\n",
      "Batch 2493 - loss: 0.5258885025978088\n",
      "Batch 2494 - loss: 0.47019466757774353\n",
      "Batch 2495 - loss: 0.5101661682128906\n",
      "Batch 2496 - loss: 0.5697351098060608\n",
      "Batch 2497 - loss: 0.5222689509391785\n",
      "Batch 2498 - loss: 0.558593213558197\n",
      "Batch 2499 - loss: 0.5493999719619751\n",
      "Batch 2500 - loss: 0.5079919695854187\n",
      "Batch 2501 - loss: 0.6428682208061218\n",
      "Batch 2502 - loss: 0.557306706905365\n",
      "Batch 2503 - loss: 0.5381614565849304\n",
      "Batch 2504 - loss: 0.5379098653793335\n",
      "Batch 2505 - loss: 0.5230138897895813\n",
      "Batch 2506 - loss: 0.5097327828407288\n",
      "Batch 2507 - loss: 0.5606117248535156\n",
      "Batch 2508 - loss: 0.5185872912406921\n",
      "Batch 2509 - loss: 0.5188910961151123\n",
      "Batch 2510 - loss: 0.5489687919616699\n",
      "Batch 2511 - loss: 0.544387936592102\n",
      "Batch 2512 - loss: 0.5379355549812317\n",
      "Batch 2513 - loss: 0.5466341972351074\n",
      "Batch 2514 - loss: 0.4783153235912323\n",
      "Batch 2515 - loss: 0.5939489603042603\n",
      "Batch 2516 - loss: 0.5289384126663208\n",
      "Batch 2517 - loss: 0.5073065161705017\n",
      "Batch 2518 - loss: 0.512951672077179\n",
      "Batch 2519 - loss: 0.6020107269287109\n",
      "Batch 2520 - loss: 0.511707603931427\n",
      "Batch 2521 - loss: 0.5388827323913574\n",
      "Batch 2522 - loss: 0.5256420969963074\n",
      "Batch 2523 - loss: 0.519934892654419\n",
      "Batch 2524 - loss: 0.4976944625377655\n",
      "Batch 2525 - loss: 0.492681622505188\n",
      "Batch 2526 - loss: 0.5125715136528015\n",
      "Batch 2527 - loss: 0.5099664330482483\n",
      "Batch 2528 - loss: 0.5500428676605225\n",
      "Batch 2529 - loss: 0.5747511386871338\n",
      "Batch 2530 - loss: 0.6203863620758057\n",
      "Batch 2531 - loss: 0.4996686279773712\n",
      "Batch 2532 - loss: 0.46614572405815125\n",
      "Batch 2533 - loss: 0.5560031533241272\n",
      "Batch 2534 - loss: 0.5763118863105774\n",
      "Batch 2535 - loss: 0.5713593363761902\n",
      "Batch 2536 - loss: 0.6020928025245667\n",
      "Batch 2537 - loss: 0.4974665641784668\n",
      "Batch 2538 - loss: 0.49945542216300964\n",
      "Batch 2539 - loss: 0.5207801461219788\n",
      "Batch 2540 - loss: 0.49512356519699097\n",
      "Batch 2541 - loss: 0.5328317880630493\n",
      "Batch 2542 - loss: 0.5648285746574402\n",
      "Batch 2543 - loss: 0.4899600148200989\n",
      "Batch 2544 - loss: 0.5173562169075012\n",
      "Batch 2545 - loss: 0.523820161819458\n",
      "Batch 2546 - loss: 0.5272732377052307\n",
      "Batch 2547 - loss: 0.4854687750339508\n",
      "Batch 2548 - loss: 0.5197281241416931\n",
      "Batch 2549 - loss: 0.5213323831558228\n",
      "Batch 2550 - loss: 0.5440124869346619\n",
      "Batch 2551 - loss: 0.5527154207229614\n",
      "Batch 2552 - loss: 0.5731459856033325\n",
      "Batch 2553 - loss: 0.5299683213233948\n",
      "Batch 2554 - loss: 0.5339205861091614\n",
      "Batch 2555 - loss: 0.5616656541824341\n",
      "Batch 2556 - loss: 0.5442135334014893\n",
      "Batch 2557 - loss: 0.5503290295600891\n",
      "Batch 2558 - loss: 0.5242827534675598\n",
      "Batch 2559 - loss: 0.6127786636352539\n",
      "Batch 2560 - loss: 0.5496558547019958\n",
      "Batch 2561 - loss: 0.5960078239440918\n",
      "Batch 2562 - loss: 0.5753729939460754\n",
      "Batch 2563 - loss: 0.5384047031402588\n",
      "Batch 2564 - loss: 0.5229708552360535\n",
      "Batch 2565 - loss: 0.5706325769424438\n",
      "Batch 2566 - loss: 0.5193575620651245\n",
      "Batch 2567 - loss: 0.567491888999939\n",
      "Batch 2568 - loss: 0.5186513662338257\n",
      "Batch 2569 - loss: 0.4965420961380005\n",
      "Batch 2570 - loss: 0.5221589207649231\n",
      "Batch 2571 - loss: 0.5273193717002869\n",
      "Batch 2572 - loss: 0.4746835231781006\n",
      "Batch 2573 - loss: 0.6455553770065308\n",
      "Batch 2574 - loss: 0.4805149734020233\n",
      "Batch 2575 - loss: 0.5266239047050476\n",
      "Batch 2576 - loss: 0.4880064129829407\n",
      "Batch 2577 - loss: 0.5330883264541626\n",
      "Batch 2578 - loss: 0.5018967390060425\n",
      "Batch 2579 - loss: 0.5685657858848572\n",
      "Batch 2580 - loss: 0.5286778211593628\n",
      "Batch 2581 - loss: 0.5363553762435913\n",
      "Batch 2582 - loss: 0.5138829946517944\n",
      "Batch 2583 - loss: 0.5553008317947388\n",
      "Batch 2584 - loss: 0.5411578416824341\n",
      "Batch 2585 - loss: 0.5466816425323486\n",
      "Batch 2586 - loss: 0.6200527548789978\n",
      "Batch 2587 - loss: 0.5627747178077698\n",
      "Batch 2588 - loss: 0.5388849973678589\n",
      "Batch 2589 - loss: 0.617891788482666\n",
      "Batch 2590 - loss: 0.5588048100471497\n",
      "Batch 2591 - loss: 0.5111887454986572\n",
      "Batch 2592 - loss: 0.5250717401504517\n",
      "Batch 2593 - loss: 0.46486082673072815\n",
      "Batch 2594 - loss: 0.5115433931350708\n",
      "Batch 2595 - loss: 0.5252222418785095\n",
      "Batch 2596 - loss: 0.5072920322418213\n",
      "Batch 2597 - loss: 0.5715017914772034\n",
      "Batch 2598 - loss: 0.5491287708282471\n",
      "Batch 2599 - loss: 0.5370913147926331\n",
      "Batch 2600 - loss: 0.5131579041481018\n",
      "Batch 2601 - loss: 0.528971254825592\n",
      "Batch 2602 - loss: 0.5255528092384338\n",
      "Batch 2603 - loss: 0.5224282741546631\n",
      "Batch 2604 - loss: 0.5175341963768005\n",
      "Batch 2605 - loss: 0.5318096280097961\n",
      "Batch 2606 - loss: 0.44671115279197693\n",
      "Batch 2607 - loss: 0.5525588393211365\n",
      "Batch 2608 - loss: 0.534602165222168\n",
      "Batch 2609 - loss: 0.550584077835083\n",
      "Batch 2610 - loss: 0.5442396402359009\n",
      "Batch 2611 - loss: 0.5516685247421265\n",
      "Batch 2612 - loss: 0.5114489197731018\n",
      "Batch 2613 - loss: 0.5202060341835022\n",
      "Batch 2614 - loss: 0.49218904972076416\n",
      "Batch 2615 - loss: 0.513164758682251\n",
      "Batch 2616 - loss: 0.5269486308097839\n",
      "Batch 2617 - loss: 0.5745286345481873\n",
      "Batch 2618 - loss: 0.5548675656318665\n",
      "Batch 2619 - loss: 0.4839034080505371\n",
      "Batch 2620 - loss: 0.5249742269515991\n",
      "Batch 2621 - loss: 0.5345118045806885\n",
      "Batch 2622 - loss: 0.5994075536727905\n",
      "Batch 2623 - loss: 0.5596157312393188\n",
      "Batch 2624 - loss: 0.47518688440322876\n",
      "Batch 2625 - loss: 0.5731372237205505\n",
      "Batch 2626 - loss: 0.5534636378288269\n",
      "Batch 2627 - loss: 0.5523568987846375\n",
      "Batch 2628 - loss: 0.49040138721466064\n",
      "Batch 2629 - loss: 0.5425490736961365\n",
      "Batch 2630 - loss: 0.5419082045555115\n",
      "Batch 2631 - loss: 0.4747231602668762\n",
      "Batch 2632 - loss: 0.5367089509963989\n",
      "Batch 2633 - loss: 0.5861322283744812\n",
      "Batch 2634 - loss: 0.5377408266067505\n",
      "Batch 2635 - loss: 0.5557668209075928\n",
      "Batch 2636 - loss: 0.5296960473060608\n",
      "Batch 2637 - loss: 0.5366036295890808\n",
      "Batch 2638 - loss: 0.5105781555175781\n",
      "Batch 2639 - loss: 0.4475739896297455\n",
      "Batch 2640 - loss: 0.5165258646011353\n",
      "Batch 2641 - loss: 0.5465487837791443\n",
      "Batch 2642 - loss: 0.4984535276889801\n",
      "Batch 2643 - loss: 0.5027173757553101\n",
      "Batch 2644 - loss: 0.550066351890564\n",
      "Batch 2645 - loss: 0.4647890329360962\n",
      "Batch 2646 - loss: 0.5642011761665344\n",
      "Batch 2647 - loss: 0.48647522926330566\n",
      "Batch 2648 - loss: 0.5238752961158752\n",
      "Batch 2649 - loss: 0.5509321093559265\n",
      "Batch 2650 - loss: 0.5598030686378479\n",
      "Batch 2651 - loss: 0.5431066751480103\n",
      "Batch 2652 - loss: 0.5681065320968628\n",
      "Batch 2653 - loss: 0.561504065990448\n",
      "Batch 2654 - loss: 0.5113017559051514\n",
      "Batch 2655 - loss: 0.549896240234375\n",
      "Batch 2656 - loss: 0.5620359778404236\n",
      "Batch 2657 - loss: 0.523377537727356\n",
      "Batch 2658 - loss: 0.6006168723106384\n",
      "Batch 2659 - loss: 0.5476522445678711\n",
      "Batch 2660 - loss: 0.6005842089653015\n",
      "Batch 2661 - loss: 0.5932615995407104\n",
      "Batch 2662 - loss: 0.5883863568305969\n",
      "Batch 2663 - loss: 0.547563374042511\n",
      "Batch 2664 - loss: 0.598084032535553\n",
      "Batch 2665 - loss: 0.5474376678466797\n",
      "Batch 2666 - loss: 0.5248190760612488\n",
      "Batch 2667 - loss: 0.535142719745636\n",
      "Batch 2668 - loss: 0.5472354292869568\n",
      "Batch 2669 - loss: 0.5018894672393799\n",
      "Batch 2670 - loss: 0.5093822479248047\n",
      "Batch 2671 - loss: 0.5554396510124207\n",
      "Batch 2672 - loss: 0.48344147205352783\n",
      "Batch 2673 - loss: 0.5320554971694946\n",
      "Batch 2674 - loss: 0.5584920048713684\n",
      "Batch 2675 - loss: 0.49435511231422424\n",
      "Batch 2676 - loss: 0.521801769733429\n",
      "Batch 2677 - loss: 0.5689488649368286\n",
      "Batch 2678 - loss: 0.523073136806488\n",
      "Batch 2679 - loss: 0.4847167730331421\n",
      "Batch 2680 - loss: 0.5195366740226746\n",
      "Batch 2681 - loss: 0.5407307744026184\n",
      "Batch 2682 - loss: 0.5450561046600342\n",
      "Batch 2683 - loss: 0.5743505358695984\n",
      "Batch 2684 - loss: 0.5272558331489563\n",
      "Batch 2685 - loss: 0.5306515693664551\n",
      "Batch 2686 - loss: 0.5540204048156738\n",
      "Batch 2687 - loss: 0.5658566951751709\n",
      "Batch 2688 - loss: 0.5584670901298523\n",
      "Batch 2689 - loss: 0.5713452100753784\n",
      "Batch 2690 - loss: 0.5181635022163391\n",
      "Batch 2691 - loss: 0.5582460165023804\n",
      "Batch 2692 - loss: 0.5159479379653931\n",
      "Batch 2693 - loss: 0.5560031533241272\n",
      "Batch 2694 - loss: 0.5396130084991455\n",
      "Batch 2695 - loss: 0.5411721467971802\n",
      "Batch 2696 - loss: 0.575788676738739\n",
      "Batch 2697 - loss: 0.5447965860366821\n",
      "Batch 2698 - loss: 0.5555610656738281\n",
      "Batch 2699 - loss: 0.5068188309669495\n",
      "Batch 2700 - loss: 0.5413031578063965\n",
      "Batch 2701 - loss: 0.6414953470230103\n",
      "Batch 2702 - loss: 0.5567583441734314\n",
      "Batch 2703 - loss: 0.4889761209487915\n",
      "Batch 2704 - loss: 0.47243499755859375\n",
      "Batch 2705 - loss: 0.5329241752624512\n",
      "Batch 2706 - loss: 0.5394496321678162\n",
      "Batch 2707 - loss: 0.562667191028595\n",
      "Batch 2708 - loss: 0.5582108497619629\n",
      "Batch 2709 - loss: 0.5339322686195374\n",
      "Batch 2710 - loss: 0.5732027888298035\n",
      "Batch 2711 - loss: 0.5593045353889465\n",
      "Batch 2712 - loss: 0.5511206984519958\n",
      "Batch 2713 - loss: 0.5446667075157166\n",
      "Batch 2714 - loss: 0.508734941482544\n",
      "Batch 2715 - loss: 0.5482583045959473\n",
      "Batch 2716 - loss: 0.5298076868057251\n",
      "Batch 2717 - loss: 0.5296326875686646\n",
      "Batch 2718 - loss: 0.6013451218605042\n",
      "Batch 2719 - loss: 0.5505785346031189\n",
      "Batch 2720 - loss: 0.5933787226676941\n",
      "Batch 2721 - loss: 0.6130937933921814\n",
      "Batch 2722 - loss: 0.5300508737564087\n",
      "Batch 2723 - loss: 0.5312062501907349\n",
      "Batch 2724 - loss: 0.5660107135772705\n",
      "Batch 2725 - loss: 0.591048002243042\n",
      "Batch 2726 - loss: 0.537565290927887\n",
      "Batch 2727 - loss: 0.5484076142311096\n",
      "Batch 2728 - loss: 0.5410534739494324\n",
      "Batch 2729 - loss: 0.5163763165473938\n",
      "Batch 2730 - loss: 0.5556774735450745\n",
      "Batch 2731 - loss: 0.5778145790100098\n",
      "Batch 2732 - loss: 0.48886874318122864\n",
      "Batch 2733 - loss: 0.5820236802101135\n",
      "Batch 2734 - loss: 0.4982552230358124\n",
      "Batch 2735 - loss: 0.5463823080062866\n",
      "Batch 2736 - loss: 0.5900330543518066\n",
      "Batch 2737 - loss: 0.5059598088264465\n",
      "Batch 2738 - loss: 0.5328741073608398\n",
      "Batch 2739 - loss: 0.5836248397827148\n",
      "Batch 2740 - loss: 0.5637337565422058\n",
      "Batch 2741 - loss: 0.5307357311248779\n",
      "Batch 2742 - loss: 0.5486017465591431\n",
      "Batch 2743 - loss: 0.4948046803474426\n",
      "Batch 2744 - loss: 0.545790433883667\n",
      "Batch 2745 - loss: 0.5172346234321594\n",
      "Batch 2746 - loss: 0.5270611643791199\n",
      "Batch 2747 - loss: 0.5609359741210938\n",
      "Batch 2748 - loss: 0.5262599587440491\n",
      "Batch 2749 - loss: 0.5131735801696777\n",
      "Batch 2750 - loss: 0.528448760509491\n",
      "Batch 2751 - loss: 0.5748634934425354\n",
      "Batch 2752 - loss: 0.5534239411354065\n",
      "Batch 2753 - loss: 0.46800604462623596\n",
      "Batch 2754 - loss: 0.5293167233467102\n",
      "Batch 2755 - loss: 0.5010539293289185\n",
      "Batch 2756 - loss: 0.535669207572937\n",
      "Batch 2757 - loss: 0.6094101071357727\n",
      "Batch 2758 - loss: 0.5637739300727844\n",
      "Batch 2759 - loss: 0.5607099533081055\n",
      "Batch 2760 - loss: 0.5302037596702576\n",
      "Batch 2761 - loss: 0.5271754264831543\n",
      "Batch 2762 - loss: 0.4773050546646118\n",
      "Batch 2763 - loss: 0.5243273377418518\n",
      "Batch 2764 - loss: 0.5393509864807129\n",
      "Batch 2765 - loss: 0.5162702202796936\n",
      "Batch 2766 - loss: 0.5968348383903503\n",
      "Batch 2767 - loss: 0.5179558396339417\n",
      "Batch 2768 - loss: 0.521385908126831\n",
      "Batch 2769 - loss: 0.509587287902832\n",
      "Batch 2770 - loss: 0.542818009853363\n",
      "Batch 2771 - loss: 0.5004554390907288\n",
      "Batch 2772 - loss: 0.5686845779418945\n",
      "Batch 2773 - loss: 0.5885457992553711\n",
      "Batch 2774 - loss: 0.5234806537628174\n",
      "Batch 2775 - loss: 0.5339595079421997\n",
      "Batch 2776 - loss: 0.5405588746070862\n",
      "Batch 2777 - loss: 0.577948272228241\n",
      "Batch 2778 - loss: 0.5215338468551636\n",
      "Batch 2779 - loss: 0.5341079235076904\n",
      "Batch 2780 - loss: 0.519608199596405\n",
      "Batch 2781 - loss: 0.5641616582870483\n",
      "Batch 2782 - loss: 0.5306270122528076\n",
      "Batch 2783 - loss: 0.49839842319488525\n",
      "Batch 2784 - loss: 0.5322393178939819\n",
      "Batch 2785 - loss: 0.5369953513145447\n",
      "Batch 2786 - loss: 0.4650322496891022\n",
      "Batch 2787 - loss: 0.5233254432678223\n",
      "Batch 2788 - loss: 0.5454975962638855\n",
      "Batch 2789 - loss: 0.5064544677734375\n",
      "Batch 2790 - loss: 0.5088509917259216\n",
      "Batch 2791 - loss: 0.5404541492462158\n",
      "Batch 2792 - loss: 0.5306536555290222\n",
      "Batch 2793 - loss: 0.5093784332275391\n",
      "Batch 2794 - loss: 0.6189081072807312\n",
      "Batch 2795 - loss: 0.5802778601646423\n",
      "Batch 2796 - loss: 0.5819587111473083\n",
      "Batch 2797 - loss: 0.5602208375930786\n",
      "Batch 2798 - loss: 0.5686469078063965\n",
      "Batch 2799 - loss: 0.49820852279663086\n",
      "Batch 2800 - loss: 0.5260071158409119\n",
      "Batch 2801 - loss: 0.5479373335838318\n",
      "Batch 2802 - loss: 0.4582071900367737\n",
      "Batch 2803 - loss: 0.4857918918132782\n",
      "Batch 2804 - loss: 0.5732443332672119\n",
      "Batch 2805 - loss: 0.5742747187614441\n",
      "Batch 2806 - loss: 0.512675940990448\n",
      "Batch 2807 - loss: 0.5100535750389099\n",
      "Batch 2808 - loss: 0.5418405532836914\n",
      "Batch 2809 - loss: 0.49621960520744324\n",
      "Batch 2810 - loss: 0.521144449710846\n",
      "Batch 2811 - loss: 0.5175333619117737\n",
      "Batch 2812 - loss: 0.5130427479743958\n",
      "Batch 2813 - loss: 0.5619757175445557\n",
      "Batch 2814 - loss: 0.5111708045005798\n",
      "Batch 2815 - loss: 0.5924862027168274\n",
      "Batch 2816 - loss: 0.5922664403915405\n",
      "Batch 2817 - loss: 0.5481207966804504\n",
      "Batch 2818 - loss: 0.5263500809669495\n",
      "Batch 2819 - loss: 0.5217885971069336\n",
      "Batch 2820 - loss: 0.5012727379798889\n",
      "Batch 2821 - loss: 0.5066238045692444\n",
      "Batch 2822 - loss: 0.535330593585968\n",
      "Batch 2823 - loss: 0.5857900977134705\n",
      "Batch 2824 - loss: 0.5175292491912842\n",
      "Batch 2825 - loss: 0.540817379951477\n",
      "Batch 2826 - loss: 0.6251706480979919\n",
      "Batch 2827 - loss: 0.5711469054222107\n",
      "Batch 2828 - loss: 0.545006513595581\n",
      "Batch 2829 - loss: 0.5453928709030151\n",
      "Batch 2830 - loss: 0.4904980957508087\n",
      "Batch 2831 - loss: 0.5038870573043823\n",
      "Batch 2832 - loss: 0.5971609950065613\n",
      "Batch 2833 - loss: 0.5460912585258484\n",
      "Batch 2834 - loss: 0.5404266119003296\n",
      "Batch 2835 - loss: 0.5670425891876221\n",
      "Batch 2836 - loss: 0.4903438687324524\n",
      "Batch 2837 - loss: 0.530511200428009\n",
      "Batch 2838 - loss: 0.5926861763000488\n",
      "Batch 2839 - loss: 0.5632452964782715\n",
      "Batch 2840 - loss: 0.5424453020095825\n",
      "Batch 2841 - loss: 0.5320057272911072\n",
      "Batch 2842 - loss: 0.5436256527900696\n",
      "Batch 2843 - loss: 0.5544670820236206\n",
      "Batch 2844 - loss: 0.5561779141426086\n",
      "Batch 2845 - loss: 0.5280912518501282\n",
      "Batch 2846 - loss: 0.5524669885635376\n",
      "Batch 2847 - loss: 0.5814868807792664\n",
      "Batch 2848 - loss: 0.5457789301872253\n",
      "Batch 2849 - loss: 0.5626038312911987\n",
      "Batch 2850 - loss: 0.5294317007064819\n",
      "Batch 2851 - loss: 0.48804110288619995\n",
      "Batch 2852 - loss: 0.5425354242324829\n",
      "Batch 2853 - loss: 0.5144615173339844\n",
      "Batch 2854 - loss: 0.5165398716926575\n",
      "Batch 2855 - loss: 0.5625492334365845\n",
      "Batch 2856 - loss: 0.4876280128955841\n",
      "Batch 2857 - loss: 0.5481178164482117\n",
      "Batch 2858 - loss: 0.5706643462181091\n",
      "Batch 2859 - loss: 0.54691082239151\n",
      "Batch 2860 - loss: 0.5392203330993652\n",
      "Batch 2861 - loss: 0.5305771231651306\n",
      "Batch 2862 - loss: 0.5469633340835571\n",
      "Batch 2863 - loss: 0.5437588095664978\n",
      "Batch 2864 - loss: 0.5428710579872131\n",
      "Batch 2865 - loss: 0.5654237866401672\n",
      "Batch 2866 - loss: 0.4885658621788025\n",
      "Batch 2867 - loss: 0.483948290348053\n",
      "Batch 2868 - loss: 0.5002750754356384\n",
      "Batch 2869 - loss: 0.5456933975219727\n",
      "Batch 2870 - loss: 0.4996062219142914\n",
      "Batch 2871 - loss: 0.5493886470794678\n",
      "Batch 2872 - loss: 0.5512962341308594\n",
      "Batch 2873 - loss: 0.5449766516685486\n",
      "Batch 2874 - loss: 0.5584665536880493\n",
      "Batch 2875 - loss: 0.5237953066825867\n",
      "Batch 2876 - loss: 0.5143188238143921\n",
      "Batch 2877 - loss: 0.5159072875976562\n",
      "Batch 2878 - loss: 0.5677353739738464\n",
      "Batch 2879 - loss: 0.48772475123405457\n",
      "Batch 2880 - loss: 0.5419604778289795\n",
      "Batch 2881 - loss: 0.5321208238601685\n",
      "Batch 2882 - loss: 0.4995556175708771\n",
      "Batch 2883 - loss: 0.5373232364654541\n",
      "Batch 2884 - loss: 0.5440440773963928\n",
      "Batch 2885 - loss: 0.5031875371932983\n",
      "Batch 2886 - loss: 0.5375450253486633\n",
      "Batch 2887 - loss: 0.4927229881286621\n",
      "Batch 2888 - loss: 0.5344694256782532\n",
      "Batch 2889 - loss: 0.541549563407898\n",
      "Batch 2890 - loss: 0.5248069763183594\n",
      "Batch 2891 - loss: 0.5741692781448364\n",
      "Batch 2892 - loss: 0.45749902725219727\n",
      "Batch 2893 - loss: 0.4721594750881195\n",
      "Batch 2894 - loss: 0.5885878801345825\n",
      "Batch 2895 - loss: 0.6337767243385315\n",
      "Batch 2896 - loss: 0.5608417391777039\n",
      "Batch 2897 - loss: 0.4997527003288269\n",
      "Batch 2898 - loss: 0.5850803852081299\n",
      "Batch 2899 - loss: 0.4788011908531189\n",
      "Batch 2900 - loss: 0.5149126052856445\n",
      "Batch 2901 - loss: 0.5397102236747742\n",
      "Batch 2902 - loss: 0.5664069056510925\n",
      "Batch 2903 - loss: 0.5760440826416016\n",
      "Batch 2904 - loss: 0.5951811671257019\n",
      "Batch 2905 - loss: 0.5521707534790039\n",
      "Batch 2906 - loss: 0.4946892559528351\n",
      "Batch 2907 - loss: 0.5302499532699585\n",
      "Batch 2908 - loss: 0.5253839492797852\n",
      "Batch 2909 - loss: 0.47184693813323975\n",
      "Batch 2910 - loss: 0.6314852237701416\n",
      "Batch 2911 - loss: 0.5018417835235596\n",
      "Batch 2912 - loss: 0.5732371211051941\n",
      "Batch 2913 - loss: 0.5840645432472229\n",
      "Batch 2914 - loss: 0.5627248883247375\n",
      "Batch 2915 - loss: 0.5543322563171387\n",
      "Batch 2916 - loss: 0.5402181148529053\n",
      "Batch 2917 - loss: 0.5572856664657593\n",
      "Batch 2918 - loss: 0.47923269867897034\n",
      "Batch 2919 - loss: 0.5580000877380371\n",
      "Batch 2920 - loss: 0.6076469421386719\n",
      "Batch 2921 - loss: 0.5219457149505615\n",
      "Batch 2922 - loss: 0.522208571434021\n",
      "Batch 2923 - loss: 0.5497258305549622\n",
      "Batch 2924 - loss: 0.5232383012771606\n",
      "Batch 2925 - loss: 0.5089139938354492\n",
      "Batch 2926 - loss: 0.5340490937232971\n",
      "Batch 2927 - loss: 0.5653964281082153\n",
      "Batch 2928 - loss: 0.5148114562034607\n",
      "Batch 2929 - loss: 0.5048434138298035\n",
      "Batch 2930 - loss: 0.5456404089927673\n",
      "Batch 2931 - loss: 0.5898717045783997\n",
      "Batch 2932 - loss: 0.5365453362464905\n",
      "Batch 2933 - loss: 0.5303952097892761\n",
      "Batch 2934 - loss: 0.4440855383872986\n",
      "Batch 2935 - loss: 0.5583682656288147\n",
      "Batch 2936 - loss: 0.5211721062660217\n",
      "Batch 2937 - loss: 0.44437962770462036\n",
      "Batch 2938 - loss: 0.5910614728927612\n",
      "Batch 2939 - loss: 0.5711224675178528\n",
      "Batch 2940 - loss: 0.5365427136421204\n",
      "Batch 2941 - loss: 0.5606228709220886\n",
      "Batch 2942 - loss: 0.5357412695884705\n",
      "Batch 2943 - loss: 0.5266827344894409\n",
      "Batch 2944 - loss: 0.499435693025589\n",
      "Batch 2945 - loss: 0.4742269814014435\n",
      "Batch 2946 - loss: 0.5604938864707947\n",
      "Batch 2947 - loss: 0.542381227016449\n",
      "Batch 2948 - loss: 0.5004035234451294\n",
      "Batch 2949 - loss: 0.5619592070579529\n",
      "Batch 2950 - loss: 0.5232166051864624\n",
      "Batch 2951 - loss: 0.5578575134277344\n",
      "Batch 2952 - loss: 0.5318400859832764\n",
      "Batch 2953 - loss: 0.5118944048881531\n",
      "Batch 2954 - loss: 0.5298892855644226\n",
      "Batch 2955 - loss: 0.5587966442108154\n",
      "Batch 2956 - loss: 0.5105550289154053\n",
      "Batch 2957 - loss: 0.47184860706329346\n",
      "Batch 2958 - loss: 0.5527032017707825\n",
      "Batch 2959 - loss: 0.48086807131767273\n",
      "Batch 2960 - loss: 0.49721091985702515\n",
      "Batch 2961 - loss: 0.5953437685966492\n",
      "Batch 2962 - loss: 0.5761749148368835\n",
      "Batch 2963 - loss: 0.5464741587638855\n",
      "Batch 2964 - loss: 0.474161833524704\n",
      "Batch 2965 - loss: 0.5354059934616089\n",
      "Batch 2966 - loss: 0.5225526094436646\n",
      "Batch 2967 - loss: 0.548541247844696\n",
      "Batch 2968 - loss: 0.5467585325241089\n",
      "Batch 2969 - loss: 0.5037777423858643\n",
      "Batch 2970 - loss: 0.47730833292007446\n",
      "Batch 2971 - loss: 0.5719321370124817\n",
      "Batch 2972 - loss: 0.6184542775154114\n",
      "Batch 2973 - loss: 0.5972687602043152\n",
      "Batch 2974 - loss: 0.5668954253196716\n",
      "Batch 2975 - loss: 0.5450235605239868\n",
      "Batch 2976 - loss: 0.4859330654144287\n",
      "Batch 2977 - loss: 0.5265825986862183\n",
      "Batch 2978 - loss: 0.49211233854293823\n",
      "Batch 2979 - loss: 0.5317099690437317\n",
      "Batch 2980 - loss: 0.563457190990448\n",
      "Batch 2981 - loss: 0.4886348843574524\n",
      "Batch 2982 - loss: 0.5766479969024658\n",
      "Batch 2983 - loss: 0.5617371797561646\n",
      "Batch 2984 - loss: 0.5040560364723206\n",
      "Batch 2985 - loss: 0.5265797972679138\n",
      "Batch 2986 - loss: 0.5504528284072876\n",
      "Batch 2987 - loss: 0.49897515773773193\n",
      "Batch 2988 - loss: 0.5029826760292053\n",
      "Batch 2989 - loss: 0.5328523516654968\n",
      "Batch 2990 - loss: 0.5237892866134644\n",
      "Batch 2991 - loss: 0.5326688885688782\n",
      "Batch 2992 - loss: 0.5836121439933777\n",
      "Batch 2993 - loss: 0.5043156743049622\n",
      "Batch 2994 - loss: 0.48412200808525085\n",
      "Batch 2995 - loss: 0.5509761571884155\n",
      "Batch 2996 - loss: 0.5351499915122986\n",
      "Batch 2997 - loss: 0.583709180355072\n",
      "Batch 2998 - loss: 0.5145542621612549\n",
      "Batch 2999 - loss: 0.5039200186729431\n",
      "Batch 3000 - loss: 0.5237481594085693\n",
      "Batch 3001 - loss: 0.5327625870704651\n",
      "Batch 3002 - loss: 0.536663830280304\n",
      "Batch 3003 - loss: 0.5547433495521545\n",
      "Batch 3004 - loss: 0.5295125246047974\n",
      "Batch 3005 - loss: 0.5183796882629395\n",
      "Batch 3006 - loss: 0.4755516052246094\n",
      "Batch 3007 - loss: 0.48686835169792175\n",
      "Batch 3008 - loss: 0.5500589609146118\n",
      "Batch 3009 - loss: 0.5379853248596191\n",
      "Batch 3010 - loss: 0.5195902585983276\n",
      "Batch 3011 - loss: 0.507043182849884\n",
      "Batch 3012 - loss: 0.5256955027580261\n",
      "Batch 3013 - loss: 0.4874323904514313\n",
      "Batch 3014 - loss: 0.4586162865161896\n",
      "Batch 3015 - loss: 0.5795795917510986\n",
      "Batch 3016 - loss: 0.5180419683456421\n",
      "Batch 3017 - loss: 0.5173979997634888\n",
      "Batch 3018 - loss: 0.5014324188232422\n",
      "Batch 3019 - loss: 0.5249680280685425\n",
      "Batch 3020 - loss: 0.5261077284812927\n",
      "Batch 3021 - loss: 0.556787371635437\n",
      "Batch 3022 - loss: 0.5943743586540222\n",
      "Batch 3023 - loss: 0.5570213198661804\n",
      "Batch 3024 - loss: 0.5606281757354736\n",
      "Batch 3025 - loss: 0.5260305404663086\n",
      "Batch 3026 - loss: 0.5406709313392639\n",
      "Batch 3027 - loss: 0.5326642990112305\n",
      "Batch 3028 - loss: 0.5151891708374023\n",
      "Batch 3029 - loss: 0.5245451927185059\n",
      "Batch 3030 - loss: 0.5246191024780273\n",
      "Batch 3031 - loss: 0.5245014429092407\n",
      "Batch 3032 - loss: 0.4848446249961853\n",
      "Batch 3033 - loss: 0.49512380361557007\n",
      "Batch 3034 - loss: 0.4916883111000061\n",
      "Batch 3035 - loss: 0.5361687541007996\n",
      "Batch 3036 - loss: 0.600957989692688\n",
      "Batch 3037 - loss: 0.49847695231437683\n",
      "Batch 3038 - loss: 0.6094827651977539\n",
      "Batch 3039 - loss: 0.483195424079895\n",
      "Batch 3040 - loss: 0.46629825234413147\n",
      "Batch 3041 - loss: 0.6046430468559265\n",
      "Batch 3042 - loss: 0.5117470622062683\n",
      "Batch 3043 - loss: 0.5245928168296814\n",
      "Batch 3044 - loss: 0.4981671869754791\n",
      "Batch 3045 - loss: 0.5094162225723267\n",
      "Batch 3046 - loss: 0.5221778154373169\n",
      "Batch 3047 - loss: 0.5008513331413269\n",
      "Batch 3048 - loss: 0.48556411266326904\n",
      "Batch 3049 - loss: 0.5360543131828308\n",
      "Batch 3050 - loss: 0.5003061890602112\n",
      "Batch 3051 - loss: 0.554024875164032\n",
      "Batch 3052 - loss: 0.5701763033866882\n",
      "Batch 3053 - loss: 0.5349348783493042\n",
      "Batch 3054 - loss: 0.5409952998161316\n",
      "Batch 3055 - loss: 0.48169755935668945\n",
      "Batch 3056 - loss: 0.516157865524292\n",
      "Batch 3057 - loss: 0.5318500995635986\n",
      "Batch 3058 - loss: 0.5331145524978638\n",
      "Batch 3059 - loss: 0.5015649199485779\n",
      "Batch 3060 - loss: 0.5216107964515686\n",
      "Batch 3061 - loss: 0.5158852934837341\n",
      "Batch 3062 - loss: 0.5341403484344482\n",
      "Batch 3063 - loss: 0.5111052393913269\n",
      "Batch 3064 - loss: 0.5531678199768066\n",
      "Batch 3065 - loss: 0.46885427832603455\n",
      "Batch 3066 - loss: 0.5823469161987305\n",
      "Batch 3067 - loss: 0.5316084623336792\n",
      "Batch 3068 - loss: 0.5343985557556152\n",
      "Batch 3069 - loss: 0.482575386762619\n",
      "Batch 3070 - loss: 0.4982166886329651\n",
      "Batch 3071 - loss: 0.5175324082374573\n",
      "Batch 3072 - loss: 0.5359907150268555\n",
      "Batch 3073 - loss: 0.5478127598762512\n",
      "Batch 3074 - loss: 0.5188679099082947\n",
      "Batch 3075 - loss: 0.4887499511241913\n",
      "Batch 3076 - loss: 0.5444954037666321\n",
      "Batch 3077 - loss: 0.537689208984375\n",
      "Batch 3078 - loss: 0.5110046863555908\n",
      "Batch 3079 - loss: 0.45643121004104614\n",
      "Batch 3080 - loss: 0.4983394742012024\n",
      "Batch 3081 - loss: 0.5599583387374878\n",
      "Batch 3082 - loss: 0.5305311679840088\n",
      "Batch 3083 - loss: 0.4915972948074341\n",
      "Batch 3084 - loss: 0.53202885389328\n",
      "Batch 3085 - loss: 0.5121458768844604\n",
      "Batch 3086 - loss: 0.5374017953872681\n",
      "Batch 3087 - loss: 0.5145536065101624\n",
      "Batch 3088 - loss: 0.5035312175750732\n",
      "Batch 3089 - loss: 0.5168277621269226\n",
      "Batch 3090 - loss: 0.5908924341201782\n",
      "Batch 3091 - loss: 0.5219451785087585\n",
      "Batch 3092 - loss: 0.4914242625236511\n",
      "Batch 3093 - loss: 0.5105741620063782\n",
      "Batch 3094 - loss: 0.5694440007209778\n",
      "Batch 3095 - loss: 0.5284855961799622\n",
      "Batch 3096 - loss: 0.5878771543502808\n",
      "Batch 3097 - loss: 0.5042815804481506\n",
      "Batch 3098 - loss: 0.6231224536895752\n",
      "Batch 3099 - loss: 0.5778906345367432\n",
      "Batch 3100 - loss: 0.5446138381958008\n",
      "Batch 3101 - loss: 0.5084934234619141\n",
      "Batch 3102 - loss: 0.5427704453468323\n",
      "Batch 3103 - loss: 0.4949794113636017\n",
      "Batch 3104 - loss: 0.5443236231803894\n",
      "Batch 3105 - loss: 0.5693065524101257\n",
      "Batch 3106 - loss: 0.578088104724884\n",
      "Batch 3107 - loss: 0.5005250573158264\n",
      "Batch 3108 - loss: 0.5608710646629333\n",
      "Batch 3109 - loss: 0.5411919355392456\n",
      "Batch 3110 - loss: 0.5023422837257385\n",
      "Batch 3111 - loss: 0.524660587310791\n",
      "Batch 3112 - loss: 0.5945028066635132\n",
      "Batch 3113 - loss: 0.5398895144462585\n",
      "Batch 3114 - loss: 0.4875957667827606\n",
      "Batch 3115 - loss: 0.49335238337516785\n",
      "Batch 3116 - loss: 0.5418135523796082\n",
      "Batch 3117 - loss: 0.5523993968963623\n",
      "Batch 3118 - loss: 0.5864164233207703\n",
      "Batch 3119 - loss: 0.5382764935493469\n",
      "Batch 3120 - loss: 0.5112725496292114\n",
      "Batch 3121 - loss: 0.5523796081542969\n",
      "Batch 3122 - loss: 0.49803969264030457\n",
      "Batch 3123 - loss: 0.4726475477218628\n",
      "Batch 3124 - loss: 0.5264660716056824\n",
      "Batch 3125 - loss: 0.5654328465461731\n",
      "Batch 3126 - loss: 0.5619028806686401\n",
      "Batch 3127 - loss: 0.5399203300476074\n",
      "Batch 3128 - loss: 0.5465312600135803\n",
      "Batch 3129 - loss: 0.5357334613800049\n",
      "Batch 3130 - loss: 0.5836212635040283\n",
      "Batch 3131 - loss: 0.5045105814933777\n",
      "Batch 3132 - loss: 0.5606491565704346\n",
      "Batch 3133 - loss: 0.5717738270759583\n",
      "Batch 3134 - loss: 0.5191954374313354\n",
      "Batch 3135 - loss: 0.4929921329021454\n",
      "Batch 3136 - loss: 0.5343695878982544\n",
      "Batch 3137 - loss: 0.5304735898971558\n",
      "Batch 3138 - loss: 0.5593397617340088\n",
      "Batch 3139 - loss: 0.5723593235015869\n",
      "Batch 3140 - loss: 0.5724400281906128\n",
      "Batch 3141 - loss: 0.5335099697113037\n",
      "Batch 3142 - loss: 0.5372838377952576\n",
      "Batch 3143 - loss: 0.4866122305393219\n",
      "Batch 3144 - loss: 0.5253678560256958\n",
      "Batch 3145 - loss: 0.5363287329673767\n",
      "Batch 3146 - loss: 0.5209226608276367\n",
      "Batch 3147 - loss: 0.5082739591598511\n",
      "Batch 3148 - loss: 0.5252523422241211\n",
      "Batch 3149 - loss: 0.5472599267959595\n",
      "Batch 3150 - loss: 0.555845320224762\n",
      "Batch 3151 - loss: 0.529285192489624\n",
      "Batch 3152 - loss: 0.5337945222854614\n",
      "Batch 3153 - loss: 0.4993881285190582\n",
      "Batch 3154 - loss: 0.5690611004829407\n",
      "Batch 3155 - loss: 0.5767420530319214\n",
      "Batch 3156 - loss: 0.5455729961395264\n",
      "Batch 3157 - loss: 0.48662739992141724\n",
      "Batch 3158 - loss: 0.5425369143486023\n",
      "Batch 3159 - loss: 0.598442554473877\n",
      "Batch 3160 - loss: 0.5527455806732178\n",
      "Batch 3161 - loss: 0.5251210927963257\n",
      "Batch 3162 - loss: 0.5285293459892273\n",
      "Batch 3163 - loss: 0.5430962443351746\n",
      "Batch 3164 - loss: 0.4690778851509094\n",
      "Batch 3165 - loss: 0.5748761296272278\n",
      "Batch 3166 - loss: 0.5658107995986938\n",
      "Batch 3167 - loss: 0.46724799275398254\n",
      "Batch 3168 - loss: 0.5269417762756348\n",
      "Batch 3169 - loss: 0.5832827687263489\n",
      "Batch 3170 - loss: 0.5818108916282654\n",
      "Batch 3171 - loss: 0.5950689911842346\n",
      "Batch 3172 - loss: 0.55829256772995\n",
      "Batch 3173 - loss: 0.5207434296607971\n",
      "Batch 3174 - loss: 0.5842545032501221\n",
      "Batch 3175 - loss: 0.531039297580719\n",
      "Batch 3176 - loss: 0.5499041080474854\n",
      "Batch 3177 - loss: 0.5591427683830261\n",
      "Batch 3178 - loss: 0.5310573577880859\n",
      "Batch 3179 - loss: 0.5881302952766418\n",
      "Batch 3180 - loss: 0.5294567942619324\n",
      "Batch 3181 - loss: 0.46180829405784607\n",
      "Batch 3182 - loss: 0.5399526953697205\n",
      "Batch 3183 - loss: 0.5587050914764404\n",
      "Batch 3184 - loss: 0.5338317155838013\n",
      "Batch 3185 - loss: 0.5300005078315735\n",
      "Batch 3186 - loss: 0.5694710612297058\n",
      "Batch 3187 - loss: 0.5676542520523071\n",
      "Batch 3188 - loss: 0.5614519119262695\n",
      "Batch 3189 - loss: 0.48112672567367554\n",
      "Batch 3190 - loss: 0.5563012957572937\n",
      "Batch 3191 - loss: 0.5708695650100708\n",
      "Batch 3192 - loss: 0.5130370855331421\n",
      "Batch 3193 - loss: 0.5679062604904175\n",
      "Batch 3194 - loss: 0.5140310525894165\n",
      "Batch 3195 - loss: 0.5560845732688904\n",
      "Batch 3196 - loss: 0.5591132044792175\n",
      "Batch 3197 - loss: 0.5184365510940552\n",
      "Batch 3198 - loss: 0.5916053652763367\n",
      "Batch 3199 - loss: 0.5903352499008179\n",
      "Batch 3200 - loss: 0.4884694218635559\n",
      "Batch 3201 - loss: 0.5188988447189331\n",
      "Batch 3202 - loss: 0.5793776512145996\n",
      "Batch 3203 - loss: 0.5259983539581299\n",
      "Batch 3204 - loss: 0.5514419674873352\n",
      "Batch 3205 - loss: 0.5130167007446289\n",
      "Batch 3206 - loss: 0.5102534890174866\n",
      "Batch 3207 - loss: 0.5103651881217957\n",
      "Batch 3208 - loss: 0.5091888308525085\n",
      "Batch 3209 - loss: 0.6040533185005188\n",
      "Batch 3210 - loss: 0.5216176509857178\n",
      "Batch 3211 - loss: 0.4825573265552521\n",
      "Batch 3212 - loss: 0.5659083127975464\n",
      "Batch 3213 - loss: 0.5464217066764832\n",
      "Batch 3214 - loss: 0.4574509859085083\n",
      "Batch 3215 - loss: 0.5275577902793884\n",
      "Batch 3216 - loss: 0.49556300044059753\n",
      "Batch 3217 - loss: 0.5490043759346008\n",
      "Batch 3218 - loss: 0.4495854675769806\n",
      "Batch 3219 - loss: 0.5175331234931946\n",
      "Batch 3220 - loss: 0.4793802499771118\n",
      "Batch 3221 - loss: 0.513778030872345\n",
      "Batch 3222 - loss: 0.595045268535614\n",
      "Batch 3223 - loss: 0.534389853477478\n",
      "Batch 3224 - loss: 0.5575228333473206\n",
      "Batch 3225 - loss: 0.49380093812942505\n",
      "Batch 3226 - loss: 0.5931680798530579\n",
      "Batch 3227 - loss: 0.4552566111087799\n",
      "Batch 3228 - loss: 0.6027749180793762\n",
      "Batch 3229 - loss: 0.48835575580596924\n",
      "Batch 3230 - loss: 0.5515998005867004\n",
      "Batch 3231 - loss: 0.5106866359710693\n",
      "Batch 3232 - loss: 0.5788309574127197\n",
      "Batch 3233 - loss: 0.5009429454803467\n",
      "Batch 3234 - loss: 0.49762651324272156\n",
      "Batch 3235 - loss: 0.517194926738739\n",
      "Batch 3236 - loss: 0.5524740815162659\n",
      "Batch 3237 - loss: 0.5781805515289307\n",
      "Batch 3238 - loss: 0.5826287865638733\n",
      "Batch 3239 - loss: 0.5467841625213623\n",
      "Batch 3240 - loss: 0.5321510434150696\n",
      "Batch 3241 - loss: 0.4857535660266876\n",
      "Batch 3242 - loss: 0.4868440628051758\n",
      "Batch 3243 - loss: 0.560374915599823\n",
      "Batch 3244 - loss: 0.5422212481498718\n",
      "Batch 3245 - loss: 0.516097366809845\n",
      "Batch 3246 - loss: 0.5393009781837463\n",
      "Batch 3247 - loss: 0.5285775065422058\n",
      "Batch 3248 - loss: 0.5377934575080872\n",
      "Batch 3249 - loss: 0.5444443225860596\n",
      "Batch 3250 - loss: 0.535942018032074\n",
      "Batch 3251 - loss: 0.5319777131080627\n",
      "Batch 3252 - loss: 0.5561584830284119\n",
      "Batch 3253 - loss: 0.5526478290557861\n",
      "Batch 3254 - loss: 0.4957638382911682\n",
      "Batch 3255 - loss: 0.5003255009651184\n",
      "Batch 3256 - loss: 0.6113216280937195\n",
      "Batch 3257 - loss: 0.5547147393226624\n",
      "Batch 3258 - loss: 0.5619463920593262\n",
      "Batch 3259 - loss: 0.45030373334884644\n",
      "Batch 3260 - loss: 0.4861961901187897\n",
      "Batch 3261 - loss: 0.48639893531799316\n",
      "Batch 3262 - loss: 0.5894215703010559\n",
      "Batch 3263 - loss: 0.5790919065475464\n",
      "Batch 3264 - loss: 0.4992826282978058\n",
      "Batch 3265 - loss: 0.517130434513092\n",
      "Batch 3266 - loss: 0.5301350951194763\n",
      "Batch 3267 - loss: 0.5333625674247742\n",
      "Batch 3268 - loss: 0.5506335496902466\n",
      "Batch 3269 - loss: 0.5080706477165222\n",
      "Batch 3270 - loss: 0.5708479881286621\n",
      "Batch 3271 - loss: 0.5028280019760132\n",
      "Batch 3272 - loss: 0.5283675789833069\n",
      "Batch 3273 - loss: 0.577305793762207\n",
      "Batch 3274 - loss: 0.5128097534179688\n",
      "Batch 3275 - loss: 0.5261008739471436\n",
      "Batch 3276 - loss: 0.5343483090400696\n",
      "Batch 3277 - loss: 0.49828672409057617\n",
      "Batch 3278 - loss: 0.5202257633209229\n",
      "Batch 3279 - loss: 0.5505666732788086\n",
      "Batch 3280 - loss: 0.5621257424354553\n",
      "Batch 3281 - loss: 0.5043646097183228\n",
      "Batch 3282 - loss: 0.5098245143890381\n",
      "Batch 3283 - loss: 0.5970260500907898\n",
      "Batch 3284 - loss: 0.49404799938201904\n",
      "Batch 3285 - loss: 0.5479159355163574\n",
      "Batch 3286 - loss: 0.5197668671607971\n",
      "Batch 3287 - loss: 0.5310826301574707\n",
      "Batch 3288 - loss: 0.5294924378395081\n",
      "Batch 3289 - loss: 0.4864695072174072\n",
      "Batch 3290 - loss: 0.5305790901184082\n",
      "Batch 3291 - loss: 0.5676900148391724\n",
      "Batch 3292 - loss: 0.5312167406082153\n",
      "Batch 3293 - loss: 0.5519244074821472\n",
      "Batch 3294 - loss: 0.5313565731048584\n",
      "Batch 3295 - loss: 0.4919999837875366\n",
      "Batch 3296 - loss: 0.5081197619438171\n",
      "Batch 3297 - loss: 0.5168044567108154\n",
      "Batch 3298 - loss: 0.4900544583797455\n",
      "Batch 3299 - loss: 0.509588360786438\n",
      "Batch 3300 - loss: 0.5284887552261353\n",
      "Batch 3301 - loss: 0.507535457611084\n",
      "Batch 3302 - loss: 0.4750584363937378\n",
      "Batch 3303 - loss: 0.5093634128570557\n",
      "Batch 3304 - loss: 0.49503564834594727\n",
      "Batch 3305 - loss: 0.5261949300765991\n",
      "Batch 3306 - loss: 0.5425160527229309\n",
      "Batch 3307 - loss: 0.48834022879600525\n",
      "Batch 3308 - loss: 0.5398147106170654\n",
      "Batch 3309 - loss: 0.5373616814613342\n",
      "Batch 3310 - loss: 0.5205329656600952\n",
      "Batch 3311 - loss: 0.4998670518398285\n",
      "Batch 3312 - loss: 0.5044474601745605\n",
      "Batch 3313 - loss: 0.5130756497383118\n",
      "Batch 3314 - loss: 0.5828737616539001\n",
      "Batch 3315 - loss: 0.5962942838668823\n",
      "Batch 3316 - loss: 0.5196836590766907\n",
      "Batch 3317 - loss: 0.5221502184867859\n",
      "Batch 3318 - loss: 0.4947505593299866\n",
      "Batch 3319 - loss: 0.5192702412605286\n",
      "Batch 3320 - loss: 0.4606652855873108\n",
      "Batch 3321 - loss: 0.47698459029197693\n",
      "Batch 3322 - loss: 0.4986712634563446\n",
      "Batch 3323 - loss: 0.527532160282135\n",
      "Batch 3324 - loss: 0.47587108612060547\n",
      "Batch 3325 - loss: 0.49860525131225586\n",
      "Batch 3326 - loss: 0.5203238725662231\n",
      "Batch 3327 - loss: 0.5496882796287537\n",
      "Batch 3328 - loss: 0.5498169660568237\n",
      "Batch 3329 - loss: 0.5314106345176697\n",
      "Batch 3330 - loss: 0.5251280665397644\n",
      "Batch 3331 - loss: 0.5337473154067993\n",
      "Batch 3332 - loss: 0.5352894067764282\n",
      "Batch 3333 - loss: 0.5670924782752991\n",
      "Batch 3334 - loss: 0.5176892876625061\n",
      "Batch 3335 - loss: 0.541475236415863\n",
      "Batch 3336 - loss: 0.5347842574119568\n",
      "Batch 3337 - loss: 0.5916838645935059\n",
      "Batch 3338 - loss: 0.48145875334739685\n",
      "Batch 3339 - loss: 0.5455226302146912\n",
      "Batch 3340 - loss: 0.5523236989974976\n",
      "Batch 3341 - loss: 0.5566613078117371\n",
      "Batch 3342 - loss: 0.47750037908554077\n",
      "Batch 3343 - loss: 0.5313453674316406\n",
      "Batch 3344 - loss: 0.4980238378047943\n",
      "Batch 3345 - loss: 0.4990966320037842\n",
      "Batch 3346 - loss: 0.541103720664978\n",
      "Batch 3347 - loss: 0.5459303259849548\n",
      "Batch 3348 - loss: 0.49468550086021423\n",
      "Batch 3349 - loss: 0.5069366097450256\n",
      "Batch 3350 - loss: 0.5020624995231628\n",
      "Batch 3351 - loss: 0.5105759501457214\n",
      "Batch 3352 - loss: 0.5266045331954956\n",
      "Batch 3353 - loss: 0.5157756209373474\n",
      "Batch 3354 - loss: 0.5485444664955139\n",
      "Batch 3355 - loss: 0.541843593120575\n",
      "Batch 3356 - loss: 0.5404511094093323\n",
      "Batch 3357 - loss: 0.5208378434181213\n",
      "Batch 3358 - loss: 0.48490867018699646\n",
      "Batch 3359 - loss: 0.5165203213691711\n",
      "Batch 3360 - loss: 0.5124466419219971\n",
      "Batch 3361 - loss: 0.5487595200538635\n",
      "Batch 3362 - loss: 0.5074149370193481\n",
      "Batch 3363 - loss: 0.5654169321060181\n",
      "Batch 3364 - loss: 0.5791350603103638\n",
      "Batch 3365 - loss: 0.5734156370162964\n",
      "Batch 3366 - loss: 0.5297110080718994\n",
      "Batch 3367 - loss: 0.5641465187072754\n",
      "Batch 3368 - loss: 0.5142260193824768\n",
      "Batch 3369 - loss: 0.627997875213623\n",
      "Batch 3370 - loss: 0.49310794472694397\n",
      "Batch 3371 - loss: 0.5552688837051392\n",
      "Batch 3372 - loss: 0.5073597431182861\n",
      "Batch 3373 - loss: 0.51555997133255\n",
      "Batch 3374 - loss: 0.5300617814064026\n",
      "Batch 3375 - loss: 0.5134062767028809\n",
      "Batch 3376 - loss: 0.5321919322013855\n",
      "Batch 3377 - loss: 0.5125007629394531\n",
      "Batch 3378 - loss: 0.5092813372612\n",
      "Batch 3379 - loss: 0.5355513691902161\n",
      "Batch 3380 - loss: 0.4913393557071686\n",
      "Batch 3381 - loss: 0.5133892893791199\n",
      "Batch 3382 - loss: 0.5438032150268555\n",
      "Batch 3383 - loss: 0.5479382276535034\n",
      "Batch 3384 - loss: 0.5254941582679749\n",
      "Batch 3385 - loss: 0.5244055390357971\n",
      "Batch 3386 - loss: 0.5730512142181396\n",
      "Batch 3387 - loss: 0.52109694480896\n",
      "Batch 3388 - loss: 0.5509418249130249\n",
      "Batch 3389 - loss: 0.5359482169151306\n",
      "Batch 3390 - loss: 0.5197870135307312\n",
      "Batch 3391 - loss: 0.5224514603614807\n",
      "Batch 3392 - loss: 0.5072084069252014\n",
      "Batch 3393 - loss: 0.5319749712944031\n",
      "Batch 3394 - loss: 0.5653405785560608\n",
      "Batch 3395 - loss: 0.5024914741516113\n",
      "Batch 3396 - loss: 0.5803970098495483\n",
      "Batch 3397 - loss: 0.5248929858207703\n",
      "Batch 3398 - loss: 0.611333966255188\n",
      "Batch 3399 - loss: 0.4917254149913788\n",
      "Batch 3400 - loss: 0.5309275388717651\n",
      "Batch 3401 - loss: 0.5119117498397827\n",
      "Batch 3402 - loss: 0.5057920813560486\n",
      "Batch 3403 - loss: 0.5568116903305054\n",
      "Batch 3404 - loss: 0.5769359469413757\n",
      "Batch 3405 - loss: 0.5543262958526611\n",
      "Batch 3406 - loss: 0.5032740235328674\n",
      "Batch 3407 - loss: 0.5117358565330505\n",
      "Batch 3408 - loss: 0.5822773575782776\n",
      "Batch 3409 - loss: 0.4778946042060852\n",
      "Batch 3410 - loss: 0.5780797004699707\n",
      "Batch 3411 - loss: 0.5229153633117676\n",
      "Batch 3412 - loss: 0.5475648641586304\n",
      "Batch 3413 - loss: 0.5022822022438049\n",
      "Batch 3414 - loss: 0.5000503063201904\n",
      "Batch 3415 - loss: 0.45414501428604126\n",
      "Batch 3416 - loss: 0.5410332679748535\n",
      "Batch 3417 - loss: 0.49063611030578613\n",
      "Batch 3418 - loss: 0.555556058883667\n",
      "Batch 3419 - loss: 0.5080423355102539\n",
      "Batch 3420 - loss: 0.5971075892448425\n",
      "Batch 3421 - loss: 0.5393205285072327\n",
      "Batch 3422 - loss: 0.43316662311553955\n",
      "Batch 3423 - loss: 0.5141026973724365\n",
      "Batch 3424 - loss: 0.49079418182373047\n",
      "Batch 3425 - loss: 0.5487926602363586\n",
      "Batch 3426 - loss: 0.5515949726104736\n",
      "Batch 3427 - loss: 0.5334997773170471\n",
      "Batch 3428 - loss: 0.5211237668991089\n",
      "Batch 3429 - loss: 0.5381091833114624\n",
      "Batch 3430 - loss: 0.5229018330574036\n",
      "Batch 3431 - loss: 0.5013561844825745\n",
      "Batch 3432 - loss: 0.545429527759552\n",
      "Batch 3433 - loss: 0.505710780620575\n",
      "Batch 3434 - loss: 0.5951982736587524\n",
      "Batch 3435 - loss: 0.5142618417739868\n",
      "Batch 3436 - loss: 0.498503178358078\n",
      "Batch 3437 - loss: 0.5777677893638611\n",
      "Batch 3438 - loss: 0.5145006775856018\n",
      "Batch 3439 - loss: 0.5419319868087769\n",
      "Batch 3440 - loss: 0.5221452713012695\n",
      "Batch 3441 - loss: 0.5463857650756836\n",
      "Batch 3442 - loss: 0.5274084806442261\n",
      "Batch 3443 - loss: 0.5652630925178528\n",
      "Batch 3444 - loss: 0.5491222739219666\n",
      "Batch 3445 - loss: 0.5517088174819946\n",
      "Batch 3446 - loss: 0.5368237495422363\n",
      "Batch 3447 - loss: 0.5103358626365662\n",
      "Batch 3448 - loss: 0.49634820222854614\n",
      "Batch 3449 - loss: 0.5039731860160828\n",
      "Batch 3450 - loss: 0.5944944620132446\n",
      "Batch 3451 - loss: 0.5661529898643494\n",
      "Batch 3452 - loss: 0.5176504254341125\n",
      "Batch 3453 - loss: 0.553991973400116\n",
      "Batch 3454 - loss: 0.5410147905349731\n",
      "Batch 3455 - loss: 0.5147170424461365\n",
      "Batch 3456 - loss: 0.5374186635017395\n",
      "Batch 3457 - loss: 0.5766549110412598\n",
      "Batch 3458 - loss: 0.5082643032073975\n",
      "Batch 3459 - loss: 0.5301713943481445\n",
      "Batch 3460 - loss: 0.5161570906639099\n",
      "Batch 3461 - loss: 0.48910075426101685\n",
      "Batch 3462 - loss: 0.5738939642906189\n",
      "Batch 3463 - loss: 0.5697907209396362\n",
      "Batch 3464 - loss: 0.5285695791244507\n",
      "Batch 3465 - loss: 0.5074071884155273\n",
      "Batch 3466 - loss: 0.5102324485778809\n",
      "Batch 3467 - loss: 0.5279475450515747\n",
      "Batch 3468 - loss: 0.4862678647041321\n",
      "Batch 3469 - loss: 0.5471770763397217\n",
      "Batch 3470 - loss: 0.5082827806472778\n",
      "Batch 3471 - loss: 0.5185984373092651\n",
      "Batch 3472 - loss: 0.5884393453598022\n",
      "Batch 3473 - loss: 0.476126492023468\n",
      "Batch 3474 - loss: 0.5049381256103516\n",
      "Batch 3475 - loss: 0.5442968606948853\n",
      "Batch 3476 - loss: 0.5506759285926819\n",
      "Batch 3477 - loss: 0.5685271620750427\n",
      "Batch 3478 - loss: 0.5373483896255493\n",
      "Batch 3479 - loss: 0.5201147198677063\n",
      "Batch 3480 - loss: 0.48914703726768494\n",
      "Batch 3481 - loss: 0.5204858183860779\n",
      "Batch 3482 - loss: 0.575935959815979\n",
      "Batch 3483 - loss: 0.5486846566200256\n",
      "Batch 3484 - loss: 0.5746715664863586\n",
      "Batch 3485 - loss: 0.5559695959091187\n",
      "Batch 3486 - loss: 0.5773636698722839\n",
      "Batch 3487 - loss: 0.5229988098144531\n",
      "Batch 3488 - loss: 0.5165413022041321\n",
      "Batch 3489 - loss: 0.5040728449821472\n",
      "Batch 3490 - loss: 0.5148285031318665\n",
      "Batch 3491 - loss: 0.5345579981803894\n",
      "Batch 3492 - loss: 0.5755648016929626\n",
      "Batch 3493 - loss: 0.5462080836296082\n",
      "Batch 3494 - loss: 0.5699282884597778\n",
      "Batch 3495 - loss: 0.5680365562438965\n",
      "Batch 3496 - loss: 0.5189235806465149\n",
      "Batch 3497 - loss: 0.532477080821991\n",
      "Batch 3498 - loss: 0.5682153701782227\n",
      "Batch 3499 - loss: 0.6090696454048157\n",
      "Batch 3500 - loss: 0.6003009676933289\n",
      "Batch 3501 - loss: 0.5143693089485168\n",
      "Batch 3502 - loss: 0.5570098757743835\n",
      "Batch 3503 - loss: 0.5854056477546692\n",
      "Batch 3504 - loss: 0.5399069786071777\n",
      "Batch 3505 - loss: 0.4964619278907776\n",
      "Batch 3506 - loss: 0.569659948348999\n",
      "Batch 3507 - loss: 0.5541937947273254\n",
      "Batch 3508 - loss: 0.5824075937271118\n",
      "Batch 3509 - loss: 0.5421754717826843\n",
      "Batch 3510 - loss: 0.5282179713249207\n",
      "Batch 3511 - loss: 0.5460970997810364\n",
      "Batch 3512 - loss: 0.5712591409683228\n",
      "Batch 3513 - loss: 0.5450181365013123\n",
      "Batch 3514 - loss: 0.5598256587982178\n",
      "Batch 3515 - loss: 0.5942044854164124\n",
      "Batch 3516 - loss: 0.565420389175415\n",
      "Batch 3517 - loss: 0.5085904002189636\n",
      "Batch 3518 - loss: 0.5557807087898254\n",
      "Batch 3519 - loss: 0.5731688141822815\n",
      "Batch 3520 - loss: 0.5114552974700928\n",
      "Batch 3521 - loss: 0.5141245722770691\n",
      "Batch 3522 - loss: 0.5831299424171448\n",
      "Batch 3523 - loss: 0.5115649104118347\n",
      "Batch 3524 - loss: 0.5325092673301697\n",
      "Batch 3525 - loss: 0.5919046401977539\n",
      "Batch 3526 - loss: 0.531898558139801\n",
      "Batch 3527 - loss: 0.5335431098937988\n",
      "Batch 3528 - loss: 0.5272367596626282\n",
      "Batch 3529 - loss: 0.4882953464984894\n",
      "Batch 3530 - loss: 0.48232290148735046\n",
      "Batch 3531 - loss: 0.47712215781211853\n",
      "Batch 3532 - loss: 0.5831031799316406\n",
      "Batch 3533 - loss: 0.5526940822601318\n",
      "Batch 3534 - loss: 0.5165442228317261\n",
      "Batch 3535 - loss: 0.5266984105110168\n",
      "Batch 3536 - loss: 0.5919305086135864\n",
      "Batch 3537 - loss: 0.5505700707435608\n",
      "Batch 3538 - loss: 0.5155344009399414\n",
      "Batch 3539 - loss: 0.5245093107223511\n",
      "Batch 3540 - loss: 0.5394999980926514\n",
      "Batch 3541 - loss: 0.5016084313392639\n",
      "Batch 3542 - loss: 0.5582777857780457\n",
      "Batch 3543 - loss: 0.5566352605819702\n",
      "Batch 3544 - loss: 0.5394684076309204\n",
      "Batch 3545 - loss: 0.5351867079734802\n",
      "Batch 3546 - loss: 0.5733399987220764\n",
      "Batch 3547 - loss: 0.5297729969024658\n",
      "Batch 3548 - loss: 0.5077598094940186\n",
      "Batch 3549 - loss: 0.5112539529800415\n",
      "Batch 3550 - loss: 0.4924508035182953\n",
      "Batch 3551 - loss: 0.562023937702179\n",
      "Batch 3552 - loss: 0.4639878273010254\n",
      "Batch 3553 - loss: 0.5369101166725159\n",
      "Batch 3554 - loss: 0.4942789077758789\n",
      "Batch 3555 - loss: 0.5247927308082581\n",
      "Batch 3556 - loss: 0.533369779586792\n",
      "Batch 3557 - loss: 0.552383542060852\n",
      "Batch 3558 - loss: 0.5026456117630005\n",
      "Batch 3559 - loss: 0.5576326847076416\n",
      "Batch 3560 - loss: 0.5377197861671448\n",
      "Batch 3561 - loss: 0.5563883781433105\n",
      "Batch 3562 - loss: 0.5363208055496216\n",
      "Batch 3563 - loss: 0.49212244153022766\n",
      "Batch 3564 - loss: 0.4851491451263428\n",
      "Batch 3565 - loss: 0.599618673324585\n",
      "Batch 3566 - loss: 0.46475058794021606\n",
      "Batch 3567 - loss: 0.4998634159564972\n",
      "Batch 3568 - loss: 0.45208805799484253\n",
      "Batch 3569 - loss: 0.6089460253715515\n",
      "Batch 3570 - loss: 0.5364401340484619\n",
      "Batch 3571 - loss: 0.5814375281333923\n",
      "Batch 3572 - loss: 0.5355439782142639\n",
      "Batch 3573 - loss: 0.5170189738273621\n",
      "Batch 3574 - loss: 0.5155867338180542\n",
      "Batch 3575 - loss: 0.5383851528167725\n",
      "Batch 3576 - loss: 0.51888108253479\n",
      "Batch 3577 - loss: 0.5403596758842468\n",
      "Batch 3578 - loss: 0.6474460959434509\n",
      "Batch 3579 - loss: 0.5251190066337585\n",
      "Batch 3580 - loss: 0.5201379656791687\n",
      "Batch 3581 - loss: 0.4759024381637573\n",
      "Batch 3582 - loss: 0.5625337958335876\n",
      "Batch 3583 - loss: 0.5446376204490662\n",
      "Batch 3584 - loss: 0.4559803605079651\n",
      "Batch 3585 - loss: 0.5281116366386414\n",
      "Batch 3586 - loss: 0.564286470413208\n",
      "Batch 3587 - loss: 0.4977916181087494\n",
      "Batch 3588 - loss: 0.5373623967170715\n",
      "Batch 3589 - loss: 0.48654577136039734\n",
      "Batch 3590 - loss: 0.5059120059013367\n",
      "Batch 3591 - loss: 0.47930094599723816\n",
      "Batch 3592 - loss: 0.5141182541847229\n",
      "Batch 3593 - loss: 0.47793442010879517\n",
      "Batch 3594 - loss: 0.5022872686386108\n",
      "Batch 3595 - loss: 0.47794076800346375\n",
      "Batch 3596 - loss: 0.5289742350578308\n",
      "Batch 3597 - loss: 0.5520451664924622\n",
      "Batch 3598 - loss: 0.5762252807617188\n",
      "Batch 3599 - loss: 0.5582674741744995\n",
      "Batch 3600 - loss: 0.5550645589828491\n",
      "Batch 3601 - loss: 0.4847109615802765\n",
      "Batch 3602 - loss: 0.5923515558242798\n",
      "Batch 3603 - loss: 0.46531662344932556\n",
      "Batch 3604 - loss: 0.5205575227737427\n",
      "Batch 3605 - loss: 0.49884501099586487\n",
      "Batch 3606 - loss: 0.5681394338607788\n",
      "Batch 3607 - loss: 0.49106937646865845\n",
      "Batch 3608 - loss: 0.4896835386753082\n",
      "Batch 3609 - loss: 0.516688883304596\n",
      "Batch 3610 - loss: 0.5126199126243591\n",
      "Batch 3611 - loss: 0.5388553142547607\n",
      "Batch 3612 - loss: 0.5732472538948059\n",
      "Batch 3613 - loss: 0.5456174612045288\n",
      "Batch 3614 - loss: 0.5879212021827698\n",
      "Batch 3615 - loss: 0.539981484413147\n",
      "Batch 3616 - loss: 0.4855556786060333\n",
      "Batch 3617 - loss: 0.5326739549636841\n",
      "Batch 3618 - loss: 0.5447383522987366\n",
      "Batch 3619 - loss: 0.5882927179336548\n",
      "Batch 3620 - loss: 0.48717620968818665\n",
      "Batch 3621 - loss: 0.5046067237854004\n",
      "Batch 3622 - loss: 0.577547013759613\n",
      "Batch 3623 - loss: 0.5394943952560425\n",
      "Batch 3624 - loss: 0.5610578656196594\n",
      "Batch 3625 - loss: 0.5243397951126099\n",
      "Batch 3626 - loss: 0.48816484212875366\n",
      "Batch 3627 - loss: 0.5328062772750854\n",
      "Batch 3628 - loss: 0.4819061756134033\n",
      "Batch 3629 - loss: 0.5202265381813049\n",
      "Batch 3630 - loss: 0.5591914057731628\n",
      "Batch 3631 - loss: 0.5173613429069519\n",
      "Batch 3632 - loss: 0.5704229474067688\n",
      "Batch 3633 - loss: 0.5298267602920532\n",
      "Batch 3634 - loss: 0.47918930649757385\n",
      "Batch 3635 - loss: 0.6954370737075806\n",
      "Batch 3636 - loss: 0.5743710994720459\n",
      "Batch 3637 - loss: 0.5636565089225769\n",
      "Batch 3638 - loss: 0.5292308330535889\n",
      "Batch 3639 - loss: 0.539892852306366\n",
      "Batch 3640 - loss: 0.5094652771949768\n",
      "Batch 3641 - loss: 0.6000468730926514\n",
      "Batch 3642 - loss: 0.607896625995636\n",
      "Batch 3643 - loss: 0.4477606415748596\n",
      "Batch 3644 - loss: 0.6265622973442078\n",
      "Batch 3645 - loss: 0.5145564675331116\n",
      "Batch 3646 - loss: 0.529910147190094\n",
      "Batch 3647 - loss: 0.47327500581741333\n",
      "Batch 3648 - loss: 0.5323631167411804\n",
      "Batch 3649 - loss: 0.49740615487098694\n",
      "Batch 3650 - loss: 0.51513671875\n",
      "Batch 3651 - loss: 0.5548479557037354\n",
      "Batch 3652 - loss: 0.5389288067817688\n",
      "Batch 3653 - loss: 0.5347009897232056\n",
      "Batch 3654 - loss: 0.5335935950279236\n",
      "Batch 3655 - loss: 0.5068666338920593\n",
      "Batch 3656 - loss: 0.5261852741241455\n",
      "Batch 3657 - loss: 0.5895715355873108\n",
      "Batch 3658 - loss: 0.5101399421691895\n",
      "Batch 3659 - loss: 0.5927950143814087\n",
      "Batch 3660 - loss: 0.5420531630516052\n",
      "Batch 3661 - loss: 0.501208484172821\n",
      "Batch 3662 - loss: 0.5868198871612549\n",
      "Batch 3663 - loss: 0.5258637070655823\n",
      "Batch 3664 - loss: 0.48799991607666016\n",
      "Batch 3665 - loss: 0.554129958152771\n",
      "Batch 3666 - loss: 0.6058195233345032\n",
      "Batch 3667 - loss: 0.5851765871047974\n",
      "Batch 3668 - loss: 0.5259830355644226\n",
      "Batch 3669 - loss: 0.5370298624038696\n",
      "Batch 3670 - loss: 0.5030874013900757\n",
      "Batch 3671 - loss: 0.5068493485450745\n",
      "Batch 3672 - loss: 0.481643944978714\n",
      "Batch 3673 - loss: 0.5474820137023926\n",
      "Batch 3674 - loss: 0.5411061644554138\n",
      "Batch 3675 - loss: 0.5236851572990417\n",
      "Batch 3676 - loss: 0.5622654557228088\n",
      "Batch 3677 - loss: 0.49871450662612915\n",
      "Batch 3678 - loss: 0.5633321404457092\n",
      "Batch 3679 - loss: 0.5395129323005676\n",
      "Batch 3680 - loss: 0.4951174557209015\n",
      "Batch 3681 - loss: 0.5150599479675293\n",
      "Batch 3682 - loss: 0.4839114248752594\n",
      "Batch 3683 - loss: 0.5768108367919922\n",
      "Batch 3684 - loss: 0.5547721982002258\n",
      "Batch 3685 - loss: 0.4749240279197693\n",
      "Batch 3686 - loss: 0.5192307233810425\n",
      "Batch 3687 - loss: 0.5403552055358887\n",
      "Batch 3688 - loss: 0.5480644106864929\n",
      "Batch 3689 - loss: 0.5053714513778687\n",
      "Batch 3690 - loss: 0.5006016492843628\n",
      "Batch 3691 - loss: 0.5260926485061646\n",
      "Batch 3692 - loss: 0.5978808999061584\n",
      "Batch 3693 - loss: 0.5112135410308838\n",
      "Batch 3694 - loss: 0.44968146085739136\n",
      "Batch 3695 - loss: 0.49509674310684204\n",
      "Batch 3696 - loss: 0.5397178530693054\n",
      "Batch 3697 - loss: 0.5808866620063782\n",
      "Batch 3698 - loss: 0.5433439016342163\n",
      "Batch 3699 - loss: 0.5828117728233337\n",
      "Batch 3700 - loss: 0.49941951036453247\n",
      "Batch 3701 - loss: 0.5229289531707764\n",
      "Batch 3702 - loss: 0.6104650497436523\n",
      "Batch 3703 - loss: 0.49202245473861694\n",
      "Batch 3704 - loss: 0.5284304022789001\n",
      "Batch 3705 - loss: 0.5241780877113342\n",
      "Batch 3706 - loss: 0.5210261940956116\n",
      "Batch 3707 - loss: 0.5174368023872375\n",
      "Batch 3708 - loss: 0.570896565914154\n",
      "Batch 3709 - loss: 0.539644718170166\n",
      "Batch 3710 - loss: 0.6437177062034607\n",
      "Batch 3711 - loss: 0.575670599937439\n",
      "Batch 3712 - loss: 0.5054050087928772\n",
      "Batch 3713 - loss: 0.5094693303108215\n",
      "Batch 3714 - loss: 0.5363134145736694\n",
      "Batch 3715 - loss: 0.5173134207725525\n",
      "Batch 3716 - loss: 0.4869979918003082\n",
      "Batch 3717 - loss: 0.4838787913322449\n",
      "Batch 3718 - loss: 0.485734224319458\n",
      "Batch 3719 - loss: 0.5026392936706543\n",
      "Batch 3720 - loss: 0.5000322461128235\n",
      "Batch 3721 - loss: 0.5515886545181274\n",
      "Batch 3722 - loss: 0.5821810960769653\n",
      "Batch 3723 - loss: 0.5483994483947754\n",
      "Batch 3724 - loss: 0.5149434804916382\n",
      "Batch 3725 - loss: 0.4778006970882416\n",
      "Batch 3726 - loss: 0.5328854918479919\n",
      "Batch 3727 - loss: 0.5292341709136963\n",
      "Batch 3728 - loss: 0.5007013082504272\n",
      "Batch 3729 - loss: 0.5315898656845093\n",
      "Batch 3730 - loss: 0.5319302678108215\n",
      "Batch 3731 - loss: 0.513317883014679\n",
      "Batch 3732 - loss: 0.575587272644043\n",
      "Batch 3733 - loss: 0.5181609988212585\n",
      "Batch 3734 - loss: 0.4845443069934845\n",
      "Batch 3735 - loss: 0.4641793668270111\n",
      "Batch 3736 - loss: 0.4997642934322357\n",
      "Batch 3737 - loss: 0.47675105929374695\n",
      "Batch 3738 - loss: 0.48346978425979614\n",
      "Batch 3739 - loss: 0.5847508311271667\n",
      "Batch 3740 - loss: 0.516208827495575\n",
      "Batch 3741 - loss: 0.5172446966171265\n",
      "Batch 3742 - loss: 0.5529477000236511\n",
      "Batch 3743 - loss: 0.5392971038818359\n",
      "Batch 3744 - loss: 0.5584969520568848\n",
      "Batch 3745 - loss: 0.6151168942451477\n",
      "Batch 3746 - loss: 0.4864963889122009\n",
      "Batch 3747 - loss: 0.563836395740509\n",
      "Batch 3748 - loss: 0.5346866250038147\n",
      "Batch 3749 - loss: 0.514523983001709\n",
      "Batch 3750 - loss: 0.49285516142845154\n",
      "Batch 3751 - loss: 0.4982048571109772\n",
      "Batch 3752 - loss: 0.5199251770973206\n",
      "Batch 3753 - loss: 0.5201453566551208\n",
      "Batch 3754 - loss: 0.41974273324012756\n",
      "Batch 3755 - loss: 0.5909680724143982\n",
      "Batch 3756 - loss: 0.48757460713386536\n",
      "Batch 3757 - loss: 0.5761517882347107\n",
      "Batch 3758 - loss: 0.596322774887085\n",
      "Batch 3759 - loss: 0.5306347012519836\n",
      "Batch 3760 - loss: 0.5543649792671204\n",
      "Batch 3761 - loss: 0.5296990275382996\n",
      "Batch 3762 - loss: 0.512096643447876\n",
      "Batch 3763 - loss: 0.47805237770080566\n",
      "Batch 3764 - loss: 0.5151152610778809\n",
      "Batch 3765 - loss: 0.5617280006408691\n",
      "Batch 3766 - loss: 0.5023674368858337\n",
      "Batch 3767 - loss: 0.5642555952072144\n",
      "Batch 3768 - loss: 0.5583478808403015\n",
      "Batch 3769 - loss: 0.5018332004547119\n",
      "Batch 3770 - loss: 0.5065810680389404\n",
      "Batch 3771 - loss: 0.5266373157501221\n",
      "Batch 3772 - loss: 0.5555844902992249\n",
      "Batch 3773 - loss: 0.5312386751174927\n",
      "Batch 3774 - loss: 0.47712746262550354\n",
      "Batch 3775 - loss: 0.5225783586502075\n",
      "Batch 3776 - loss: 0.5728721022605896\n",
      "Batch 3777 - loss: 0.5539548993110657\n",
      "Batch 3778 - loss: 0.5459650158882141\n",
      "Batch 3779 - loss: 0.4683372676372528\n",
      "Batch 3780 - loss: 0.48546481132507324\n",
      "Batch 3781 - loss: 0.46961623430252075\n",
      "Batch 3782 - loss: 0.5465586185455322\n",
      "Batch 3783 - loss: 0.4736584722995758\n",
      "Batch 3784 - loss: 0.4989100992679596\n",
      "Batch 3785 - loss: 0.5255585312843323\n",
      "Batch 3786 - loss: 0.6478903889656067\n",
      "Batch 3787 - loss: 0.5551941990852356\n",
      "Batch 3788 - loss: 0.5267584323883057\n",
      "Batch 3789 - loss: 0.5258141160011292\n",
      "Batch 3790 - loss: 0.48348090052604675\n",
      "Batch 3791 - loss: 0.5095491409301758\n",
      "Batch 3792 - loss: 0.48331400752067566\n",
      "Batch 3793 - loss: 0.5188645720481873\n",
      "Batch 3794 - loss: 0.4970126152038574\n",
      "Batch 3795 - loss: 0.5172014832496643\n",
      "Batch 3796 - loss: 0.572771430015564\n",
      "Batch 3797 - loss: 0.5191348195075989\n",
      "Batch 3798 - loss: 0.560990571975708\n",
      "Batch 3799 - loss: 0.5274699330329895\n",
      "Batch 3800 - loss: 0.5597425103187561\n",
      "Batch 3801 - loss: 0.5335215330123901\n",
      "Batch 3802 - loss: 0.5113006234169006\n",
      "Batch 3803 - loss: 0.5356171727180481\n",
      "Batch 3804 - loss: 0.496613085269928\n",
      "Batch 3805 - loss: 0.5120739340782166\n",
      "Batch 3806 - loss: 0.5139347314834595\n",
      "Batch 3807 - loss: 0.5012663006782532\n",
      "Batch 3808 - loss: 0.535309910774231\n",
      "Batch 3809 - loss: 0.6022387742996216\n",
      "Batch 3810 - loss: 0.5112910866737366\n",
      "Batch 3811 - loss: 0.4949512779712677\n",
      "Batch 3812 - loss: 0.5362588763237\n",
      "Batch 3813 - loss: 0.5104023814201355\n",
      "Batch 3814 - loss: 0.5952574014663696\n",
      "Batch 3815 - loss: 0.5703330636024475\n",
      "Batch 3816 - loss: 0.522403359413147\n",
      "Batch 3817 - loss: 0.4481961131095886\n",
      "Batch 3818 - loss: 0.4584934711456299\n",
      "Batch 3819 - loss: 0.5262693166732788\n",
      "Batch 3820 - loss: 0.5104381442070007\n",
      "Batch 3821 - loss: 0.5284411311149597\n",
      "Batch 3822 - loss: 0.5018711686134338\n",
      "Batch 3823 - loss: 0.5489202737808228\n",
      "Batch 3824 - loss: 0.5299842953681946\n",
      "Batch 3825 - loss: 0.5998795628547668\n",
      "Batch 3826 - loss: 0.47444644570350647\n",
      "Batch 3827 - loss: 0.5358476638793945\n",
      "Batch 3828 - loss: 0.5231914520263672\n",
      "Batch 3829 - loss: 0.5289809703826904\n",
      "Batch 3830 - loss: 0.5439510941505432\n",
      "Batch 3831 - loss: 0.5030640363693237\n",
      "Batch 3832 - loss: 0.5447589159011841\n",
      "Batch 3833 - loss: 0.465395987033844\n",
      "Batch 3834 - loss: 0.48216015100479126\n",
      "Batch 3835 - loss: 0.5467186570167542\n",
      "Batch 3836 - loss: 0.52033931016922\n",
      "Batch 3837 - loss: 0.5153976082801819\n",
      "Batch 3838 - loss: 0.5711163878440857\n",
      "Batch 3839 - loss: 0.49799150228500366\n",
      "Batch 3840 - loss: 0.5479780435562134\n",
      "Batch 3841 - loss: 0.496473491191864\n",
      "Batch 3842 - loss: 0.5816165208816528\n",
      "Batch 3843 - loss: 0.5354924201965332\n",
      "Batch 3844 - loss: 0.5398671627044678\n",
      "Batch 3845 - loss: 0.5644432902336121\n",
      "Batch 3846 - loss: 0.5064116716384888\n",
      "Batch 3847 - loss: 0.5322206020355225\n",
      "Batch 3848 - loss: 0.5590128302574158\n",
      "Batch 3849 - loss: 0.5499744415283203\n",
      "Batch 3850 - loss: 0.4674812853336334\n",
      "Batch 3851 - loss: 0.5863421559333801\n",
      "Batch 3852 - loss: 0.5349540710449219\n",
      "Batch 3853 - loss: 0.5039084553718567\n",
      "Batch 3854 - loss: 0.5661464929580688\n",
      "Batch 3855 - loss: 0.5246939659118652\n",
      "Batch 3856 - loss: 0.5460439920425415\n",
      "Batch 3857 - loss: 0.47491011023521423\n",
      "Batch 3858 - loss: 0.5623325705528259\n",
      "Batch 3859 - loss: 0.5086159110069275\n",
      "Batch 3860 - loss: 0.5752451419830322\n",
      "Batch 3861 - loss: 0.564851701259613\n",
      "Batch 3862 - loss: 0.5651484131813049\n",
      "Batch 3863 - loss: 0.5044025778770447\n",
      "Batch 3864 - loss: 0.4781550168991089\n",
      "Batch 3865 - loss: 0.5349487066268921\n",
      "Batch 3866 - loss: 0.4747454822063446\n",
      "Batch 3867 - loss: 0.5520278215408325\n",
      "Batch 3868 - loss: 0.5785844922065735\n",
      "Batch 3869 - loss: 0.5111085772514343\n",
      "Batch 3870 - loss: 0.50853431224823\n",
      "Batch 3871 - loss: 0.4996625483036041\n",
      "Batch 3872 - loss: 0.4790516793727875\n",
      "Batch 3873 - loss: 0.566504716873169\n",
      "Batch 3874 - loss: 0.5346777439117432\n",
      "Batch 3875 - loss: 0.5643390417098999\n",
      "Batch 3876 - loss: 0.43293797969818115\n",
      "Batch 3877 - loss: 0.5392580628395081\n",
      "Batch 3878 - loss: 0.532183825969696\n",
      "Batch 3879 - loss: 0.5179672837257385\n",
      "Batch 3880 - loss: 0.5042457580566406\n",
      "Batch 3881 - loss: 0.5624086260795593\n",
      "Batch 3882 - loss: 0.558883786201477\n",
      "Batch 3883 - loss: 0.5224553346633911\n",
      "Batch 3884 - loss: 0.49059388041496277\n",
      "Batch 3885 - loss: 0.5156871676445007\n",
      "Batch 3886 - loss: 0.5261331796646118\n",
      "Batch 3887 - loss: 0.5012189149856567\n",
      "Batch 3888 - loss: 0.49754828214645386\n",
      "Batch 3889 - loss: 0.504055917263031\n",
      "Batch 3890 - loss: 0.5717459917068481\n",
      "Batch 3891 - loss: 0.5135008096694946\n",
      "Batch 3892 - loss: 0.5288568735122681\n",
      "Batch 3893 - loss: 0.5445854663848877\n",
      "Batch 3894 - loss: 0.5734713673591614\n",
      "Batch 3895 - loss: 0.5274307131767273\n",
      "Batch 3896 - loss: 0.5185943245887756\n",
      "Batch 3897 - loss: 0.5358060598373413\n",
      "Batch 3898 - loss: 0.5280480980873108\n",
      "Batch 3899 - loss: 0.48921942710876465\n",
      "Batch 3900 - loss: 0.5238142609596252\n",
      "Batch 3901 - loss: 0.5089354515075684\n",
      "Batch 3902 - loss: 0.514197826385498\n",
      "Batch 3903 - loss: 0.4822033941745758\n",
      "Batch 3904 - loss: 0.5764033794403076\n",
      "Batch 3905 - loss: 0.5100915431976318\n",
      "Batch 3906 - loss: 0.5239812731742859\n",
      "Batch 3907 - loss: 0.48227396607398987\n",
      "Batch 3908 - loss: 0.5015296339988708\n",
      "Batch 3909 - loss: 0.5018733739852905\n",
      "Batch 3910 - loss: 0.5081807374954224\n",
      "Batch 3911 - loss: 0.5248098373413086\n",
      "Batch 3912 - loss: 0.5951523184776306\n",
      "Batch 3913 - loss: 0.5845125913619995\n",
      "Batch 3914 - loss: 0.5395666360855103\n",
      "Batch 3915 - loss: 0.542277991771698\n",
      "Batch 3916 - loss: 0.565143346786499\n",
      "Batch 3917 - loss: 0.495183527469635\n",
      "Batch 3918 - loss: 0.5404837727546692\n",
      "Batch 3919 - loss: 0.5037391185760498\n",
      "Batch 3920 - loss: 0.5205148458480835\n",
      "Batch 3921 - loss: 0.5267929434776306\n",
      "Batch 3922 - loss: 0.5093448162078857\n",
      "Batch 3923 - loss: 0.5309130549430847\n",
      "Batch 3924 - loss: 0.5091768503189087\n",
      "Batch 3925 - loss: 0.5160181522369385\n",
      "Batch 3926 - loss: 0.5741969347000122\n",
      "Batch 3927 - loss: 0.4922281801700592\n",
      "Batch 3928 - loss: 0.5287441611289978\n",
      "Batch 3929 - loss: 0.5741622447967529\n",
      "Batch 3930 - loss: 0.5230981111526489\n",
      "Batch 3931 - loss: 0.5101783275604248\n",
      "Batch 3932 - loss: 0.502957284450531\n",
      "Batch 3933 - loss: 0.5334822535514832\n",
      "Batch 3934 - loss: 0.49118784070014954\n",
      "Batch 3935 - loss: 0.5239493250846863\n",
      "Batch 3936 - loss: 0.5661213994026184\n",
      "Batch 3937 - loss: 0.5530121922492981\n",
      "Batch 3938 - loss: 0.5223950147628784\n",
      "Batch 3939 - loss: 0.5840526819229126\n",
      "Batch 3940 - loss: 0.5396357178688049\n",
      "Batch 3941 - loss: 0.5820056200027466\n",
      "Batch 3942 - loss: 0.5240256190299988\n",
      "Batch 3943 - loss: 0.5701040625572205\n",
      "Batch 3944 - loss: 0.521795928478241\n",
      "Batch 3945 - loss: 0.5723863244056702\n",
      "Batch 3946 - loss: 0.5208005905151367\n",
      "Batch 3947 - loss: 0.5423840284347534\n",
      "Batch 3948 - loss: 0.5078915357589722\n",
      "Batch 3949 - loss: 0.49950671195983887\n",
      "Batch 3950 - loss: 0.5480875968933105\n",
      "Batch 3951 - loss: 0.49369388818740845\n",
      "Batch 3952 - loss: 0.4591016471385956\n",
      "Batch 3953 - loss: 0.5155553817749023\n",
      "Batch 3954 - loss: 0.48933279514312744\n",
      "Batch 3955 - loss: 0.5759462118148804\n",
      "Batch 3956 - loss: 0.5531015396118164\n",
      "Batch 3957 - loss: 0.5010877251625061\n",
      "Batch 3958 - loss: 0.5371344685554504\n",
      "Batch 3959 - loss: 0.49880099296569824\n",
      "Batch 3960 - loss: 0.552463173866272\n",
      "Batch 3961 - loss: 0.5050916075706482\n",
      "Batch 3962 - loss: 0.48776617646217346\n",
      "Batch 3963 - loss: 0.5249372124671936\n",
      "Batch 3964 - loss: 0.5307250022888184\n",
      "Batch 3965 - loss: 0.5340858697891235\n",
      "Batch 3966 - loss: 0.5016114711761475\n",
      "Batch 3967 - loss: 0.4842197299003601\n",
      "Batch 3968 - loss: 0.4884257912635803\n",
      "Batch 3969 - loss: 0.5038529634475708\n",
      "Batch 3970 - loss: 0.526148796081543\n",
      "Batch 3971 - loss: 0.5399711728096008\n",
      "Batch 3972 - loss: 0.47233739495277405\n",
      "Batch 3973 - loss: 0.4463523328304291\n",
      "Batch 3974 - loss: 0.555193305015564\n",
      "Batch 3975 - loss: 0.5182614326477051\n",
      "Batch 3976 - loss: 0.6127512454986572\n",
      "Batch 3977 - loss: 0.6229214668273926\n",
      "Batch 3978 - loss: 0.5638272762298584\n",
      "Batch 3979 - loss: 0.5213823318481445\n",
      "Batch 3980 - loss: 0.5076775550842285\n",
      "Batch 3981 - loss: 0.5031843781471252\n",
      "Batch 3982 - loss: 0.49945124983787537\n",
      "Batch 3983 - loss: 0.5449894070625305\n",
      "Batch 3984 - loss: 0.5625834465026855\n",
      "Batch 3985 - loss: 0.46741652488708496\n",
      "Batch 3986 - loss: 0.48677048087120056\n",
      "Batch 3987 - loss: 0.5671460628509521\n",
      "Batch 3988 - loss: 0.48109331727027893\n",
      "Batch 3989 - loss: 0.5183839201927185\n",
      "Batch 3990 - loss: 0.5423094630241394\n",
      "Batch 3991 - loss: 0.4683492183685303\n",
      "Batch 3992 - loss: 0.5128780007362366\n",
      "Batch 3993 - loss: 0.5273324251174927\n",
      "Batch 3994 - loss: 0.5637826323509216\n",
      "Batch 3995 - loss: 0.5760035514831543\n",
      "Batch 3996 - loss: 0.5300790667533875\n",
      "Batch 3997 - loss: 0.525516927242279\n",
      "Batch 3998 - loss: 0.5066816210746765\n",
      "Batch 3999 - loss: 0.5026043057441711\n",
      "Batch 4000 - loss: 0.5197784900665283\n",
      "Batch 4001 - loss: 0.5259281992912292\n",
      "Batch 4002 - loss: 0.5952628254890442\n",
      "Batch 4003 - loss: 0.4969945549964905\n",
      "Batch 4004 - loss: 0.5263844132423401\n",
      "Batch 4005 - loss: 0.5436169505119324\n",
      "Batch 4006 - loss: 0.5554367303848267\n",
      "Batch 4007 - loss: 0.4789736270904541\n",
      "Batch 4008 - loss: 0.5623694062232971\n",
      "Batch 4009 - loss: 0.5820018649101257\n",
      "Batch 4010 - loss: 0.5468968749046326\n",
      "Batch 4011 - loss: 0.5179690718650818\n",
      "Batch 4012 - loss: 0.5466447472572327\n",
      "Batch 4013 - loss: 0.5237478017807007\n",
      "Batch 4014 - loss: 0.4977492094039917\n",
      "Batch 4015 - loss: 0.5023303031921387\n",
      "Batch 4016 - loss: 0.5480366349220276\n",
      "Batch 4017 - loss: 0.5445197224617004\n",
      "Batch 4018 - loss: 0.5091195106506348\n",
      "Batch 4019 - loss: 0.5725414752960205\n",
      "Batch 4020 - loss: 0.4819892644882202\n",
      "Batch 4021 - loss: 0.4768929183483124\n",
      "Batch 4022 - loss: 0.6172058582305908\n",
      "Batch 4023 - loss: 0.53689044713974\n",
      "Batch 4024 - loss: 0.5855036377906799\n",
      "Batch 4025 - loss: 0.5616910457611084\n",
      "Batch 4026 - loss: 0.5941516757011414\n",
      "Batch 4027 - loss: 0.5209364891052246\n",
      "Batch 4028 - loss: 0.5194852352142334\n",
      "Batch 4029 - loss: 0.544937014579773\n",
      "Batch 4030 - loss: 0.5001881122589111\n",
      "Batch 4031 - loss: 0.48308590054512024\n",
      "Batch 4032 - loss: 0.5613036751747131\n",
      "Batch 4033 - loss: 0.5555850863456726\n",
      "Batch 4034 - loss: 0.5386802554130554\n",
      "Batch 4035 - loss: 0.52544766664505\n",
      "Batch 4036 - loss: 0.5136399865150452\n",
      "Batch 4037 - loss: 0.5150631070137024\n",
      "Batch 4038 - loss: 0.5544142127037048\n",
      "Batch 4039 - loss: 0.5300528407096863\n",
      "Batch 4040 - loss: 0.532473087310791\n",
      "Batch 4041 - loss: 0.563437819480896\n",
      "Batch 4042 - loss: 0.5406023859977722\n",
      "Batch 4043 - loss: 0.5085553526878357\n",
      "Batch 4044 - loss: 0.46735963225364685\n",
      "Batch 4045 - loss: 0.5342342257499695\n",
      "Batch 4046 - loss: 0.49770426750183105\n",
      "Batch 4047 - loss: 0.4668556749820709\n",
      "Batch 4048 - loss: 0.49907588958740234\n",
      "Batch 4049 - loss: 0.5352252125740051\n",
      "Batch 4050 - loss: 0.4937865734100342\n",
      "Batch 4051 - loss: 0.48767775297164917\n",
      "Batch 4052 - loss: 0.5023722052574158\n",
      "Batch 4053 - loss: 0.4938793480396271\n",
      "Batch 4054 - loss: 0.5280269384384155\n",
      "Batch 4055 - loss: 0.4786972403526306\n",
      "Batch 4056 - loss: 0.5123745799064636\n",
      "Batch 4057 - loss: 0.5673710107803345\n",
      "Batch 4058 - loss: 0.47499701380729675\n",
      "Batch 4059 - loss: 0.5401297807693481\n",
      "Batch 4060 - loss: 0.46428030729293823\n",
      "Batch 4061 - loss: 0.5437576770782471\n",
      "Batch 4062 - loss: 0.543865978717804\n",
      "Batch 4063 - loss: 0.5743955373764038\n",
      "Batch 4064 - loss: 0.4763078987598419\n",
      "Batch 4065 - loss: 0.4802119731903076\n",
      "Batch 4066 - loss: 0.5807825922966003\n",
      "Batch 4067 - loss: 0.452426552772522\n",
      "Batch 4068 - loss: 0.5571624040603638\n",
      "Batch 4069 - loss: 0.5613833665847778\n",
      "Batch 4070 - loss: 0.48117804527282715\n",
      "Batch 4071 - loss: 0.5353425145149231\n",
      "Batch 4072 - loss: 0.49776285886764526\n",
      "Batch 4073 - loss: 0.5437695980072021\n",
      "Batch 4074 - loss: 0.5335198044776917\n",
      "Batch 4075 - loss: 0.49925497174263\n",
      "Batch 4076 - loss: 0.5373761653900146\n",
      "Batch 4077 - loss: 0.5065363049507141\n",
      "Batch 4078 - loss: 0.525820255279541\n",
      "Batch 4079 - loss: 0.4857601523399353\n",
      "Batch 4080 - loss: 0.5136116743087769\n",
      "Batch 4081 - loss: 0.5441391468048096\n",
      "Batch 4082 - loss: 0.491353303194046\n",
      "Batch 4083 - loss: 0.5774250030517578\n",
      "Batch 4084 - loss: 0.56451016664505\n",
      "Batch 4085 - loss: 0.5613869428634644\n",
      "Batch 4086 - loss: 0.506578266620636\n",
      "Batch 4087 - loss: 0.5361916422843933\n",
      "Batch 4088 - loss: 0.5477789640426636\n",
      "Batch 4089 - loss: 0.6013094782829285\n",
      "Batch 4090 - loss: 0.46803411841392517\n",
      "Batch 4091 - loss: 0.49232128262519836\n",
      "Batch 4092 - loss: 0.5082772970199585\n",
      "Batch 4093 - loss: 0.43782350420951843\n",
      "Batch 4094 - loss: 0.5217030644416809\n",
      "Batch 4095 - loss: 0.5445182919502258\n",
      "Batch 4096 - loss: 0.5037333965301514\n",
      "Batch 4097 - loss: 0.5123118758201599\n",
      "Batch 4098 - loss: 0.4512401223182678\n",
      "Batch 4099 - loss: 0.5207034349441528\n",
      "Batch 4100 - loss: 0.4806133806705475\n",
      "Batch 4101 - loss: 0.5255405306816101\n",
      "Batch 4102 - loss: 0.5945210456848145\n",
      "Batch 4103 - loss: 0.5081504583358765\n",
      "Batch 4104 - loss: 0.5142830610275269\n",
      "Batch 4105 - loss: 0.49126216769218445\n",
      "Batch 4106 - loss: 0.4452213644981384\n",
      "Batch 4107 - loss: 0.5207463502883911\n",
      "Batch 4108 - loss: 0.5300830602645874\n",
      "Batch 4109 - loss: 0.5442858338356018\n",
      "Batch 4110 - loss: 0.5149741768836975\n",
      "Batch 4111 - loss: 0.5126858353614807\n",
      "Batch 4112 - loss: 0.4785504639148712\n",
      "Batch 4113 - loss: 0.7181077003479004\n",
      "Batch 4114 - loss: 0.5328255295753479\n",
      "Batch 4115 - loss: 0.4710637629032135\n",
      "Batch 4116 - loss: 0.5636997818946838\n",
      "Batch 4117 - loss: 0.5925720930099487\n",
      "Batch 4118 - loss: 0.5206607580184937\n",
      "Batch 4119 - loss: 0.5369024276733398\n",
      "Batch 4120 - loss: 0.5626257658004761\n",
      "Batch 4121 - loss: 0.5561747550964355\n",
      "Batch 4122 - loss: 0.49248960614204407\n",
      "Batch 4123 - loss: 0.4829377233982086\n",
      "Batch 4124 - loss: 0.4290447235107422\n",
      "Batch 4125 - loss: 0.5048038959503174\n",
      "Batch 4126 - loss: 0.6065720319747925\n",
      "Batch 4127 - loss: 0.4885324239730835\n",
      "Batch 4128 - loss: 0.5562506914138794\n",
      "Batch 4129 - loss: 0.5211036205291748\n",
      "Batch 4130 - loss: 0.5560342073440552\n",
      "Batch 4131 - loss: 0.4461388885974884\n",
      "Batch 4132 - loss: 0.49977201223373413\n",
      "Batch 4133 - loss: 0.6619207859039307\n",
      "Batch 4134 - loss: 0.6205378174781799\n",
      "Batch 4135 - loss: 0.5736679434776306\n",
      "Batch 4136 - loss: 0.4971051812171936\n",
      "Batch 4137 - loss: 0.5635853409767151\n",
      "Batch 4138 - loss: 0.5291120409965515\n",
      "Batch 4139 - loss: 0.4769313931465149\n",
      "Batch 4140 - loss: 0.5660305619239807\n",
      "Batch 4141 - loss: 0.4798526465892792\n",
      "Batch 4142 - loss: 0.5330002307891846\n",
      "Batch 4143 - loss: 0.601240873336792\n",
      "Batch 4144 - loss: 0.5220552086830139\n",
      "Batch 4145 - loss: 0.4815959930419922\n",
      "Batch 4146 - loss: 0.5096594095230103\n",
      "Batch 4147 - loss: 0.5344622731208801\n",
      "Batch 4148 - loss: 0.5645667910575867\n",
      "Batch 4149 - loss: 0.5255609154701233\n",
      "Batch 4150 - loss: 0.5220076441764832\n",
      "Batch 4151 - loss: 0.4899977445602417\n",
      "Batch 4152 - loss: 0.5169253349304199\n",
      "Batch 4153 - loss: 0.6297439336776733\n",
      "Batch 4154 - loss: 0.5407500267028809\n",
      "Batch 4155 - loss: 0.5602713823318481\n",
      "Batch 4156 - loss: 0.48998913168907166\n",
      "Batch 4157 - loss: 0.5305119752883911\n",
      "Batch 4158 - loss: 0.5228294134140015\n",
      "Batch 4159 - loss: 0.5101349353790283\n",
      "Batch 4160 - loss: 0.6701221466064453\n",
      "Batch 4161 - loss: 0.5050467252731323\n",
      "Batch 4162 - loss: 0.45899099111557007\n",
      "Batch 4163 - loss: 0.46598103642463684\n",
      "Batch 4164 - loss: 0.4573437571525574\n",
      "Batch 4165 - loss: 0.4944624900817871\n",
      "Batch 4166 - loss: 0.542216956615448\n",
      "Batch 4167 - loss: 0.5308896899223328\n",
      "Batch 4168 - loss: 0.5378431081771851\n",
      "Batch 4169 - loss: 0.4956514537334442\n",
      "Batch 4170 - loss: 0.5217538475990295\n",
      "Batch 4171 - loss: 0.5035004615783691\n",
      "Batch 4172 - loss: 0.5388468503952026\n",
      "Batch 4173 - loss: 0.5462293028831482\n",
      "Batch 4174 - loss: 0.5141833424568176\n",
      "Batch 4175 - loss: 0.4961589276790619\n",
      "Batch 4176 - loss: 0.516122043132782\n",
      "Batch 4177 - loss: 0.5264804363250732\n",
      "Batch 4178 - loss: 0.5180248618125916\n",
      "Batch 4179 - loss: 0.5513824820518494\n",
      "Batch 4180 - loss: 0.45919305086135864\n",
      "Batch 4181 - loss: 0.49544480443000793\n",
      "Batch 4182 - loss: 0.5143099427223206\n",
      "Batch 4183 - loss: 0.5807846188545227\n",
      "Batch 4184 - loss: 0.5452760457992554\n",
      "Batch 4185 - loss: 0.48133328557014465\n",
      "Batch 4186 - loss: 0.5230614542961121\n",
      "Batch 4187 - loss: 0.5595316886901855\n",
      "Batch 4188 - loss: 0.5623929500579834\n",
      "Batch 4189 - loss: 0.5063713788986206\n",
      "Batch 4190 - loss: 0.47921842336654663\n",
      "Batch 4191 - loss: 0.5200805068016052\n",
      "Batch 4192 - loss: 0.5504487156867981\n",
      "Batch 4193 - loss: 0.5341800451278687\n",
      "Batch 4194 - loss: 0.5898783802986145\n",
      "Batch 4195 - loss: 0.5291574597358704\n",
      "Batch 4196 - loss: 0.5341785550117493\n",
      "Batch 4197 - loss: 0.480448842048645\n",
      "Batch 4198 - loss: 0.5037661790847778\n",
      "Batch 4199 - loss: 0.5007262229919434\n",
      "Batch 4200 - loss: 0.5488759875297546\n",
      "Batch 4201 - loss: 0.5865949392318726\n",
      "Batch 4202 - loss: 0.5479634404182434\n",
      "Batch 4203 - loss: 0.4967561364173889\n",
      "Batch 4204 - loss: 0.4751972556114197\n",
      "Batch 4205 - loss: 0.5195518732070923\n",
      "Batch 4206 - loss: 0.5640515089035034\n",
      "Batch 4207 - loss: 0.5296743512153625\n",
      "Batch 4208 - loss: 0.5557657480239868\n",
      "Batch 4209 - loss: 0.5421491861343384\n",
      "Batch 4210 - loss: 0.5128151178359985\n",
      "Batch 4211 - loss: 0.5334100723266602\n",
      "Batch 4212 - loss: 0.4914347231388092\n",
      "Batch 4213 - loss: 0.5742630958557129\n",
      "Batch 4214 - loss: 0.5626702308654785\n",
      "Batch 4215 - loss: 0.5739067792892456\n",
      "Batch 4216 - loss: 0.48856422305107117\n",
      "Batch 4217 - loss: 0.461180180311203\n",
      "Batch 4218 - loss: 0.5083850622177124\n",
      "Batch 4219 - loss: 0.5366529822349548\n",
      "Batch 4220 - loss: 0.5550638437271118\n",
      "Batch 4221 - loss: 0.5577643513679504\n",
      "Batch 4222 - loss: 0.536043643951416\n",
      "Batch 4223 - loss: 0.5543335676193237\n",
      "Batch 4224 - loss: 0.5178532600402832\n",
      "Batch 4225 - loss: 0.5121563076972961\n",
      "Batch 4226 - loss: 0.5407028198242188\n",
      "Batch 4227 - loss: 0.49454641342163086\n",
      "Batch 4228 - loss: 0.5172896385192871\n",
      "Batch 4229 - loss: 0.5015689134597778\n",
      "Batch 4230 - loss: 0.5597610473632812\n",
      "Batch 4231 - loss: 0.48139306902885437\n",
      "Batch 4232 - loss: 0.5447232127189636\n",
      "Batch 4233 - loss: 0.5078577399253845\n",
      "Batch 4234 - loss: 0.5055130124092102\n",
      "Batch 4235 - loss: 0.49679097533226013\n",
      "Batch 4236 - loss: 0.515995979309082\n",
      "Batch 4237 - loss: 0.4900500178337097\n",
      "Batch 4238 - loss: 0.49642300605773926\n",
      "Batch 4239 - loss: 0.5822706818580627\n",
      "Batch 4240 - loss: 0.5626047253608704\n",
      "Batch 4241 - loss: 0.5305907130241394\n",
      "Batch 4242 - loss: 0.541295051574707\n",
      "Batch 4243 - loss: 0.5609475374221802\n",
      "Batch 4244 - loss: 0.47255489230155945\n",
      "Batch 4245 - loss: 0.47955119609832764\n",
      "Batch 4246 - loss: 0.492667019367218\n",
      "Batch 4247 - loss: 0.5431820750236511\n",
      "Batch 4248 - loss: 0.5544623136520386\n",
      "Batch 4249 - loss: 0.48366475105285645\n",
      "Batch 4250 - loss: 0.5121031999588013\n",
      "Batch 4251 - loss: 0.5295780897140503\n",
      "Batch 4252 - loss: 0.5109949707984924\n",
      "Batch 4253 - loss: 0.5657044053077698\n",
      "Batch 4254 - loss: 0.47922471165657043\n",
      "Batch 4255 - loss: 0.5464303493499756\n",
      "Batch 4256 - loss: 0.4960704743862152\n",
      "Batch 4257 - loss: 0.5113196969032288\n",
      "Batch 4258 - loss: 0.4722031354904175\n",
      "Batch 4259 - loss: 0.4775320887565613\n",
      "Batch 4260 - loss: 0.5035613179206848\n",
      "Batch 4261 - loss: 0.5203749537467957\n",
      "Batch 4262 - loss: 0.4836170971393585\n",
      "Batch 4263 - loss: 0.4846350848674774\n",
      "Batch 4264 - loss: 0.5219708681106567\n",
      "Batch 4265 - loss: 0.5250970125198364\n",
      "Batch 4266 - loss: 0.5342087149620056\n",
      "Batch 4267 - loss: 0.5890867114067078\n",
      "Batch 4268 - loss: 0.5296813249588013\n",
      "Batch 4269 - loss: 0.4797557294368744\n",
      "Batch 4270 - loss: 0.544358491897583\n",
      "Batch 4271 - loss: 0.5126035213470459\n",
      "Batch 4272 - loss: 0.5840014219284058\n",
      "Batch 4273 - loss: 0.5285120606422424\n",
      "Batch 4274 - loss: 0.5540829300880432\n",
      "Batch 4275 - loss: 0.5347780585289001\n",
      "Batch 4276 - loss: 0.5913066267967224\n",
      "Batch 4277 - loss: 0.4990680515766144\n",
      "Batch 4278 - loss: 0.5143609642982483\n",
      "Batch 4279 - loss: 0.5275823473930359\n",
      "Batch 4280 - loss: 0.5527524352073669\n",
      "Batch 4281 - loss: 0.5070112943649292\n",
      "Batch 4282 - loss: 0.439608097076416\n",
      "Batch 4283 - loss: 0.5060468316078186\n",
      "Batch 4284 - loss: 0.48368096351623535\n",
      "Batch 4285 - loss: 0.5420424938201904\n",
      "Batch 4286 - loss: 0.557766854763031\n",
      "Batch 4287 - loss: 0.5072683691978455\n",
      "Batch 4288 - loss: 0.5249437689781189\n",
      "Batch 4289 - loss: 0.5220580101013184\n",
      "Batch 4290 - loss: 0.49625450372695923\n",
      "Batch 4291 - loss: 0.5561050772666931\n",
      "Batch 4292 - loss: 0.5100744366645813\n",
      "Batch 4293 - loss: 0.5388395190238953\n",
      "Batch 4294 - loss: 0.5523004531860352\n",
      "Batch 4295 - loss: 0.5104185938835144\n",
      "Batch 4296 - loss: 0.5008912682533264\n",
      "Batch 4297 - loss: 0.5764235854148865\n",
      "Batch 4298 - loss: 0.4716689884662628\n",
      "Batch 4299 - loss: 0.5095032453536987\n",
      "Batch 4300 - loss: 0.5397080779075623\n",
      "Batch 4301 - loss: 0.5486509203910828\n",
      "Batch 4302 - loss: 0.5017534494400024\n",
      "Batch 4303 - loss: 0.553360104560852\n",
      "Batch 4304 - loss: 0.5103769302368164\n",
      "Batch 4305 - loss: 0.5034233331680298\n",
      "Batch 4306 - loss: 0.48175355792045593\n",
      "Batch 4307 - loss: 0.523120641708374\n",
      "Batch 4308 - loss: 0.5225034356117249\n",
      "Batch 4309 - loss: 0.5117030143737793\n",
      "Batch 4310 - loss: 0.4943590760231018\n",
      "Batch 4311 - loss: 0.5184637308120728\n",
      "Batch 4312 - loss: 0.529584527015686\n",
      "Batch 4313 - loss: 0.48209407925605774\n",
      "Batch 4314 - loss: 0.5106939673423767\n",
      "Batch 4315 - loss: 0.5655039548873901\n",
      "Batch 4316 - loss: 0.5065171718597412\n",
      "Batch 4317 - loss: 0.5872409343719482\n",
      "Batch 4318 - loss: 0.5148782730102539\n",
      "Batch 4319 - loss: 0.5218150615692139\n",
      "Batch 4320 - loss: 0.4707404375076294\n",
      "Batch 4321 - loss: 0.5127174854278564\n",
      "Batch 4322 - loss: 0.5410921573638916\n",
      "Batch 4323 - loss: 0.5359822511672974\n",
      "Batch 4324 - loss: 0.5188389420509338\n",
      "Batch 4325 - loss: 0.5078749060630798\n",
      "Batch 4326 - loss: 0.5221826434135437\n",
      "Batch 4327 - loss: 0.5148993134498596\n",
      "Batch 4328 - loss: 0.5472144484519958\n",
      "Batch 4329 - loss: 0.5386819243431091\n",
      "Batch 4330 - loss: 0.5119867324829102\n",
      "Batch 4331 - loss: 0.5141876339912415\n",
      "Batch 4332 - loss: 0.5213446021080017\n",
      "Batch 4333 - loss: 0.4860961437225342\n",
      "Batch 4334 - loss: 0.5011441111564636\n",
      "Batch 4335 - loss: 0.5455990433692932\n",
      "Batch 4336 - loss: 0.541841447353363\n",
      "Batch 4337 - loss: 0.5201579332351685\n",
      "Batch 4338 - loss: 0.43909522891044617\n",
      "Batch 4339 - loss: 0.5049920678138733\n",
      "Batch 4340 - loss: 0.5159483551979065\n",
      "Batch 4341 - loss: 0.5349700450897217\n",
      "Batch 4342 - loss: 0.5177375078201294\n",
      "Batch 4343 - loss: 0.5241498947143555\n",
      "Batch 4344 - loss: 0.5015507340431213\n",
      "Batch 4345 - loss: 0.4406314492225647\n",
      "Batch 4346 - loss: 0.5367792844772339\n",
      "Batch 4347 - loss: 0.5868890285491943\n",
      "Batch 4348 - loss: 0.5423322319984436\n",
      "Batch 4349 - loss: 0.48503196239471436\n",
      "Batch 4350 - loss: 0.5736880302429199\n",
      "Batch 4351 - loss: 0.5536713600158691\n",
      "Batch 4352 - loss: 0.5242340564727783\n",
      "Batch 4353 - loss: 0.5393842458724976\n",
      "Batch 4354 - loss: 0.5278043150901794\n",
      "Batch 4355 - loss: 0.5397183895111084\n",
      "Batch 4356 - loss: 0.5952784419059753\n",
      "Batch 4357 - loss: 0.5608258843421936\n",
      "Batch 4358 - loss: 0.4767279028892517\n",
      "Batch 4359 - loss: 0.48555058240890503\n",
      "Batch 4360 - loss: 0.56159907579422\n",
      "Batch 4361 - loss: 0.5881519317626953\n",
      "Batch 4362 - loss: 0.4716276228427887\n",
      "Batch 4363 - loss: 0.5714243650436401\n",
      "Batch 4364 - loss: 0.5308279395103455\n",
      "Batch 4365 - loss: 0.5540542006492615\n",
      "Batch 4366 - loss: 0.5521543025970459\n",
      "Batch 4367 - loss: 0.5055165886878967\n",
      "Batch 4368 - loss: 0.5614944696426392\n",
      "Batch 4369 - loss: 0.5159567594528198\n",
      "Batch 4370 - loss: 0.5897004008293152\n",
      "Batch 4371 - loss: 0.519454836845398\n",
      "Batch 4372 - loss: 0.5249625444412231\n",
      "Batch 4373 - loss: 0.5370314121246338\n",
      "Batch 4374 - loss: 0.4873170852661133\n",
      "Batch 4375 - loss: 0.49226319789886475\n",
      "Batch 4376 - loss: 0.5152262449264526\n",
      "Batch 4377 - loss: 0.5347471237182617\n",
      "Batch 4378 - loss: 0.5744906067848206\n",
      "Batch 4379 - loss: 0.5021558403968811\n",
      "Batch 4380 - loss: 0.5540792346000671\n",
      "Batch 4381 - loss: 0.5194255113601685\n",
      "Batch 4382 - loss: 0.4827730655670166\n",
      "Batch 4383 - loss: 0.5404168367385864\n",
      "Batch 4384 - loss: 0.5158619284629822\n",
      "Batch 4385 - loss: 0.4707548916339874\n",
      "Batch 4386 - loss: 0.5685843825340271\n",
      "Batch 4387 - loss: 0.5645901560783386\n",
      "Batch 4388 - loss: 0.45530781149864197\n",
      "Batch 4389 - loss: 0.49217846989631653\n",
      "Batch 4390 - loss: 0.5722760558128357\n",
      "Batch 4391 - loss: 0.5211493372917175\n",
      "Batch 4392 - loss: 0.5074349045753479\n",
      "Batch 4393 - loss: 0.6052083373069763\n",
      "Batch 4394 - loss: 0.5237911343574524\n",
      "Batch 4395 - loss: 0.5188579559326172\n",
      "Batch 4396 - loss: 0.49496594071388245\n",
      "Batch 4397 - loss: 0.5950149893760681\n",
      "Batch 4398 - loss: 0.5081031322479248\n",
      "Batch 4399 - loss: 0.4986538589000702\n",
      "Batch 4400 - loss: 0.5162156820297241\n",
      "Batch 4401 - loss: 0.4834649860858917\n",
      "Batch 4402 - loss: 0.5239386558532715\n",
      "Batch 4403 - loss: 0.5458067059516907\n",
      "Batch 4404 - loss: 0.4985111653804779\n",
      "Batch 4405 - loss: 0.46380627155303955\n",
      "Batch 4406 - loss: 0.5148451328277588\n",
      "Batch 4407 - loss: 0.54591304063797\n",
      "Batch 4408 - loss: 0.4936738908290863\n",
      "Batch 4409 - loss: 0.5447984933853149\n",
      "Batch 4410 - loss: 0.5224282145500183\n",
      "Batch 4411 - loss: 0.5176494121551514\n",
      "Batch 4412 - loss: 0.5372053384780884\n",
      "Batch 4413 - loss: 0.500942587852478\n",
      "Batch 4414 - loss: 0.5430362224578857\n",
      "Batch 4415 - loss: 0.5312797427177429\n",
      "Batch 4416 - loss: 0.5078436136245728\n",
      "Batch 4417 - loss: 0.539239764213562\n",
      "Batch 4418 - loss: 0.49569493532180786\n",
      "Batch 4419 - loss: 0.48024147748947144\n",
      "Batch 4420 - loss: 0.5341590046882629\n",
      "Batch 4421 - loss: 0.5005922913551331\n",
      "Batch 4422 - loss: 0.5265350341796875\n",
      "Batch 4423 - loss: 0.52851402759552\n",
      "Batch 4424 - loss: 0.5267903208732605\n",
      "Batch 4425 - loss: 0.4765847623348236\n",
      "Batch 4426 - loss: 0.5274412035942078\n",
      "Batch 4427 - loss: 0.5298768877983093\n",
      "Batch 4428 - loss: 0.5747382640838623\n",
      "Batch 4429 - loss: 0.5197044610977173\n",
      "Batch 4430 - loss: 0.4500964879989624\n",
      "Batch 4431 - loss: 0.5114834904670715\n",
      "Batch 4432 - loss: 0.5809494256973267\n",
      "Batch 4433 - loss: 0.5282878875732422\n",
      "Batch 4434 - loss: 0.554006814956665\n",
      "Batch 4435 - loss: 0.5169414281845093\n",
      "Batch 4436 - loss: 0.5105555057525635\n",
      "Batch 4437 - loss: 0.47636160254478455\n",
      "Batch 4438 - loss: 0.4821735620498657\n",
      "Batch 4439 - loss: 0.5266463756561279\n",
      "Batch 4440 - loss: 0.5055438876152039\n",
      "Batch 4441 - loss: 0.5311095118522644\n",
      "Batch 4442 - loss: 0.5226573944091797\n",
      "Batch 4443 - loss: 0.5364912748336792\n",
      "Batch 4444 - loss: 0.4875078797340393\n",
      "Batch 4445 - loss: 0.5693876147270203\n",
      "Batch 4446 - loss: 0.48567861318588257\n",
      "Batch 4447 - loss: 0.4733152389526367\n",
      "Batch 4448 - loss: 0.5387728214263916\n",
      "Batch 4449 - loss: 0.503555417060852\n",
      "Batch 4450 - loss: 0.5351384878158569\n",
      "Batch 4451 - loss: 0.5482890605926514\n",
      "Batch 4452 - loss: 0.5586465001106262\n",
      "Batch 4453 - loss: 0.4947057068347931\n",
      "Batch 4454 - loss: 0.5259153246879578\n",
      "Batch 4455 - loss: 0.521043598651886\n",
      "Batch 4456 - loss: 0.5636364221572876\n",
      "Batch 4457 - loss: 0.5210567712783813\n",
      "Batch 4458 - loss: 0.4908021092414856\n",
      "Batch 4459 - loss: 0.534020185470581\n",
      "Batch 4460 - loss: 0.4825083911418915\n",
      "Batch 4461 - loss: 0.5094116926193237\n",
      "Batch 4462 - loss: 0.5381084084510803\n",
      "Batch 4463 - loss: 0.48617058992385864\n",
      "Batch 4464 - loss: 0.5508251190185547\n",
      "Batch 4465 - loss: 0.5038352608680725\n",
      "Batch 4466 - loss: 0.5666509866714478\n",
      "Batch 4467 - loss: 0.5255839824676514\n",
      "Batch 4468 - loss: 0.5258817672729492\n",
      "Batch 4469 - loss: 0.5016883015632629\n",
      "Batch 4470 - loss: 0.5095228552818298\n",
      "Batch 4471 - loss: 0.5243555903434753\n",
      "Batch 4472 - loss: 0.5616329312324524\n",
      "Batch 4473 - loss: 0.5961055159568787\n",
      "Batch 4474 - loss: 0.4967099130153656\n",
      "Batch 4475 - loss: 0.5644617676734924\n",
      "Batch 4476 - loss: 0.5532347559928894\n",
      "Batch 4477 - loss: 0.5590943098068237\n",
      "Batch 4478 - loss: 0.46670427918434143\n",
      "Batch 4479 - loss: 0.5288829803466797\n",
      "Batch 4480 - loss: 0.5460473895072937\n",
      "Batch 4481 - loss: 0.5416624546051025\n",
      "Batch 4482 - loss: 0.5139979720115662\n",
      "Batch 4483 - loss: 0.5412521362304688\n",
      "Batch 4484 - loss: 0.51291424036026\n",
      "Batch 4485 - loss: 0.502352774143219\n",
      "Batch 4486 - loss: 0.5112422704696655\n",
      "Batch 4487 - loss: 0.5105684995651245\n",
      "Batch 4488 - loss: 0.5895204544067383\n",
      "Batch 4489 - loss: 0.5499376058578491\n",
      "Batch 4490 - loss: 0.47042161226272583\n",
      "Batch 4491 - loss: 0.5373579859733582\n",
      "Batch 4492 - loss: 0.49914059042930603\n",
      "Batch 4493 - loss: 0.5139095187187195\n",
      "Batch 4494 - loss: 0.5508443713188171\n",
      "Batch 4495 - loss: 0.5581062436103821\n",
      "Batch 4496 - loss: 0.46684473752975464\n",
      "Batch 4497 - loss: 0.4942949414253235\n",
      "Batch 4498 - loss: 0.47220075130462646\n",
      "Batch 4499 - loss: 0.4768950641155243\n",
      "Batch 4500 - loss: 0.5367069244384766\n",
      "Batch 4501 - loss: 0.5489716529846191\n",
      "Batch 4502 - loss: 0.5610306859016418\n",
      "Batch 4503 - loss: 0.5071488618850708\n",
      "Batch 4504 - loss: 0.45321956276893616\n",
      "Batch 4505 - loss: 0.5305174589157104\n",
      "Batch 4506 - loss: 0.5264414548873901\n",
      "Batch 4507 - loss: 0.48107776045799255\n",
      "Batch 4508 - loss: 0.5343007445335388\n",
      "Batch 4509 - loss: 0.519891619682312\n",
      "Batch 4510 - loss: 0.5174075961112976\n",
      "Batch 4511 - loss: 0.5832458138465881\n",
      "Batch 4512 - loss: 0.5178066492080688\n",
      "Batch 4513 - loss: 0.491548627614975\n",
      "Batch 4514 - loss: 0.5330910682678223\n",
      "Batch 4515 - loss: 0.4854036867618561\n",
      "Batch 4516 - loss: 0.4943273663520813\n",
      "Batch 4517 - loss: 0.5136294960975647\n",
      "Batch 4518 - loss: 0.5981698036193848\n",
      "Batch 4519 - loss: 0.5503562092781067\n",
      "Batch 4520 - loss: 0.5069282054901123\n",
      "Batch 4521 - loss: 0.5224365592002869\n",
      "Batch 4522 - loss: 0.4758304953575134\n",
      "Batch 4523 - loss: 0.5281869769096375\n",
      "Batch 4524 - loss: 0.5834497213363647\n",
      "Batch 4525 - loss: 0.481618732213974\n",
      "Batch 4526 - loss: 0.5223406553268433\n",
      "Batch 4527 - loss: 0.49259981513023376\n",
      "Batch 4528 - loss: 0.49906298518180847\n",
      "Batch 4529 - loss: 0.5147275328636169\n",
      "Batch 4530 - loss: 0.5361019968986511\n",
      "Batch 4531 - loss: 0.49828553199768066\n",
      "Batch 4532 - loss: 0.5397309064865112\n",
      "Batch 4533 - loss: 0.4849383533000946\n",
      "Batch 4534 - loss: 0.4999327063560486\n",
      "Batch 4535 - loss: 0.5371595621109009\n",
      "Batch 4536 - loss: 0.45220980048179626\n",
      "Batch 4537 - loss: 0.5053117871284485\n",
      "Batch 4538 - loss: 0.5387688279151917\n",
      "Batch 4539 - loss: 0.4564576745033264\n",
      "Batch 4540 - loss: 0.558631420135498\n",
      "Batch 4541 - loss: 0.4889999330043793\n",
      "Batch 4542 - loss: 0.5276419520378113\n",
      "Batch 4543 - loss: 0.47857093811035156\n",
      "Batch 4544 - loss: 0.48487481474876404\n",
      "Batch 4545 - loss: 0.527711033821106\n",
      "Batch 4546 - loss: 0.5379096269607544\n",
      "Batch 4547 - loss: 0.5560780763626099\n",
      "Batch 4548 - loss: 0.5899201035499573\n",
      "Batch 4549 - loss: 0.5500010251998901\n",
      "Batch 4550 - loss: 0.572363555431366\n",
      "Batch 4551 - loss: 0.5108248591423035\n",
      "Batch 4552 - loss: 0.5069845914840698\n",
      "Batch 4553 - loss: 0.4699437618255615\n",
      "Batch 4554 - loss: 0.5783180594444275\n",
      "Batch 4555 - loss: 0.502810537815094\n",
      "Batch 4556 - loss: 0.5688096880912781\n",
      "Batch 4557 - loss: 0.4857221841812134\n",
      "Batch 4558 - loss: 0.5278338193893433\n",
      "Batch 4559 - loss: 0.4797939360141754\n",
      "Batch 4560 - loss: 0.5332900285720825\n",
      "Batch 4561 - loss: 0.5127082467079163\n",
      "Batch 4562 - loss: 0.5822346806526184\n",
      "Batch 4563 - loss: 0.5991066098213196\n",
      "Batch 4564 - loss: 0.5360340476036072\n",
      "Batch 4565 - loss: 0.5335878729820251\n",
      "Batch 4566 - loss: 0.5139144659042358\n",
      "Batch 4567 - loss: 0.5548045039176941\n",
      "Batch 4568 - loss: 0.4529731273651123\n",
      "Batch 4569 - loss: 0.5252977013587952\n",
      "Batch 4570 - loss: 0.5334213972091675\n",
      "Batch 4571 - loss: 0.5040616393089294\n",
      "Batch 4572 - loss: 0.4878122806549072\n",
      "Batch 4573 - loss: 0.5432451367378235\n",
      "Batch 4574 - loss: 0.5334410071372986\n",
      "Batch 4575 - loss: 0.516893208026886\n",
      "Batch 4576 - loss: 0.5314408540725708\n",
      "Batch 4577 - loss: 0.506134033203125\n",
      "Batch 4578 - loss: 0.5099121928215027\n",
      "Batch 4579 - loss: 0.5621427297592163\n",
      "Batch 4580 - loss: 0.5609548091888428\n",
      "Batch 4581 - loss: 0.5289300084114075\n",
      "Batch 4582 - loss: 0.4672996699810028\n",
      "Batch 4583 - loss: 0.5387260913848877\n",
      "Batch 4584 - loss: 0.5546737909317017\n",
      "Batch 4585 - loss: 0.5296640396118164\n",
      "Batch 4586 - loss: 0.4867958724498749\n",
      "Batch 4587 - loss: 0.46062636375427246\n",
      "Batch 4588 - loss: 0.4991949796676636\n",
      "Batch 4589 - loss: 0.5007808208465576\n",
      "Batch 4590 - loss: 0.4926223158836365\n",
      "Batch 4591 - loss: 0.5187039971351624\n",
      "Batch 4592 - loss: 0.5232598781585693\n",
      "Batch 4593 - loss: 0.549509584903717\n",
      "Batch 4594 - loss: 0.45979559421539307\n",
      "Batch 4595 - loss: 0.5553411245346069\n",
      "Batch 4596 - loss: 0.4960452914237976\n",
      "Batch 4597 - loss: 0.48984476923942566\n",
      "Batch 4598 - loss: 0.6087012887001038\n",
      "Batch 4599 - loss: 0.5877689123153687\n",
      "Batch 4600 - loss: 0.5940608382225037\n",
      "Batch 4601 - loss: 0.5110200643539429\n",
      "Batch 4602 - loss: 0.49068358540534973\n",
      "Batch 4603 - loss: 0.5244178771972656\n",
      "Batch 4604 - loss: 0.5409853458404541\n",
      "Batch 4605 - loss: 0.5067728757858276\n",
      "Batch 4606 - loss: 0.5403268337249756\n",
      "Batch 4607 - loss: 0.45147034525871277\n",
      "Batch 4608 - loss: 0.48168525099754333\n",
      "Batch 4609 - loss: 0.5296311378479004\n",
      "Batch 4610 - loss: 0.5692977905273438\n",
      "Batch 4611 - loss: 0.5466199517250061\n",
      "Batch 4612 - loss: 0.47025689482688904\n",
      "Batch 4613 - loss: 0.5257450342178345\n",
      "Batch 4614 - loss: 0.46994927525520325\n",
      "Batch 4615 - loss: 0.5055261850357056\n",
      "Batch 4616 - loss: 0.5616771578788757\n",
      "Batch 4617 - loss: 0.5692341327667236\n",
      "Batch 4618 - loss: 0.5474003553390503\n",
      "Batch 4619 - loss: 0.557191014289856\n",
      "Batch 4620 - loss: 0.5862562656402588\n",
      "Batch 4621 - loss: 0.49035441875457764\n",
      "Batch 4622 - loss: 0.5445288419723511\n",
      "Batch 4623 - loss: 0.6077172160148621\n",
      "Batch 4624 - loss: 0.5140253901481628\n",
      "Batch 4625 - loss: 0.5163536667823792\n",
      "Batch 4626 - loss: 0.555288553237915\n",
      "Batch 4627 - loss: 0.564367413520813\n",
      "Batch 4628 - loss: 0.5187575817108154\n",
      "Batch 4629 - loss: 0.5187707543373108\n",
      "Batch 4630 - loss: 0.511045515537262\n",
      "Batch 4631 - loss: 0.5360212326049805\n",
      "Batch 4632 - loss: 0.547133207321167\n",
      "Batch 4633 - loss: 0.4598162770271301\n",
      "Batch 4634 - loss: 0.530994713306427\n",
      "Batch 4635 - loss: 0.5160149931907654\n",
      "Batch 4636 - loss: 0.47459861636161804\n",
      "Batch 4637 - loss: 0.5394318699836731\n",
      "Batch 4638 - loss: 0.495333731174469\n",
      "Batch 4639 - loss: 0.541912317276001\n",
      "Batch 4640 - loss: 0.5451899766921997\n",
      "Batch 4641 - loss: 0.49203771352767944\n",
      "Batch 4642 - loss: 0.518382728099823\n",
      "Batch 4643 - loss: 0.5055924654006958\n",
      "Batch 4644 - loss: 0.5269294381141663\n",
      "Batch 4645 - loss: 0.4967983365058899\n",
      "Batch 4646 - loss: 0.48233041167259216\n",
      "Batch 4647 - loss: 0.49875080585479736\n",
      "Batch 4648 - loss: 0.5540618896484375\n",
      "Batch 4649 - loss: 0.5399826169013977\n",
      "Batch 4650 - loss: 0.5421801209449768\n",
      "Batch 4651 - loss: 0.4934648871421814\n",
      "Batch 4652 - loss: 0.5259145498275757\n",
      "Batch 4653 - loss: 0.49905428290367126\n",
      "Batch 4654 - loss: 0.5303573608398438\n",
      "Batch 4655 - loss: 0.5537614822387695\n",
      "Batch 4656 - loss: 0.4734574258327484\n",
      "Batch 4657 - loss: 0.5264418721199036\n",
      "Batch 4658 - loss: 0.5486783981323242\n",
      "Batch 4659 - loss: 0.45433154702186584\n",
      "Batch 4660 - loss: 0.47562021017074585\n",
      "Batch 4661 - loss: 0.4940134882926941\n",
      "Batch 4662 - loss: 0.5392205119132996\n",
      "Batch 4663 - loss: 0.4946567416191101\n",
      "Batch 4664 - loss: 0.5637755990028381\n",
      "Batch 4665 - loss: 0.517347514629364\n",
      "Batch 4666 - loss: 0.5742930173873901\n",
      "Batch 4667 - loss: 0.5100295543670654\n",
      "Batch 4668 - loss: 0.5276275277137756\n",
      "Batch 4669 - loss: 0.5329837203025818\n",
      "Batch 4670 - loss: 0.4969073235988617\n",
      "Batch 4671 - loss: 0.5591403841972351\n",
      "Batch 4672 - loss: 0.5653675198554993\n",
      "Batch 4673 - loss: 0.5289508700370789\n",
      "Batch 4674 - loss: 0.4804435670375824\n",
      "Batch 4675 - loss: 0.4598833918571472\n",
      "Batch 4676 - loss: 0.49116793274879456\n",
      "Batch 4677 - loss: 0.6074206233024597\n",
      "Batch 4678 - loss: 0.4726146161556244\n",
      "Batch 4679 - loss: 0.5285047292709351\n",
      "Batch 4680 - loss: 0.5315312743186951\n",
      "Batch 4681 - loss: 0.49273785948753357\n",
      "Batch 4682 - loss: 0.49609825015068054\n",
      "Batch 4683 - loss: 0.546658992767334\n",
      "Batch 4684 - loss: 0.5107946991920471\n",
      "Batch 4685 - loss: 0.518248975276947\n",
      "Batch 4686 - loss: 0.5527558326721191\n",
      "Batch 4687 - loss: 0.5290307402610779\n",
      "Batch 4688 - loss: 0.5301350951194763\n",
      "Batch 4689 - loss: 0.48170366883277893\n",
      "Batch 4690 - loss: 0.4984510540962219\n",
      "Batch 4691 - loss: 0.5220349431037903\n",
      "Batch 4692 - loss: 0.5454444289207458\n",
      "Batch 4693 - loss: 0.5235027074813843\n",
      "Batch 4694 - loss: 0.521719217300415\n",
      "Batch 4695 - loss: 0.5405343174934387\n",
      "Batch 4696 - loss: 0.4765799641609192\n",
      "Batch 4697 - loss: 0.5819685459136963\n",
      "Batch 4698 - loss: 0.5116047859191895\n",
      "Batch 4699 - loss: 0.49751338362693787\n",
      "Batch 4700 - loss: 0.5155436992645264\n",
      "Batch 4701 - loss: 0.513854444026947\n",
      "Batch 4702 - loss: 0.5633025765419006\n",
      "Batch 4703 - loss: 0.5178428292274475\n",
      "Batch 4704 - loss: 0.5364049077033997\n",
      "Batch 4705 - loss: 0.5713366270065308\n",
      "Batch 4706 - loss: 0.48318055272102356\n",
      "Batch 4707 - loss: 0.45618242025375366\n",
      "Batch 4708 - loss: 0.4619606137275696\n",
      "Batch 4709 - loss: 0.5506449937820435\n",
      "Batch 4710 - loss: 0.4900539517402649\n",
      "Batch 4711 - loss: 0.4564235508441925\n",
      "Batch 4712 - loss: 0.5293008685112\n",
      "Batch 4713 - loss: 0.5168936848640442\n",
      "Batch 4714 - loss: 0.4841760993003845\n",
      "Batch 4715 - loss: 0.5415161848068237\n",
      "Batch 4716 - loss: 0.4991399645805359\n",
      "Batch 4717 - loss: 0.48355811834335327\n",
      "Batch 4718 - loss: 0.4626040458679199\n",
      "Batch 4719 - loss: 0.58878093957901\n",
      "Batch 4720 - loss: 0.5601760149002075\n",
      "Batch 4721 - loss: 0.500320553779602\n",
      "Batch 4722 - loss: 0.548325777053833\n",
      "Batch 4723 - loss: 0.5004358887672424\n",
      "Batch 4724 - loss: 0.5282050967216492\n",
      "Batch 4725 - loss: 0.5708163380622864\n",
      "Batch 4726 - loss: 0.5430339574813843\n",
      "Batch 4727 - loss: 0.4540594220161438\n",
      "Batch 4728 - loss: 0.5927262902259827\n",
      "Batch 4729 - loss: 0.5635188221931458\n",
      "Batch 4730 - loss: 0.46484315395355225\n",
      "Batch 4731 - loss: 0.5377713441848755\n",
      "Batch 4732 - loss: 0.4974029064178467\n",
      "Batch 4733 - loss: 0.5697212219238281\n",
      "Batch 4734 - loss: 0.4216197431087494\n",
      "Batch 4735 - loss: 0.476946622133255\n",
      "Batch 4736 - loss: 0.5336354970932007\n",
      "Batch 4737 - loss: 0.46952709555625916\n",
      "Batch 4738 - loss: 0.46046677231788635\n",
      "Batch 4739 - loss: 0.5161323547363281\n",
      "Batch 4740 - loss: 0.5491213798522949\n",
      "Batch 4741 - loss: 0.5144219398498535\n",
      "Batch 4742 - loss: 0.5376802086830139\n",
      "Batch 4743 - loss: 0.5220710039138794\n",
      "Batch 4744 - loss: 0.5037420392036438\n",
      "Batch 4745 - loss: 0.508837103843689\n",
      "Batch 4746 - loss: 0.5166711807250977\n",
      "Batch 4747 - loss: 0.4928288459777832\n",
      "Batch 4748 - loss: 0.5212463140487671\n",
      "Batch 4749 - loss: 0.5198842883110046\n",
      "Batch 4750 - loss: 0.5371536016464233\n",
      "Batch 4751 - loss: 0.49716654419898987\n",
      "Batch 4752 - loss: 0.5555497407913208\n",
      "Batch 4753 - loss: 0.5407464504241943\n",
      "Batch 4754 - loss: 0.5766322612762451\n",
      "Batch 4755 - loss: 0.48663702607154846\n",
      "Batch 4756 - loss: 0.48271843791007996\n",
      "Batch 4757 - loss: 0.585979163646698\n",
      "Batch 4758 - loss: 0.5227334499359131\n",
      "Batch 4759 - loss: 0.49081364274024963\n",
      "Batch 4760 - loss: 0.48428037762641907\n",
      "Batch 4761 - loss: 0.5255359411239624\n",
      "Batch 4762 - loss: 0.4568481743335724\n",
      "Batch 4763 - loss: 0.5048356652259827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a4b7e7e6394928ad5e7eb90dfa7685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4764 - loss: 0.5167539119720459\n",
      "Batch 4765 - loss: 0.5548686981201172\n",
      "Batch 4766 - loss: 0.5087302327156067\n",
      "Batch 4767 - loss: 0.5185586214065552\n",
      "Batch 4768 - loss: 0.47023794054985046\n",
      "Batch 4769 - loss: 0.4662622809410095\n",
      "Batch 4770 - loss: 0.511551558971405\n",
      "Batch 4771 - loss: 0.5278377532958984\n",
      "Batch 4772 - loss: 0.4817076623439789\n",
      "Batch 4773 - loss: 0.5066806077957153\n",
      "Batch 4774 - loss: 0.5131204128265381\n",
      "Batch 4775 - loss: 0.5003064274787903\n",
      "Batch 4776 - loss: 0.5182276964187622\n",
      "Batch 4777 - loss: 0.5377998352050781\n",
      "Batch 4778 - loss: 0.6012482643127441\n",
      "Batch 4779 - loss: 0.5481865406036377\n",
      "Batch 4780 - loss: 0.6022416949272156\n",
      "Batch 4781 - loss: 0.5438198447227478\n",
      "Batch 4782 - loss: 0.5215078592300415\n",
      "Batch 4783 - loss: 0.6207912564277649\n",
      "Batch 4784 - loss: 0.5300515294075012\n",
      "Batch 4785 - loss: 0.5323277115821838\n",
      "Batch 4786 - loss: 0.5091675519943237\n",
      "Batch 4787 - loss: 0.5482715368270874\n",
      "Batch 4788 - loss: 0.5205429792404175\n",
      "Batch 4789 - loss: 0.4427064061164856\n",
      "Batch 4790 - loss: 0.5165978670120239\n",
      "Batch 4791 - loss: 0.4865809381008148\n",
      "Batch 4792 - loss: 0.521293580532074\n",
      "Batch 4793 - loss: 0.4714362323284149\n",
      "Batch 4794 - loss: 0.5385950207710266\n",
      "Batch 4795 - loss: 0.5454063415527344\n",
      "Batch 4796 - loss: 0.491476446390152\n",
      "Batch 4797 - loss: 0.5508730411529541\n",
      "Batch 4798 - loss: 0.5367129445075989\n",
      "Batch 4799 - loss: 0.5159163475036621\n",
      "Batch 4800 - loss: 0.547425389289856\n",
      "Batch 4801 - loss: 0.5449452996253967\n",
      "Batch 4802 - loss: 0.5290791988372803\n",
      "Batch 4803 - loss: 0.5260889530181885\n",
      "Batch 4804 - loss: 0.5543362498283386\n",
      "Batch 4805 - loss: 0.5713073015213013\n",
      "Batch 4806 - loss: 0.5399110913276672\n",
      "Batch 4807 - loss: 0.4435073137283325\n",
      "Batch 4808 - loss: 0.5171344876289368\n",
      "Batch 4809 - loss: 0.5170968770980835\n",
      "Batch 4810 - loss: 0.5717770457267761\n",
      "Batch 4811 - loss: 0.5833630561828613\n",
      "Batch 4812 - loss: 0.5334895849227905\n",
      "Batch 4813 - loss: 0.531160295009613\n",
      "Batch 4814 - loss: 0.4826856553554535\n",
      "Batch 4815 - loss: 0.5113773345947266\n",
      "Batch 4816 - loss: 0.5298110842704773\n",
      "Batch 4817 - loss: 0.4990164339542389\n",
      "Batch 4818 - loss: 0.5151150226593018\n",
      "Batch 4819 - loss: 0.5618647933006287\n",
      "Batch 4820 - loss: 0.4598243832588196\n",
      "Batch 4821 - loss: 0.4959771931171417\n",
      "Batch 4822 - loss: 0.533588171005249\n",
      "Batch 4823 - loss: 0.5002772212028503\n",
      "Batch 4824 - loss: 0.5092377066612244\n",
      "Batch 4825 - loss: 0.5342355370521545\n",
      "Batch 4826 - loss: 0.5073976516723633\n",
      "Batch 4827 - loss: 0.4843200445175171\n",
      "Batch 4828 - loss: 0.5279106497764587\n",
      "Batch 4829 - loss: 0.532825231552124\n",
      "Batch 4830 - loss: 0.5313069224357605\n",
      "Batch 4831 - loss: 0.5535265207290649\n",
      "Batch 4832 - loss: 0.5079719424247742\n",
      "Batch 4833 - loss: 0.5087311863899231\n",
      "Batch 4834 - loss: 0.4989159405231476\n",
      "Batch 4835 - loss: 0.49860039353370667\n",
      "Batch 4836 - loss: 0.47751590609550476\n",
      "Batch 4837 - loss: 0.5089992880821228\n",
      "Batch 4838 - loss: 0.5346548557281494\n",
      "Batch 4839 - loss: 0.5497879385948181\n",
      "Batch 4840 - loss: 0.5112365484237671\n",
      "Batch 4841 - loss: 0.4688661992549896\n",
      "Batch 4842 - loss: 0.49706757068634033\n",
      "Batch 4843 - loss: 0.5412691831588745\n",
      "Batch 4844 - loss: 0.5378873944282532\n",
      "Batch 4845 - loss: 0.5412813425064087\n",
      "Batch 4846 - loss: 0.5415210723876953\n",
      "Batch 4847 - loss: 0.42498859763145447\n",
      "Batch 4848 - loss: 0.5468010306358337\n",
      "Batch 4849 - loss: 0.453984797000885\n",
      "Batch 4850 - loss: 0.5687938332557678\n",
      "Batch 4851 - loss: 0.5595324635505676\n",
      "Batch 4852 - loss: 0.5585267543792725\n",
      "Batch 4853 - loss: 0.5332702994346619\n",
      "Batch 4854 - loss: 0.5379183292388916\n",
      "Batch 4855 - loss: 0.5101721286773682\n",
      "Batch 4856 - loss: 0.5016851425170898\n",
      "Batch 4857 - loss: 0.5433695316314697\n",
      "Batch 4858 - loss: 0.5505864024162292\n",
      "Batch 4859 - loss: 0.4900132715702057\n",
      "Batch 4860 - loss: 0.5114273428916931\n",
      "Batch 4861 - loss: 0.5246041417121887\n",
      "Batch 4862 - loss: 0.48228326439857483\n",
      "Batch 4863 - loss: 0.47870808839797974\n",
      "Batch 4864 - loss: 0.49141713976860046\n",
      "Batch 4865 - loss: 0.4946058392524719\n",
      "Batch 4866 - loss: 0.5392408967018127\n",
      "Batch 4867 - loss: 0.5663588643074036\n",
      "Batch 4868 - loss: 0.4836646616458893\n",
      "Batch 4869 - loss: 0.46040692925453186\n",
      "Batch 4870 - loss: 0.50837641954422\n",
      "Batch 4871 - loss: 0.4630284905433655\n",
      "Batch 4872 - loss: 0.5556838512420654\n",
      "Batch 4873 - loss: 0.5242272615432739\n",
      "Batch 4874 - loss: 0.5228678584098816\n",
      "Batch 4875 - loss: 0.5231882333755493\n",
      "Batch 4876 - loss: 0.5436392426490784\n",
      "Batch 4877 - loss: 0.4857449233531952\n",
      "Batch 4878 - loss: 0.5256775617599487\n",
      "Batch 4879 - loss: 0.5279859900474548\n",
      "Batch 4880 - loss: 0.4587223529815674\n",
      "Batch 4881 - loss: 0.48093265295028687\n",
      "Batch 4882 - loss: 0.5058197975158691\n",
      "Batch 4883 - loss: 0.5339695811271667\n",
      "Batch 4884 - loss: 0.5441446304321289\n",
      "Batch 4885 - loss: 0.4715060591697693\n",
      "Batch 4886 - loss: 0.534416675567627\n",
      "Batch 4887 - loss: 0.5291213989257812\n",
      "Batch 4888 - loss: 0.5351625084877014\n",
      "Batch 4889 - loss: 0.5508618354797363\n",
      "Batch 4890 - loss: 0.4765571057796478\n",
      "Batch 4891 - loss: 0.5130282044410706\n",
      "Batch 4892 - loss: 0.5688055157661438\n",
      "Batch 4893 - loss: 0.5540174841880798\n",
      "Batch 4894 - loss: 0.5907043814659119\n",
      "Batch 4895 - loss: 0.5459718108177185\n",
      "Batch 4896 - loss: 0.5776637196540833\n",
      "Batch 4897 - loss: 0.544441282749176\n",
      "Batch 4898 - loss: 0.5070032477378845\n",
      "Batch 4899 - loss: 0.5017118453979492\n",
      "Batch 4900 - loss: 0.5088342428207397\n",
      "Batch 4901 - loss: 0.5096181631088257\n",
      "Batch 4902 - loss: 0.5260161757469177\n",
      "Batch 4903 - loss: 0.5108607411384583\n",
      "Batch 4904 - loss: 0.4788787364959717\n",
      "Batch 4905 - loss: 0.5049389600753784\n",
      "Batch 4906 - loss: 0.5292282104492188\n",
      "Batch 4907 - loss: 0.5007096529006958\n",
      "Batch 4908 - loss: 0.5082041025161743\n",
      "Batch 4909 - loss: 0.5345372557640076\n",
      "Batch 4910 - loss: 0.4973004162311554\n",
      "Batch 4911 - loss: 0.5272237062454224\n",
      "Batch 4912 - loss: 0.4728010296821594\n",
      "Batch 4913 - loss: 0.5773543119430542\n",
      "Batch 4914 - loss: 0.5504531264305115\n",
      "Batch 4915 - loss: 0.5949901342391968\n",
      "Batch 4916 - loss: 0.5105523467063904\n",
      "Batch 4917 - loss: 0.5201646685600281\n",
      "Batch 4918 - loss: 0.6059702038764954\n",
      "Batch 4919 - loss: 0.5324375629425049\n",
      "Batch 4920 - loss: 0.4942138195037842\n",
      "Batch 4921 - loss: 0.5720334649085999\n",
      "Batch 4922 - loss: 0.5304065942764282\n",
      "Batch 4923 - loss: 0.5234519839286804\n",
      "Batch 4924 - loss: 0.4895767867565155\n",
      "Batch 4925 - loss: 0.5608452558517456\n",
      "Batch 4926 - loss: 0.5451686382293701\n",
      "Batch 4927 - loss: 0.563087522983551\n",
      "Batch 4928 - loss: 0.5554792881011963\n",
      "Batch 4929 - loss: 0.4787716865539551\n",
      "Batch 4930 - loss: 0.4955950677394867\n",
      "Batch 4931 - loss: 0.596991240978241\n",
      "Batch 4932 - loss: 0.5118123292922974\n",
      "Batch 4933 - loss: 0.5210695266723633\n",
      "Batch 4934 - loss: 0.5354477167129517\n",
      "Batch 4935 - loss: 0.5148540139198303\n",
      "Batch 4936 - loss: 0.49188432097435\n",
      "Batch 4937 - loss: 0.5117918848991394\n",
      "Batch 4938 - loss: 0.5399483442306519\n",
      "Batch 4939 - loss: 0.4994793236255646\n",
      "Batch 4940 - loss: 0.552812933921814\n",
      "Batch 4941 - loss: 0.4986402690410614\n",
      "Batch 4942 - loss: 0.4577833414077759\n",
      "Batch 4943 - loss: 0.5107129216194153\n",
      "Batch 4944 - loss: 0.5536617040634155\n",
      "Batch 4945 - loss: 0.544704258441925\n",
      "Batch 4946 - loss: 0.5383172631263733\n",
      "Batch 4947 - loss: 0.5322805643081665\n",
      "Batch 4948 - loss: 0.49071556329727173\n",
      "Batch 4949 - loss: 0.5399881601333618\n",
      "Batch 4950 - loss: 0.5204022526741028\n",
      "Batch 4951 - loss: 0.5134367346763611\n",
      "Batch 4952 - loss: 0.5227202773094177\n",
      "Batch 4953 - loss: 0.5074012875556946\n",
      "Batch 4954 - loss: 0.5624998211860657\n",
      "Batch 4955 - loss: 0.4563671946525574\n",
      "Batch 4956 - loss: 0.5253472328186035\n",
      "Batch 4957 - loss: 0.4979844391345978\n",
      "Batch 4958 - loss: 0.45204806327819824\n",
      "Batch 4959 - loss: 0.5208858251571655\n",
      "Batch 4960 - loss: 0.4525708258152008\n",
      "Batch 4961 - loss: 0.4825502634048462\n",
      "Batch 4962 - loss: 0.479573130607605\n",
      "Batch 4963 - loss: 0.5225095152854919\n",
      "Batch 4964 - loss: 0.49716341495513916\n",
      "Batch 4965 - loss: 0.46319887042045593\n",
      "Batch 4966 - loss: 0.5140741467475891\n",
      "Batch 4967 - loss: 0.49350181221961975\n",
      "Batch 4968 - loss: 0.5430153608322144\n",
      "Batch 4969 - loss: 0.5283496379852295\n",
      "Batch 4970 - loss: 0.48707640171051025\n",
      "Batch 4971 - loss: 0.5096712708473206\n",
      "Batch 4972 - loss: 0.5110901594161987\n",
      "Batch 4973 - loss: 0.5364939570426941\n",
      "Batch 4974 - loss: 0.5192745327949524\n",
      "Batch 4975 - loss: 0.5101670622825623\n",
      "Batch 4976 - loss: 0.543412983417511\n",
      "Batch 4977 - loss: 0.5216580629348755\n",
      "Batch 4978 - loss: 0.5240530967712402\n",
      "Batch 4979 - loss: 0.551654040813446\n",
      "Batch 4980 - loss: 0.47407764196395874\n",
      "Batch 4981 - loss: 0.6283277869224548\n",
      "Batch 4982 - loss: 0.5331599712371826\n",
      "Batch 4983 - loss: 0.5232017636299133\n",
      "Batch 4984 - loss: 0.5591750144958496\n",
      "Batch 4985 - loss: 0.47350138425827026\n",
      "Batch 4986 - loss: 0.48075780272483826\n",
      "Batch 4987 - loss: 0.4704943299293518\n",
      "Batch 4988 - loss: 0.48521023988723755\n",
      "Batch 4989 - loss: 0.5667558312416077\n",
      "Batch 4990 - loss: 0.4862577021121979\n",
      "Batch 4991 - loss: 0.4962446093559265\n",
      "Batch 4992 - loss: 0.5527830123901367\n",
      "Batch 4993 - loss: 0.5181857943534851\n",
      "Batch 4994 - loss: 0.5244378447532654\n",
      "Batch 4995 - loss: 0.5289403200149536\n",
      "Batch 4996 - loss: 0.48838886618614197\n",
      "Batch 4997 - loss: 0.4971945285797119\n",
      "Batch 4998 - loss: 0.5831513404846191\n",
      "Batch 4999 - loss: 0.5597946643829346\n",
      "Batch 5000 - loss: 0.5084753632545471\n",
      "Batch 5001 - loss: 0.5273759961128235\n",
      "Batch 5002 - loss: 0.47609224915504456\n",
      "Batch 5003 - loss: 0.5144323706626892\n",
      "Batch 5004 - loss: 0.5082025527954102\n",
      "Batch 5005 - loss: 0.4858222007751465\n",
      "Batch 5006 - loss: 0.5089316368103027\n",
      "Batch 5007 - loss: 0.5400456190109253\n",
      "Batch 5008 - loss: 0.5208880305290222\n",
      "Batch 5009 - loss: 0.5532513856887817\n",
      "Batch 5010 - loss: 0.505715548992157\n",
      "Batch 5011 - loss: 0.5071437954902649\n",
      "Batch 5012 - loss: 0.5197947025299072\n",
      "Batch 5013 - loss: 0.5202176570892334\n",
      "Batch 5014 - loss: 0.46816176176071167\n",
      "Batch 5015 - loss: 0.5234211087226868\n",
      "Batch 5016 - loss: 0.5002053380012512\n",
      "Batch 5017 - loss: 0.4714009761810303\n",
      "Batch 5018 - loss: 0.4978412389755249\n",
      "Batch 5019 - loss: 0.5212318897247314\n",
      "Batch 5020 - loss: 0.5152472853660583\n",
      "Batch 5021 - loss: 0.5220389366149902\n",
      "Batch 5022 - loss: 0.494833379983902\n",
      "Batch 5023 - loss: 0.5504819750785828\n",
      "Batch 5024 - loss: 0.4938272535800934\n",
      "Batch 5025 - loss: 0.585946261882782\n",
      "Batch 5026 - loss: 0.5153541564941406\n",
      "Batch 5027 - loss: 0.5175209641456604\n",
      "Batch 5028 - loss: 0.5411239266395569\n",
      "Batch 5029 - loss: 0.5444566607475281\n",
      "Batch 5030 - loss: 0.49578917026519775\n",
      "Batch 5031 - loss: 0.48723268508911133\n",
      "Batch 5032 - loss: 0.5445832014083862\n",
      "Batch 5033 - loss: 0.5073876976966858\n",
      "Batch 5034 - loss: 0.520056962966919\n",
      "Batch 5035 - loss: 0.5448786616325378\n",
      "Batch 5036 - loss: 0.4962989091873169\n",
      "Batch 5037 - loss: 0.4674425423145294\n",
      "Batch 5038 - loss: 0.5157936811447144\n",
      "Batch 5039 - loss: 0.4589497447013855\n",
      "Batch 5040 - loss: 0.5374860167503357\n",
      "Batch 5041 - loss: 0.5174777507781982\n",
      "Batch 5042 - loss: 0.5234547257423401\n",
      "Batch 5043 - loss: 0.5370369553565979\n",
      "Batch 5044 - loss: 0.48388758301734924\n",
      "Batch 5045 - loss: 0.5004145503044128\n",
      "Batch 5046 - loss: 0.5399125218391418\n",
      "Batch 5047 - loss: 0.5170454978942871\n",
      "Batch 5048 - loss: 0.5133851766586304\n",
      "Batch 5049 - loss: 0.4861728549003601\n",
      "Batch 5050 - loss: 0.5157796144485474\n",
      "Batch 5051 - loss: 0.5079493522644043\n",
      "Batch 5052 - loss: 0.4901720881462097\n",
      "Batch 5053 - loss: 0.48924487829208374\n",
      "Batch 5054 - loss: 0.4433283507823944\n",
      "Batch 5055 - loss: 0.49145328998565674\n",
      "Batch 5056 - loss: 0.5290701389312744\n",
      "Batch 5057 - loss: 0.5819666385650635\n",
      "Batch 5058 - loss: 0.5727797150611877\n",
      "Batch 5059 - loss: 0.5754451155662537\n",
      "Batch 5060 - loss: 0.5047047734260559\n",
      "Batch 5061 - loss: 0.5560505390167236\n",
      "Batch 5062 - loss: 0.4872470796108246\n",
      "Batch 5063 - loss: 0.5458927750587463\n",
      "Batch 5064 - loss: 0.5257136821746826\n",
      "Batch 5065 - loss: 0.5050854086875916\n",
      "Batch 5066 - loss: 0.5615108609199524\n",
      "Batch 5067 - loss: 0.5637964606285095\n",
      "Batch 5068 - loss: 0.49462002515792847\n",
      "Batch 5069 - loss: 0.5504177808761597\n",
      "Batch 5070 - loss: 0.48244279623031616\n",
      "Batch 5071 - loss: 0.551683247089386\n",
      "Batch 5072 - loss: 0.49272653460502625\n",
      "Batch 5073 - loss: 0.4811862111091614\n",
      "Batch 5074 - loss: 0.4807945787906647\n",
      "Batch 5075 - loss: 0.455584317445755\n",
      "Batch 5076 - loss: 0.5431311726570129\n",
      "Batch 5077 - loss: 0.5106739401817322\n",
      "Batch 5078 - loss: 0.5229418277740479\n",
      "Batch 5079 - loss: 0.5524681210517883\n",
      "Batch 5080 - loss: 0.509986400604248\n",
      "Batch 5081 - loss: 0.530117928981781\n",
      "Batch 5082 - loss: 0.49125543236732483\n",
      "Batch 5083 - loss: 0.5153430700302124\n",
      "Batch 5084 - loss: 0.6136435866355896\n",
      "Batch 5085 - loss: 0.6101449728012085\n",
      "Batch 5086 - loss: 0.4927407205104828\n",
      "Batch 5087 - loss: 0.48213741183280945\n",
      "Batch 5088 - loss: 0.5669322609901428\n",
      "Batch 5089 - loss: 0.5405677556991577\n",
      "Batch 5090 - loss: 0.5575528144836426\n",
      "Batch 5091 - loss: 0.5561012625694275\n",
      "Batch 5092 - loss: 0.515764057636261\n",
      "Batch 5093 - loss: 0.49098214507102966\n",
      "Batch 5094 - loss: 0.4791261851787567\n",
      "Batch 5095 - loss: 0.5067180395126343\n",
      "Batch 5096 - loss: 0.514066219329834\n",
      "Batch 5097 - loss: 0.5421738028526306\n",
      "Batch 5098 - loss: 0.5603095293045044\n",
      "Batch 5099 - loss: 0.5431349277496338\n",
      "Batch 5100 - loss: 0.5213749408721924\n",
      "Batch 5101 - loss: 0.5239014029502869\n",
      "Batch 5102 - loss: 0.5079671144485474\n",
      "Batch 5103 - loss: 0.5029529929161072\n",
      "Batch 5104 - loss: 0.4806590676307678\n",
      "Batch 5105 - loss: 0.5011960864067078\n",
      "Batch 5106 - loss: 0.527316153049469\n",
      "Batch 5107 - loss: 0.5024562478065491\n",
      "Batch 5108 - loss: 0.5234401822090149\n",
      "Batch 5109 - loss: 0.5625174045562744\n",
      "Batch 5110 - loss: 0.5416038036346436\n",
      "Batch 5111 - loss: 0.48962026834487915\n",
      "Batch 5112 - loss: 0.5125337243080139\n",
      "Batch 5113 - loss: 0.4770800769329071\n",
      "Batch 5114 - loss: 0.5464801788330078\n",
      "Batch 5115 - loss: 0.47699666023254395\n",
      "Batch 5116 - loss: 0.5100930333137512\n",
      "Batch 5117 - loss: 0.5284122824668884\n",
      "Batch 5118 - loss: 0.4848056733608246\n",
      "Batch 5119 - loss: 0.5028733015060425\n",
      "Batch 5120 - loss: 0.543119490146637\n",
      "Batch 5121 - loss: 0.5254257321357727\n",
      "Batch 5122 - loss: 0.47908222675323486\n",
      "Batch 5123 - loss: 0.5264562368392944\n",
      "Batch 5124 - loss: 0.5252131223678589\n",
      "Batch 5125 - loss: 0.48438218235969543\n",
      "Batch 5126 - loss: 0.536799967288971\n",
      "Batch 5127 - loss: 0.5406520962715149\n",
      "Batch 5128 - loss: 0.4467582404613495\n",
      "Batch 5129 - loss: 0.5007741451263428\n",
      "Batch 5130 - loss: 0.5037134885787964\n",
      "Batch 5131 - loss: 0.5153743624687195\n",
      "Batch 5132 - loss: 0.5888270139694214\n",
      "Batch 5133 - loss: 0.5022950768470764\n",
      "Batch 5134 - loss: 0.49221673607826233\n",
      "Batch 5135 - loss: 0.5403006672859192\n",
      "Batch 5136 - loss: 0.5502665638923645\n",
      "Batch 5137 - loss: 0.5387077927589417\n",
      "Batch 5138 - loss: 0.4967386722564697\n",
      "Batch 5139 - loss: 0.5468438863754272\n",
      "Batch 5140 - loss: 0.5032442808151245\n",
      "Batch 5141 - loss: 0.5474026203155518\n",
      "Batch 5142 - loss: 0.530529797077179\n",
      "Batch 5143 - loss: 0.5340145826339722\n",
      "Batch 5144 - loss: 0.5145390629768372\n",
      "Batch 5145 - loss: 0.514376163482666\n",
      "Batch 5146 - loss: 0.534142255783081\n",
      "Batch 5147 - loss: 0.4667402505874634\n",
      "Batch 5148 - loss: 0.5229851007461548\n",
      "Batch 5149 - loss: 0.5171509981155396\n",
      "Batch 5150 - loss: 0.5547922849655151\n",
      "Batch 5151 - loss: 0.5226288437843323\n",
      "Batch 5152 - loss: 0.5243175029754639\n",
      "Batch 5153 - loss: 0.5113906264305115\n",
      "Batch 5154 - loss: 0.5078844428062439\n",
      "Batch 5155 - loss: 0.49422621726989746\n",
      "Batch 5156 - loss: 0.554333508014679\n",
      "Batch 5157 - loss: 0.4895889163017273\n",
      "Batch 5158 - loss: 0.5671547651290894\n",
      "Batch 5159 - loss: 0.5198114514350891\n",
      "Batch 5160 - loss: 0.5305615067481995\n",
      "Batch 5161 - loss: 0.5202745199203491\n",
      "Batch 5162 - loss: 0.5127652287483215\n",
      "Batch 5163 - loss: 0.6254682540893555\n",
      "Batch 5164 - loss: 0.5155583620071411\n",
      "Batch 5165 - loss: 0.5266966223716736\n",
      "Batch 5166 - loss: 0.5545739531517029\n",
      "Batch 5167 - loss: 0.49948650598526\n",
      "Batch 5168 - loss: 0.46219930052757263\n",
      "Batch 5169 - loss: 0.47233912348747253\n",
      "Batch 5170 - loss: 0.5019003748893738\n",
      "Batch 5171 - loss: 0.48719140887260437\n",
      "Batch 5172 - loss: 0.5195366740226746\n",
      "Batch 5173 - loss: 0.4937235116958618\n",
      "Batch 5174 - loss: 0.5713207125663757\n",
      "Batch 5175 - loss: 0.5156534314155579\n",
      "Batch 5176 - loss: 0.5398315191268921\n",
      "Batch 5177 - loss: 0.5372448563575745\n",
      "Batch 5178 - loss: 0.5388327240943909\n",
      "Batch 5179 - loss: 0.5492589473724365\n",
      "Batch 5180 - loss: 0.5417892336845398\n",
      "Batch 5181 - loss: 0.512861967086792\n",
      "Batch 5182 - loss: 0.471147358417511\n",
      "Batch 5183 - loss: 0.4805545508861542\n",
      "Batch 5184 - loss: 0.5066262483596802\n",
      "Batch 5185 - loss: 0.515329897403717\n",
      "Batch 5186 - loss: 0.5158317685127258\n",
      "Batch 5187 - loss: 0.5181453824043274\n",
      "Batch 5188 - loss: 0.5488345623016357\n",
      "Batch 5189 - loss: 0.5542919039726257\n",
      "Batch 5190 - loss: 0.470697820186615\n",
      "Batch 5191 - loss: 0.5193928480148315\n",
      "Batch 5192 - loss: 0.5478732585906982\n",
      "Batch 5193 - loss: 0.525409996509552\n",
      "Batch 5194 - loss: 0.5402734875679016\n",
      "Batch 5195 - loss: 0.5293846130371094\n",
      "Batch 5196 - loss: 0.4933353066444397\n",
      "Batch 5197 - loss: 0.5233681797981262\n",
      "Batch 5198 - loss: 0.47208520770072937\n",
      "Batch 5199 - loss: 0.49156761169433594\n",
      "Batch 5200 - loss: 0.5248466730117798\n",
      "Batch 5201 - loss: 0.5415378212928772\n",
      "Batch 5202 - loss: 0.5090572834014893\n",
      "Batch 5203 - loss: 0.5495357513427734\n",
      "Batch 5204 - loss: 0.5122497081756592\n",
      "Batch 5205 - loss: 0.5308462977409363\n",
      "Batch 5206 - loss: 0.5180924534797668\n",
      "Batch 5207 - loss: 0.45891305804252625\n",
      "Batch 5208 - loss: 0.6188966631889343\n",
      "Batch 5209 - loss: 0.5179199576377869\n",
      "Batch 5210 - loss: 0.5010904669761658\n",
      "Batch 5211 - loss: 0.5229331851005554\n",
      "Batch 5212 - loss: 0.5595748424530029\n",
      "Batch 5213 - loss: 0.5205562114715576\n",
      "Batch 5214 - loss: 0.5579385161399841\n",
      "Batch 5215 - loss: 0.5099892020225525\n",
      "Batch 5216 - loss: 0.5065750479698181\n",
      "Batch 5217 - loss: 0.5487890839576721\n",
      "Batch 5218 - loss: 0.5385613441467285\n",
      "Batch 5219 - loss: 0.5700011849403381\n",
      "Batch 5220 - loss: 0.5456588864326477\n",
      "Batch 5221 - loss: 0.5936185717582703\n",
      "Batch 5222 - loss: 0.5835418701171875\n",
      "Batch 5223 - loss: 0.564094603061676\n",
      "Batch 5224 - loss: 0.5241893529891968\n",
      "Batch 5225 - loss: 0.5124802589416504\n",
      "Batch 5226 - loss: 0.4679531157016754\n",
      "Batch 5227 - loss: 0.5766937732696533\n",
      "Batch 5228 - loss: 0.4519779086112976\n",
      "Batch 5229 - loss: 0.47039955854415894\n",
      "Batch 5230 - loss: 0.4563305974006653\n",
      "Batch 5231 - loss: 0.4829208552837372\n",
      "Batch 5232 - loss: 0.5554191470146179\n",
      "Batch 5233 - loss: 0.526095986366272\n",
      "Batch 5234 - loss: 0.536518931388855\n",
      "Batch 5235 - loss: 0.5437566637992859\n",
      "Batch 5236 - loss: 0.5285422205924988\n",
      "Batch 5237 - loss: 0.5532035827636719\n",
      "Batch 5238 - loss: 0.4716607928276062\n",
      "Batch 5239 - loss: 0.5244297981262207\n",
      "Batch 5240 - loss: 0.49398401379585266\n",
      "Batch 5241 - loss: 0.5686056613922119\n",
      "Batch 5242 - loss: 0.5143026113510132\n",
      "Batch 5243 - loss: 0.5639196038246155\n",
      "Batch 5244 - loss: 0.5082128047943115\n",
      "Batch 5245 - loss: 0.553996741771698\n",
      "Batch 5246 - loss: 0.48226502537727356\n",
      "Batch 5247 - loss: 0.5529229044914246\n",
      "Batch 5248 - loss: 0.5804460644721985\n",
      "Batch 5249 - loss: 0.515102207660675\n",
      "Batch 5250 - loss: 0.5172955393791199\n",
      "Batch 5251 - loss: 0.5668674111366272\n",
      "Batch 5252 - loss: 0.49743443727493286\n",
      "Batch 5253 - loss: 0.503176212310791\n",
      "Batch 5254 - loss: 0.5689048171043396\n",
      "Batch 5255 - loss: 0.5662469267845154\n",
      "Batch 5256 - loss: 0.5456995964050293\n",
      "Batch 5257 - loss: 0.5431820154190063\n",
      "Batch 5258 - loss: 0.5131369829177856\n",
      "Batch 5259 - loss: 0.5301341414451599\n",
      "Batch 5260 - loss: 0.5244783163070679\n",
      "Batch 5261 - loss: 0.5217709541320801\n",
      "Batch 5262 - loss: 0.5130789875984192\n",
      "Batch 5263 - loss: 0.5691571831703186\n",
      "Batch 5264 - loss: 0.5383095145225525\n",
      "Batch 5265 - loss: 0.5244203209877014\n",
      "Batch 5266 - loss: 0.5318101048469543\n",
      "Batch 5267 - loss: 0.4823911190032959\n",
      "Batch 5268 - loss: 0.49502038955688477\n",
      "Batch 5269 - loss: 0.5196382999420166\n",
      "Batch 5270 - loss: 0.5130146741867065\n",
      "Batch 5271 - loss: 0.5002040863037109\n",
      "Batch 5272 - loss: 0.5914490818977356\n",
      "Batch 5273 - loss: 0.5451738238334656\n",
      "Batch 5274 - loss: 0.4798969030380249\n",
      "Batch 5275 - loss: 0.5221092700958252\n",
      "Batch 5276 - loss: 0.5574106574058533\n",
      "Batch 5277 - loss: 0.5754345059394836\n",
      "Batch 5278 - loss: 0.5611669421195984\n",
      "Batch 5279 - loss: 0.5506494641304016\n",
      "Batch 5280 - loss: 0.49390658736228943\n",
      "Batch 5281 - loss: 0.5423805117607117\n",
      "Batch 5282 - loss: 0.49516019225120544\n",
      "Batch 5283 - loss: 0.5686246156692505\n",
      "Batch 5284 - loss: 0.4982089698314667\n",
      "Batch 5285 - loss: 0.5263858437538147\n",
      "Batch 5286 - loss: 0.5613735914230347\n",
      "Batch 5287 - loss: 0.4900631606578827\n",
      "Batch 5288 - loss: 0.5265105366706848\n",
      "Batch 5289 - loss: 0.5211975574493408\n",
      "Batch 5290 - loss: 0.5453190207481384\n",
      "Batch 5291 - loss: 0.5076314210891724\n",
      "Batch 5292 - loss: 0.5390527844429016\n",
      "Batch 5293 - loss: 0.4855870008468628\n",
      "Batch 5294 - loss: 0.5721701383590698\n",
      "Batch 5295 - loss: 0.5022748708724976\n",
      "Batch 5296 - loss: 0.5489277243614197\n",
      "Batch 5297 - loss: 0.5693945288658142\n",
      "Batch 5298 - loss: 0.5145308375358582\n",
      "Batch 5299 - loss: 0.502576470375061\n",
      "Batch 5300 - loss: 0.4814971685409546\n",
      "Batch 5301 - loss: 0.4957549273967743\n",
      "Batch 5302 - loss: 0.5051107406616211\n",
      "Batch 5303 - loss: 0.5632518529891968\n",
      "Batch 5304 - loss: 0.4989009499549866\n",
      "Batch 5305 - loss: 0.4854607582092285\n",
      "Batch 5306 - loss: 0.4680364429950714\n",
      "Batch 5307 - loss: 0.5357265472412109\n",
      "Batch 5308 - loss: 0.531663179397583\n",
      "Batch 5309 - loss: 0.566978931427002\n",
      "Batch 5310 - loss: 0.49552685022354126\n",
      "Batch 5311 - loss: 0.5210001468658447\n",
      "Batch 5312 - loss: 0.4926156997680664\n",
      "Batch 5313 - loss: 0.5221216678619385\n",
      "Batch 5314 - loss: 0.4982073903083801\n",
      "Batch 5315 - loss: 0.5125881433486938\n",
      "Batch 5316 - loss: 0.5665284395217896\n",
      "Batch 5317 - loss: 0.5153428316116333\n",
      "Batch 5318 - loss: 0.556811511516571\n",
      "Batch 5319 - loss: 0.5288408994674683\n",
      "Batch 5320 - loss: 0.471985399723053\n",
      "Batch 5321 - loss: 0.5576924085617065\n",
      "Batch 5322 - loss: 0.5576766729354858\n",
      "Batch 5323 - loss: 0.531816303730011\n",
      "Batch 5324 - loss: 0.5468796491622925\n",
      "Batch 5325 - loss: 0.5878005027770996\n",
      "Batch 5326 - loss: 0.5660436749458313\n",
      "Batch 5327 - loss: 0.5549501180648804\n",
      "Batch 5328 - loss: 0.5375522375106812\n",
      "Batch 5329 - loss: 0.4947478771209717\n",
      "Batch 5330 - loss: 0.47402244806289673\n",
      "Batch 5331 - loss: 0.5170421600341797\n",
      "Batch 5332 - loss: 0.5469446182250977\n",
      "Batch 5333 - loss: 0.5351118445396423\n",
      "Batch 5334 - loss: 0.4603891968727112\n",
      "Batch 5335 - loss: 0.5273627638816833\n",
      "Batch 5336 - loss: 0.5268445611000061\n",
      "Batch 5337 - loss: 0.5641385912895203\n",
      "Batch 5338 - loss: 0.5478668808937073\n",
      "Batch 5339 - loss: 0.47310730814933777\n",
      "Batch 5340 - loss: 0.5049748420715332\n",
      "Batch 5341 - loss: 0.5385247468948364\n",
      "Batch 5342 - loss: 0.5551677346229553\n",
      "Batch 5343 - loss: 0.5005563497543335\n",
      "Batch 5344 - loss: 0.5143702030181885\n",
      "Batch 5345 - loss: 0.6109294295310974\n",
      "Batch 5346 - loss: 0.5364053845405579\n",
      "Batch 5347 - loss: 0.500586211681366\n",
      "Batch 5348 - loss: 0.5340498089790344\n",
      "Batch 5349 - loss: 0.5265235900878906\n",
      "Batch 5350 - loss: 0.5397639870643616\n",
      "Batch 5351 - loss: 0.4670807123184204\n",
      "Batch 5352 - loss: 0.4450102746486664\n",
      "Batch 5353 - loss: 0.5024973154067993\n",
      "Batch 5354 - loss: 0.5142292976379395\n",
      "Batch 5355 - loss: 0.5459399819374084\n",
      "Batch 5356 - loss: 0.5061208605766296\n",
      "Batch 5357 - loss: 0.5611870288848877\n",
      "Batch 5358 - loss: 0.48098090291023254\n",
      "Batch 5359 - loss: 0.45439043641090393\n",
      "Batch 5360 - loss: 0.5288482308387756\n",
      "Batch 5361 - loss: 0.5297396779060364\n",
      "Batch 5362 - loss: 0.5196415781974792\n",
      "Batch 5363 - loss: 0.5791015625\n",
      "Batch 5364 - loss: 0.5485988259315491\n",
      "Batch 5365 - loss: 0.5067386031150818\n",
      "Batch 5366 - loss: 0.4579102098941803\n",
      "Batch 5367 - loss: 0.4739920496940613\n",
      "Batch 5368 - loss: 0.5271236896514893\n",
      "Batch 5369 - loss: 0.5036646723747253\n",
      "Batch 5370 - loss: 0.5519617795944214\n",
      "Batch 5371 - loss: 0.5147641897201538\n",
      "Batch 5372 - loss: 0.5470075607299805\n",
      "Batch 5373 - loss: 0.5010024309158325\n",
      "Batch 5374 - loss: 0.5181114077568054\n",
      "Batch 5375 - loss: 0.5830415487289429\n",
      "Batch 5376 - loss: 0.5521960258483887\n",
      "Batch 5377 - loss: 0.48882758617401123\n",
      "Batch 5378 - loss: 0.5068202614784241\n",
      "Batch 5379 - loss: 0.5469127297401428\n",
      "Batch 5380 - loss: 0.5523772835731506\n",
      "Batch 5381 - loss: 0.5298572182655334\n",
      "Batch 5382 - loss: 0.5764479041099548\n",
      "Batch 5383 - loss: 0.5405613780021667\n",
      "Batch 5384 - loss: 0.5834784507751465\n",
      "Batch 5385 - loss: 0.513685405254364\n",
      "Batch 5386 - loss: 0.4994884431362152\n",
      "Batch 5387 - loss: 0.5126803517341614\n",
      "Batch 5388 - loss: 0.518639862537384\n",
      "Batch 5389 - loss: 0.558091938495636\n",
      "Batch 5390 - loss: 0.5030844807624817\n",
      "Batch 5391 - loss: 0.5135773420333862\n",
      "Batch 5392 - loss: 0.4608628451824188\n",
      "Batch 5393 - loss: 0.5761847496032715\n",
      "Batch 5394 - loss: 0.5015727281570435\n",
      "Batch 5395 - loss: 0.49145203828811646\n",
      "Batch 5396 - loss: 0.5095798373222351\n",
      "Batch 5397 - loss: 0.5351217985153198\n",
      "Batch 5398 - loss: 0.4947955012321472\n",
      "Batch 5399 - loss: 0.5785760283470154\n",
      "Batch 5400 - loss: 0.5065513849258423\n",
      "Batch 5401 - loss: 0.5138368010520935\n",
      "Batch 5402 - loss: 0.5981644988059998\n",
      "Batch 5403 - loss: 0.5437412261962891\n",
      "Batch 5404 - loss: 0.5110363364219666\n",
      "Batch 5405 - loss: 0.5663706064224243\n",
      "Batch 5406 - loss: 0.48166221380233765\n",
      "Batch 5407 - loss: 0.5512823462486267\n",
      "Batch 5408 - loss: 0.4941083490848541\n",
      "Batch 5409 - loss: 0.4781084358692169\n",
      "Batch 5410 - loss: 0.5112482905387878\n",
      "Batch 5411 - loss: 0.5015708804130554\n",
      "Batch 5412 - loss: 0.5034289956092834\n",
      "Batch 5413 - loss: 0.5369599461555481\n",
      "Batch 5414 - loss: 0.5298658013343811\n",
      "Batch 5415 - loss: 0.4873529076576233\n",
      "Batch 5416 - loss: 0.5742376446723938\n",
      "Batch 5417 - loss: 0.45797663927078247\n",
      "Batch 5418 - loss: 0.5113489031791687\n",
      "Batch 5419 - loss: 0.598067045211792\n",
      "Batch 5420 - loss: 0.48911482095718384\n",
      "Batch 5421 - loss: 0.4816851019859314\n",
      "Batch 5422 - loss: 0.5126241445541382\n",
      "Batch 5423 - loss: 0.5926553010940552\n",
      "Batch 5424 - loss: 0.4860326647758484\n",
      "Batch 5425 - loss: 0.5438408851623535\n",
      "Batch 5426 - loss: 0.5425383448600769\n",
      "Batch 5427 - loss: 0.5225961208343506\n",
      "Batch 5428 - loss: 0.49663323163986206\n",
      "Batch 5429 - loss: 0.49979308247566223\n",
      "Batch 5430 - loss: 0.4868384301662445\n",
      "Batch 5431 - loss: 0.5258667469024658\n",
      "Batch 5432 - loss: 0.46875396370887756\n",
      "Batch 5433 - loss: 0.45305323600769043\n",
      "Batch 5434 - loss: 0.5237141251564026\n",
      "Batch 5435 - loss: 0.5252655744552612\n",
      "Batch 5436 - loss: 0.5355072617530823\n",
      "Batch 5437 - loss: 0.5484105348587036\n",
      "Batch 5438 - loss: 0.5242789387702942\n",
      "Batch 5439 - loss: 0.4792618155479431\n",
      "Batch 5440 - loss: 0.4970250725746155\n",
      "Batch 5441 - loss: 0.5193615555763245\n",
      "Batch 5442 - loss: 0.47915714979171753\n",
      "Batch 5443 - loss: 0.5127657055854797\n",
      "Batch 5444 - loss: 0.5210044384002686\n",
      "Batch 5445 - loss: 0.5541735887527466\n",
      "Batch 5446 - loss: 0.4876244068145752\n",
      "Batch 5447 - loss: 0.5209985375404358\n",
      "Batch 5448 - loss: 0.5658202171325684\n",
      "Batch 5449 - loss: 0.5671858191490173\n",
      "Batch 5450 - loss: 0.4768642485141754\n",
      "Batch 5451 - loss: 0.5435137748718262\n",
      "Batch 5452 - loss: 0.4648972451686859\n",
      "Batch 5453 - loss: 0.47809532284736633\n",
      "Batch 5454 - loss: 0.49367469549179077\n",
      "Batch 5455 - loss: 0.5249689221382141\n",
      "Batch 5456 - loss: 0.568068265914917\n",
      "Batch 5457 - loss: 0.5234211087226868\n",
      "Batch 5458 - loss: 0.4672856628894806\n",
      "Batch 5459 - loss: 0.49874627590179443\n",
      "Batch 5460 - loss: 0.48961538076400757\n",
      "Batch 5461 - loss: 0.4775819778442383\n",
      "Batch 5462 - loss: 0.5742613077163696\n",
      "Batch 5463 - loss: 0.5497969388961792\n",
      "Batch 5464 - loss: 0.4708639085292816\n",
      "Batch 5465 - loss: 0.5694389939308167\n",
      "Batch 5466 - loss: 0.48852837085723877\n",
      "Batch 5467 - loss: 0.5054774880409241\n",
      "Batch 5468 - loss: 0.5222662687301636\n",
      "Batch 5469 - loss: 0.4716055393218994\n",
      "Batch 5470 - loss: 0.517918586730957\n",
      "Batch 5471 - loss: 0.5157426595687866\n",
      "Batch 5472 - loss: 0.571106493473053\n",
      "Batch 5473 - loss: 0.5003437399864197\n",
      "Batch 5474 - loss: 0.4938746690750122\n",
      "Batch 5475 - loss: 0.5075013041496277\n",
      "Batch 5476 - loss: 0.581078290939331\n",
      "Batch 5477 - loss: 0.5057232975959778\n",
      "Batch 5478 - loss: 0.48114708065986633\n",
      "Batch 5479 - loss: 0.5181547999382019\n",
      "Batch 5480 - loss: 0.5463231801986694\n",
      "Batch 5481 - loss: 0.4937898516654968\n",
      "Batch 5482 - loss: 0.5582087635993958\n",
      "Batch 5483 - loss: 0.5188137292861938\n",
      "Batch 5484 - loss: 0.4828717112541199\n",
      "Batch 5485 - loss: 0.5654885172843933\n",
      "Batch 5486 - loss: 0.5393257141113281\n",
      "Batch 5487 - loss: 0.5535932183265686\n",
      "Batch 5488 - loss: 0.5226951837539673\n",
      "Batch 5489 - loss: 0.5132043361663818\n",
      "Batch 5490 - loss: 0.4879281520843506\n",
      "Batch 5491 - loss: 0.51026850938797\n",
      "Batch 5492 - loss: 0.5346892476081848\n",
      "Batch 5493 - loss: 0.4775075316429138\n",
      "Batch 5494 - loss: 0.516381025314331\n",
      "Batch 5495 - loss: 0.5097498297691345\n",
      "Batch 5496 - loss: 0.5817951560020447\n",
      "Batch 5497 - loss: 0.5160205364227295\n",
      "Batch 5498 - loss: 0.5083838105201721\n",
      "Batch 5499 - loss: 0.5300695300102234\n",
      "Batch 5500 - loss: 0.4996674060821533\n",
      "Batch 5501 - loss: 0.5034500360488892\n",
      "Batch 5502 - loss: 0.5188814401626587\n",
      "Batch 5503 - loss: 0.46706336736679077\n",
      "Batch 5504 - loss: 0.4727182686328888\n",
      "Batch 5505 - loss: 0.5153810977935791\n",
      "Batch 5506 - loss: 0.6024190783500671\n",
      "Batch 5507 - loss: 0.5014399290084839\n",
      "Batch 5508 - loss: 0.5525485277175903\n",
      "Batch 5509 - loss: 0.5065895318984985\n",
      "Batch 5510 - loss: 0.49175527691841125\n",
      "Batch 5511 - loss: 0.4972095787525177\n",
      "Batch 5512 - loss: 0.4681144058704376\n",
      "Batch 5513 - loss: 0.557931661605835\n",
      "Batch 5514 - loss: 0.47751855850219727\n",
      "Batch 5515 - loss: 0.5021592974662781\n",
      "Batch 5516 - loss: 0.4674929678440094\n",
      "Batch 5517 - loss: 0.45540177822113037\n",
      "Batch 5518 - loss: 0.5638964772224426\n",
      "Batch 5519 - loss: 0.4950329661369324\n",
      "Batch 5520 - loss: 0.546937108039856\n",
      "Batch 5521 - loss: 0.5494601130485535\n",
      "Batch 5522 - loss: 0.5177827477455139\n",
      "Batch 5523 - loss: 0.4956326186656952\n",
      "Batch 5524 - loss: 0.5035825967788696\n",
      "Batch 5525 - loss: 0.5377485156059265\n",
      "Batch 5526 - loss: 0.49547481536865234\n",
      "Batch 5527 - loss: 0.525349497795105\n",
      "Batch 5528 - loss: 0.5060956478118896\n",
      "Batch 5529 - loss: 0.5698568820953369\n",
      "Batch 5530 - loss: 0.5349031090736389\n",
      "Batch 5531 - loss: 0.541495680809021\n",
      "Batch 5532 - loss: 0.5589599609375\n",
      "Batch 5533 - loss: 0.5263727307319641\n",
      "Batch 5534 - loss: 0.5556666851043701\n",
      "Batch 5535 - loss: 0.5919269919395447\n",
      "Batch 5536 - loss: 0.589749276638031\n",
      "Batch 5537 - loss: 0.4721556007862091\n",
      "Batch 5538 - loss: 0.5779405832290649\n",
      "Batch 5539 - loss: 0.5288758277893066\n",
      "Batch 5540 - loss: 0.5076663494110107\n",
      "Batch 5541 - loss: 0.4869248867034912\n",
      "Batch 5542 - loss: 0.4949209988117218\n",
      "Batch 5543 - loss: 0.6065959334373474\n",
      "Batch 5544 - loss: 0.47350940108299255\n",
      "Batch 5545 - loss: 0.5276468396186829\n",
      "Batch 5546 - loss: 0.5821911692619324\n",
      "Batch 5547 - loss: 0.5441953539848328\n",
      "Batch 5548 - loss: 0.5429653525352478\n",
      "Batch 5549 - loss: 0.5833291411399841\n",
      "Batch 5550 - loss: 0.4690179228782654\n",
      "Batch 5551 - loss: 0.4869197905063629\n",
      "Batch 5552 - loss: 0.44049665331840515\n",
      "Batch 5553 - loss: 0.5733548998832703\n",
      "Batch 5554 - loss: 0.5000588297843933\n",
      "Batch 5555 - loss: 0.5451413989067078\n",
      "Batch 5556 - loss: 0.49823126196861267\n",
      "Batch 5557 - loss: 0.521580159664154\n",
      "Batch 5558 - loss: 0.5290214419364929\n",
      "Batch 5559 - loss: 0.45278796553611755\n",
      "Batch 5560 - loss: 0.5057483911514282\n",
      "Batch 5561 - loss: 0.485116571187973\n",
      "Batch 5562 - loss: 0.5285927653312683\n",
      "Batch 5563 - loss: 0.5051421523094177\n",
      "Batch 5564 - loss: 0.48448148369789124\n",
      "Batch 5565 - loss: 0.49628955125808716\n",
      "Batch 5566 - loss: 0.5179483890533447\n",
      "Batch 5567 - loss: 0.5069507956504822\n",
      "Batch 5568 - loss: 0.5197553634643555\n",
      "Batch 5569 - loss: 0.5293242931365967\n",
      "Batch 5570 - loss: 0.5174502730369568\n",
      "Batch 5571 - loss: 0.5262193083763123\n",
      "Batch 5572 - loss: 0.5353689789772034\n",
      "Batch 5573 - loss: 0.49169108271598816\n",
      "Batch 5574 - loss: 0.48579150438308716\n",
      "Batch 5575 - loss: 0.49925851821899414\n",
      "Batch 5576 - loss: 0.5201773047447205\n",
      "Batch 5577 - loss: 0.4561308026313782\n",
      "Batch 5578 - loss: 0.47259020805358887\n",
      "Batch 5579 - loss: 0.549526572227478\n",
      "Batch 5580 - loss: 0.5381715893745422\n",
      "Batch 5581 - loss: 0.4884647727012634\n",
      "Batch 5582 - loss: 0.5063570737838745\n",
      "Batch 5583 - loss: 0.4829954206943512\n",
      "Batch 5584 - loss: 0.5714229345321655\n",
      "Batch 5585 - loss: 0.5112279057502747\n",
      "Batch 5586 - loss: 0.5377432703971863\n",
      "Batch 5587 - loss: 0.4961451590061188\n",
      "Batch 5588 - loss: 0.5054087042808533\n",
      "Batch 5589 - loss: 0.5154550075531006\n",
      "Batch 5590 - loss: 0.5271242260932922\n",
      "Batch 5591 - loss: 0.4931310713291168\n",
      "Batch 5592 - loss: 0.46163129806518555\n",
      "Batch 5593 - loss: 0.5142017006874084\n",
      "Batch 5594 - loss: 0.5112398266792297\n",
      "Batch 5595 - loss: 0.463401198387146\n",
      "Batch 5596 - loss: 0.47632256150245667\n",
      "Batch 5597 - loss: 0.485169917345047\n",
      "Batch 5598 - loss: 0.5045121312141418\n",
      "Batch 5599 - loss: 0.5607249736785889\n",
      "Batch 5600 - loss: 0.5214203596115112\n",
      "Batch 5601 - loss: 0.4904541075229645\n",
      "Batch 5602 - loss: 0.4653869867324829\n",
      "Batch 5603 - loss: 0.5236979126930237\n",
      "Batch 5604 - loss: 0.5103312730789185\n",
      "Batch 5605 - loss: 0.5237686038017273\n",
      "Batch 5606 - loss: 0.5130811929702759\n",
      "Batch 5607 - loss: 0.598232626914978\n",
      "Batch 5608 - loss: 0.5476483702659607\n",
      "Batch 5609 - loss: 0.52608722448349\n",
      "Batch 5610 - loss: 0.5359543561935425\n",
      "Batch 5611 - loss: 0.5445643067359924\n",
      "Batch 5612 - loss: 0.5191922187805176\n",
      "Batch 5613 - loss: 0.542324960231781\n",
      "Batch 5614 - loss: 0.5300323963165283\n",
      "Batch 5615 - loss: 0.5018817186355591\n",
      "Batch 5616 - loss: 0.5145537853240967\n",
      "Batch 5617 - loss: 0.5841931104660034\n",
      "Batch 5618 - loss: 0.6381890177726746\n",
      "Batch 5619 - loss: 0.4894285500049591\n",
      "Batch 5620 - loss: 0.524623692035675\n",
      "Batch 5621 - loss: 0.4943333864212036\n",
      "Batch 5622 - loss: 0.4856366217136383\n",
      "Batch 5623 - loss: 0.5465359091758728\n",
      "Batch 5624 - loss: 0.5124760866165161\n",
      "Batch 5625 - loss: 0.5396265387535095\n",
      "Batch 5626 - loss: 0.4772379398345947\n",
      "Batch 5627 - loss: 0.5601425766944885\n",
      "Batch 5628 - loss: 0.5246962904930115\n",
      "Batch 5629 - loss: 0.4964892864227295\n",
      "Batch 5630 - loss: 0.5159621238708496\n",
      "Batch 5631 - loss: 0.5041793584823608\n",
      "Batch 5632 - loss: 0.48971226811408997\n",
      "Batch 5633 - loss: 0.48298558592796326\n",
      "Batch 5634 - loss: 0.48638516664505005\n",
      "Batch 5635 - loss: 0.5704251527786255\n",
      "Batch 5636 - loss: 0.5174112915992737\n",
      "Batch 5637 - loss: 0.5293974876403809\n",
      "Batch 5638 - loss: 0.5509525537490845\n",
      "Batch 5639 - loss: 0.4931575357913971\n",
      "Batch 5640 - loss: 0.5024210214614868\n",
      "Batch 5641 - loss: 0.4789319634437561\n",
      "Batch 5642 - loss: 0.4562075138092041\n",
      "Batch 5643 - loss: 0.5734597444534302\n",
      "Batch 5644 - loss: 0.5416808128356934\n",
      "Batch 5645 - loss: 0.501034677028656\n",
      "Batch 5646 - loss: 0.5089871287345886\n",
      "Batch 5647 - loss: 0.5224010348320007\n",
      "Batch 5648 - loss: 0.5077992081642151\n",
      "Batch 5649 - loss: 0.5193056464195251\n",
      "Batch 5650 - loss: 0.5479937791824341\n",
      "Batch 5651 - loss: 0.47741737961769104\n",
      "Batch 5652 - loss: 0.48835694789886475\n",
      "Batch 5653 - loss: 0.491394579410553\n",
      "Batch 5654 - loss: 0.5328174829483032\n",
      "Batch 5655 - loss: 0.5751944184303284\n",
      "Batch 5656 - loss: 0.5554951429367065\n",
      "Batch 5657 - loss: 0.5998616218566895\n",
      "Batch 5658 - loss: 0.5739556550979614\n",
      "Batch 5659 - loss: 0.5516341328620911\n",
      "Batch 5660 - loss: 0.5107761025428772\n",
      "Batch 5661 - loss: 0.5340027809143066\n",
      "Batch 5662 - loss: 0.4946311116218567\n",
      "Batch 5663 - loss: 0.5192010402679443\n",
      "Batch 5664 - loss: 0.4642464518547058\n",
      "Batch 5665 - loss: 0.5052857995033264\n",
      "Batch 5666 - loss: 0.5499557852745056\n",
      "Batch 5667 - loss: 0.4456137716770172\n",
      "Batch 5668 - loss: 0.5236821174621582\n",
      "Batch 5669 - loss: 0.5284542441368103\n",
      "Batch 5670 - loss: 0.505970299243927\n",
      "Batch 5671 - loss: 0.5041199326515198\n",
      "Batch 5672 - loss: 0.530871570110321\n",
      "Batch 5673 - loss: 0.4609154164791107\n",
      "Batch 5674 - loss: 0.47837474942207336\n",
      "Batch 5675 - loss: 0.4712820053100586\n",
      "Batch 5676 - loss: 0.5265224575996399\n",
      "Batch 5677 - loss: 0.4718513488769531\n",
      "Batch 5678 - loss: 0.5105451941490173\n",
      "Batch 5679 - loss: 0.4784107804298401\n",
      "Batch 5680 - loss: 0.46964654326438904\n",
      "Batch 5681 - loss: 0.5286380648612976\n",
      "Batch 5682 - loss: 0.5171822309494019\n",
      "Batch 5683 - loss: 0.5492410659790039\n",
      "Batch 5684 - loss: 0.5399661660194397\n",
      "Batch 5685 - loss: 0.47981834411621094\n",
      "Batch 5686 - loss: 0.5143976807594299\n",
      "Batch 5687 - loss: 0.5152354836463928\n",
      "Batch 5688 - loss: 0.5839993953704834\n",
      "Batch 5689 - loss: 0.5133348107337952\n",
      "Batch 5690 - loss: 0.4986865520477295\n",
      "Batch 5691 - loss: 0.5299511551856995\n",
      "Batch 5692 - loss: 0.5457252860069275\n",
      "Batch 5693 - loss: 0.5257577896118164\n",
      "Batch 5694 - loss: 0.5306528210639954\n",
      "Batch 5695 - loss: 0.4922720193862915\n",
      "Batch 5696 - loss: 0.49132150411605835\n",
      "Batch 5697 - loss: 0.5035008788108826\n",
      "Batch 5698 - loss: 0.5170320272445679\n",
      "Batch 5699 - loss: 0.5422359704971313\n",
      "Batch 5700 - loss: 0.5685918927192688\n",
      "Batch 5701 - loss: 0.533605694770813\n",
      "Batch 5702 - loss: 0.4853087365627289\n",
      "Batch 5703 - loss: 0.542124330997467\n",
      "Batch 5704 - loss: 0.5118172764778137\n",
      "Batch 5705 - loss: 0.4624675214290619\n",
      "Batch 5706 - loss: 0.508801281452179\n",
      "Batch 5707 - loss: 0.5201298594474792\n",
      "Batch 5708 - loss: 0.5452843308448792\n",
      "Batch 5709 - loss: 0.5101712942123413\n",
      "Batch 5710 - loss: 0.4757680296897888\n",
      "Batch 5711 - loss: 0.5274999737739563\n",
      "Batch 5712 - loss: 0.48007071018218994\n",
      "Batch 5713 - loss: 0.5187139511108398\n",
      "Batch 5714 - loss: 0.5306766033172607\n",
      "Batch 5715 - loss: 0.4929862320423126\n",
      "Batch 5716 - loss: 0.56895911693573\n",
      "Batch 5717 - loss: 0.5709916949272156\n",
      "Batch 5718 - loss: 0.48969823122024536\n",
      "Batch 5719 - loss: 0.501203179359436\n",
      "Batch 5720 - loss: 0.45633888244628906\n",
      "Batch 5721 - loss: 0.49619078636169434\n",
      "Batch 5722 - loss: 0.47921022772789\n",
      "Batch 5723 - loss: 0.5284054279327393\n",
      "Batch 5724 - loss: 0.5259642601013184\n",
      "Batch 5725 - loss: 0.42010748386383057\n",
      "Batch 5726 - loss: 0.5032126307487488\n",
      "Batch 5727 - loss: 0.5523731112480164\n",
      "Batch 5728 - loss: 0.4919750988483429\n",
      "Batch 5729 - loss: 0.49442172050476074\n",
      "Batch 5730 - loss: 0.4827618896961212\n",
      "Batch 5731 - loss: 0.4801461100578308\n",
      "Batch 5732 - loss: 0.47417861223220825\n",
      "Batch 5733 - loss: 0.5291289687156677\n",
      "Batch 5734 - loss: 0.4937797784805298\n",
      "Batch 5735 - loss: 0.5200233459472656\n",
      "Batch 5736 - loss: 0.4992106556892395\n",
      "Batch 5737 - loss: 0.5025182962417603\n",
      "Batch 5738 - loss: 0.5255630612373352\n",
      "Batch 5739 - loss: 0.5089048147201538\n",
      "Batch 5740 - loss: 0.5323094129562378\n",
      "Batch 5741 - loss: 0.4889947474002838\n",
      "Batch 5742 - loss: 0.5403665900230408\n",
      "Batch 5743 - loss: 0.5458261370658875\n",
      "Batch 5744 - loss: 0.5432968139648438\n",
      "Batch 5745 - loss: 0.5199283361434937\n",
      "Batch 5746 - loss: 0.465661883354187\n",
      "Batch 5747 - loss: 0.516609787940979\n",
      "Batch 5748 - loss: 0.5559305548667908\n",
      "Batch 5749 - loss: 0.5604538321495056\n",
      "Batch 5750 - loss: 0.49636125564575195\n",
      "Batch 5751 - loss: 0.5130118727684021\n",
      "Batch 5752 - loss: 0.5380808711051941\n",
      "Batch 5753 - loss: 0.5180938243865967\n",
      "Batch 5754 - loss: 0.5095828175544739\n",
      "Batch 5755 - loss: 0.4610219895839691\n",
      "Batch 5756 - loss: 0.5329815149307251\n",
      "Batch 5757 - loss: 0.5028179287910461\n",
      "Batch 5758 - loss: 0.4943009316921234\n",
      "Batch 5759 - loss: 0.5151625275611877\n",
      "Batch 5760 - loss: 0.48597389459609985\n",
      "Batch 5761 - loss: 0.5238311290740967\n",
      "Batch 5762 - loss: 0.5123926997184753\n",
      "Batch 5763 - loss: 0.5384699702262878\n",
      "Batch 5764 - loss: 0.4836891293525696\n",
      "Batch 5765 - loss: 0.4999711215496063\n",
      "Batch 5766 - loss: 0.6117351055145264\n",
      "Batch 5767 - loss: 0.561635434627533\n",
      "Batch 5768 - loss: 0.520011842250824\n",
      "Batch 5769 - loss: 0.5226107239723206\n",
      "Batch 5770 - loss: 0.5001991987228394\n",
      "Batch 5771 - loss: 0.5592330694198608\n",
      "Batch 5772 - loss: 0.5548089146614075\n",
      "Batch 5773 - loss: 0.520858883857727\n",
      "Batch 5774 - loss: 0.5150245428085327\n",
      "Batch 5775 - loss: 0.5346064567565918\n",
      "Batch 5776 - loss: 0.5391745567321777\n",
      "Batch 5777 - loss: 0.5493337512016296\n",
      "Batch 5778 - loss: 0.5158897638320923\n",
      "Batch 5779 - loss: 0.48292621970176697\n",
      "Batch 5780 - loss: 0.46420982480049133\n",
      "Batch 5781 - loss: 0.5568275451660156\n",
      "Batch 5782 - loss: 0.4906401038169861\n",
      "Batch 5783 - loss: 0.5309785008430481\n",
      "Batch 5784 - loss: 0.49664828181266785\n",
      "Batch 5785 - loss: 0.5276700854301453\n",
      "Batch 5786 - loss: 0.47983524203300476\n",
      "Batch 5787 - loss: 0.5362743139266968\n",
      "Batch 5788 - loss: 0.49720966815948486\n",
      "Batch 5789 - loss: 0.5874279141426086\n",
      "Batch 5790 - loss: 0.4989722967147827\n",
      "Batch 5791 - loss: 0.46916407346725464\n",
      "Batch 5792 - loss: 0.5505420565605164\n",
      "Batch 5793 - loss: 0.5256971120834351\n",
      "Batch 5794 - loss: 0.5556021928787231\n",
      "Batch 5795 - loss: 0.5572803020477295\n",
      "Batch 5796 - loss: 0.5235743522644043\n",
      "Batch 5797 - loss: 0.5364471673965454\n",
      "Batch 5798 - loss: 0.48938700556755066\n",
      "Batch 5799 - loss: 0.5152185559272766\n",
      "Batch 5800 - loss: 0.4682716727256775\n",
      "Batch 5801 - loss: 0.5178605318069458\n",
      "Batch 5802 - loss: 0.5423329472541809\n",
      "Batch 5803 - loss: 0.46051836013793945\n",
      "Batch 5804 - loss: 0.5201876759529114\n",
      "Batch 5805 - loss: 0.5384514927864075\n",
      "Batch 5806 - loss: 0.5343542098999023\n",
      "Batch 5807 - loss: 0.49081137776374817\n",
      "Batch 5808 - loss: 0.5504835844039917\n",
      "Batch 5809 - loss: 0.4634508788585663\n",
      "Batch 5810 - loss: 0.5415337681770325\n",
      "Batch 5811 - loss: 0.5500038862228394\n",
      "Batch 5812 - loss: 0.5393717885017395\n",
      "Batch 5813 - loss: 0.4605320692062378\n",
      "Batch 5814 - loss: 0.48895540833473206\n",
      "Batch 5815 - loss: 0.4789275527000427\n",
      "Batch 5816 - loss: 0.518503725528717\n",
      "Batch 5817 - loss: 0.5097641944885254\n",
      "Batch 5818 - loss: 0.4932560622692108\n",
      "Batch 5819 - loss: 0.5417020916938782\n",
      "Batch 5820 - loss: 0.5355616211891174\n",
      "Batch 5821 - loss: 0.4268399178981781\n",
      "Batch 5822 - loss: 0.5044801831245422\n",
      "Batch 5823 - loss: 0.4943621754646301\n",
      "Batch 5824 - loss: 0.5209524631500244\n",
      "Batch 5825 - loss: 0.5741094350814819\n",
      "Batch 5826 - loss: 0.4926294982433319\n",
      "Batch 5827 - loss: 0.547073483467102\n",
      "Batch 5828 - loss: 0.4732486605644226\n",
      "Batch 5829 - loss: 0.5088056325912476\n",
      "Batch 5830 - loss: 0.4632132947444916\n",
      "Batch 5831 - loss: 0.5261334776878357\n",
      "Batch 5832 - loss: 0.5150508284568787\n",
      "Batch 5833 - loss: 0.48388952016830444\n",
      "Batch 5834 - loss: 0.5230924487113953\n",
      "Batch 5835 - loss: 0.52051842212677\n",
      "Batch 5836 - loss: 0.563094973564148\n",
      "Batch 5837 - loss: 0.47532787919044495\n",
      "Batch 5838 - loss: 0.5760844945907593\n",
      "Batch 5839 - loss: 0.5318219065666199\n",
      "Batch 5840 - loss: 0.4860648512840271\n",
      "Batch 5841 - loss: 0.7602887153625488\n",
      "Batch 5842 - loss: 0.5244278311729431\n",
      "Batch 5843 - loss: 0.535919725894928\n",
      "Batch 5844 - loss: 0.4975593388080597\n",
      "Batch 5845 - loss: 0.5674743056297302\n",
      "Batch 5846 - loss: 0.5302938222885132\n",
      "Batch 5847 - loss: 0.5438846349716187\n",
      "Batch 5848 - loss: 0.539548397064209\n",
      "Batch 5849 - loss: 0.5638549327850342\n",
      "Batch 5850 - loss: 0.5002408027648926\n",
      "Batch 5851 - loss: 0.5440666079521179\n",
      "Batch 5852 - loss: 0.4589109718799591\n",
      "Batch 5853 - loss: 0.48525863885879517\n",
      "Batch 5854 - loss: 0.513141930103302\n",
      "Batch 5855 - loss: 0.531304657459259\n",
      "Batch 5856 - loss: 0.5157167911529541\n",
      "Batch 5857 - loss: 0.4927034378051758\n",
      "Batch 5858 - loss: 0.48084840178489685\n",
      "Batch 5859 - loss: 0.5108293890953064\n",
      "Batch 5860 - loss: 0.4820574223995209\n",
      "Batch 5861 - loss: 0.5183495879173279\n",
      "Batch 5862 - loss: 0.5162943005561829\n",
      "Batch 5863 - loss: 0.5094506144523621\n",
      "Batch 5864 - loss: 0.5338577628135681\n",
      "Batch 5865 - loss: 0.5259518027305603\n",
      "Batch 5866 - loss: 0.5242660045623779\n",
      "Batch 5867 - loss: 0.5167379379272461\n",
      "Batch 5868 - loss: 0.4758778512477875\n",
      "Batch 5869 - loss: 0.5283330678939819\n",
      "Batch 5870 - loss: 0.5679737329483032\n",
      "Batch 5871 - loss: 0.5607003569602966\n",
      "Batch 5872 - loss: 0.5414912700653076\n",
      "Batch 5873 - loss: 0.5172789692878723\n",
      "Batch 5874 - loss: 0.44964921474456787\n",
      "Batch 5875 - loss: 0.5424532294273376\n",
      "Batch 5876 - loss: 0.599991500377655\n",
      "Batch 5877 - loss: 0.47417593002319336\n",
      "Batch 5878 - loss: 0.46495524048805237\n",
      "Batch 5879 - loss: 0.5363242030143738\n",
      "Batch 5880 - loss: 0.46534258127212524\n",
      "Batch 5881 - loss: 0.5524052381515503\n",
      "Batch 5882 - loss: 0.4644232392311096\n",
      "Batch 5883 - loss: 0.558830976486206\n",
      "Batch 5884 - loss: 0.5824395418167114\n",
      "Batch 5885 - loss: 0.550417423248291\n",
      "Batch 5886 - loss: 0.5320032835006714\n",
      "Batch 5887 - loss: 0.5541195869445801\n",
      "Batch 5888 - loss: 0.5370018482208252\n",
      "Batch 5889 - loss: 0.5420103669166565\n",
      "Batch 5890 - loss: 0.6093029975891113\n",
      "Batch 5891 - loss: 0.5155839920043945\n",
      "Batch 5892 - loss: 0.5187045335769653\n",
      "Batch 5893 - loss: 0.5449565649032593\n",
      "Batch 5894 - loss: 0.482011079788208\n",
      "Batch 5895 - loss: 0.5344029664993286\n",
      "Batch 5896 - loss: 0.5631407499313354\n",
      "Batch 5897 - loss: 0.5194615125656128\n",
      "Batch 5898 - loss: 0.5105078816413879\n",
      "Batch 5899 - loss: 0.5142923593521118\n",
      "Batch 5900 - loss: 0.5552262663841248\n",
      "Batch 5901 - loss: 0.5510183572769165\n",
      "Batch 5902 - loss: 0.4868309199810028\n",
      "Batch 5903 - loss: 0.5681723356246948\n",
      "Batch 5904 - loss: 0.48003122210502625\n",
      "Batch 5905 - loss: 0.5025966763496399\n",
      "Batch 5906 - loss: 0.5225409865379333\n",
      "Batch 5907 - loss: 0.48156121373176575\n",
      "Batch 5908 - loss: 0.5603663325309753\n",
      "Batch 5909 - loss: 0.48261359333992004\n",
      "Batch 5910 - loss: 0.4901878833770752\n",
      "Batch 5911 - loss: 0.5556343793869019\n",
      "Batch 5912 - loss: 0.5918493270874023\n",
      "Batch 5913 - loss: 0.53878253698349\n",
      "Batch 5914 - loss: 0.5765349268913269\n",
      "Batch 5915 - loss: 0.49663758277893066\n",
      "Batch 5916 - loss: 0.5310814380645752\n",
      "Batch 5917 - loss: 0.5593787431716919\n",
      "Batch 5918 - loss: 0.5002284049987793\n",
      "Batch 5919 - loss: 0.516710638999939\n",
      "Batch 5920 - loss: 0.4817749261856079\n",
      "Batch 5921 - loss: 0.5413669943809509\n",
      "Batch 5922 - loss: 0.5294446349143982\n",
      "Batch 5923 - loss: 0.5493185520172119\n",
      "Batch 5924 - loss: 0.5411427617073059\n",
      "Batch 5925 - loss: 0.5855966806411743\n",
      "Batch 5926 - loss: 0.506645917892456\n",
      "Batch 5927 - loss: 0.5628981590270996\n",
      "Batch 5928 - loss: 0.5151299238204956\n",
      "Batch 5929 - loss: 0.46515676379203796\n",
      "Batch 5930 - loss: 0.5368914008140564\n",
      "Batch 5931 - loss: 0.5180138945579529\n",
      "Batch 5932 - loss: 0.5410815477371216\n",
      "Batch 5933 - loss: 0.4668322801589966\n",
      "Batch 5934 - loss: 0.5025238394737244\n",
      "Batch 5935 - loss: 0.5080483555793762\n",
      "Batch 5936 - loss: 0.4901893734931946\n",
      "Batch 5937 - loss: 0.48445338010787964\n",
      "Batch 5938 - loss: 0.5537660121917725\n",
      "Batch 5939 - loss: 0.4970928728580475\n",
      "Batch 5940 - loss: 0.5487931370735168\n",
      "Batch 5941 - loss: 0.5322614312171936\n",
      "Batch 5942 - loss: 0.48837509751319885\n",
      "Batch 5943 - loss: 0.4990377724170685\n",
      "Batch 5944 - loss: 0.564349889755249\n",
      "Batch 5945 - loss: 0.6090371012687683\n",
      "Batch 5946 - loss: 0.6056317687034607\n",
      "Batch 5947 - loss: 0.5135726928710938\n",
      "Batch 5948 - loss: 0.5500258207321167\n",
      "Batch 5949 - loss: 0.4471428692340851\n",
      "Batch 5950 - loss: 0.5423793792724609\n",
      "Batch 5951 - loss: 0.4835491180419922\n",
      "Batch 5952 - loss: 0.5100951790809631\n",
      "Batch 5953 - loss: 0.5034943222999573\n",
      "Batch 5954 - loss: 0.5234071016311646\n",
      "Batch 5955 - loss: 0.5271409749984741\n",
      "Batch 5956 - loss: 0.46683692932128906\n",
      "Batch 5957 - loss: 0.5163365006446838\n",
      "Batch 5958 - loss: 0.5168683528900146\n",
      "Batch 5959 - loss: 0.5005419850349426\n",
      "Batch 5960 - loss: 0.5368013978004456\n",
      "Batch 5961 - loss: 0.5552496910095215\n",
      "Batch 5962 - loss: 0.5267364382743835\n",
      "Batch 5963 - loss: 0.476610392332077\n",
      "Batch 5964 - loss: 0.5229949355125427\n",
      "Batch 5965 - loss: 0.47899529337882996\n",
      "Batch 5966 - loss: 0.4872933328151703\n",
      "Batch 5967 - loss: 0.49164676666259766\n",
      "Batch 5968 - loss: 0.5986568927764893\n",
      "Batch 5969 - loss: 0.5642415285110474\n",
      "Batch 5970 - loss: 0.5587547421455383\n",
      "Batch 5971 - loss: 0.5363568663597107\n",
      "Batch 5972 - loss: 0.48261699080467224\n",
      "Batch 5973 - loss: 0.5089549422264099\n",
      "Batch 5974 - loss: 0.4895517826080322\n",
      "Batch 5975 - loss: 0.5290415287017822\n",
      "Batch 5976 - loss: 0.5181655287742615\n",
      "Batch 5977 - loss: 0.5842936635017395\n",
      "Batch 5978 - loss: 0.5006101727485657\n",
      "Batch 5979 - loss: 0.4540594816207886\n",
      "Batch 5980 - loss: 0.4909537732601166\n",
      "Batch 5981 - loss: 0.5225836634635925\n",
      "Batch 5982 - loss: 0.5537608861923218\n",
      "Batch 5983 - loss: 0.5230888724327087\n",
      "Batch 5984 - loss: 0.4961196184158325\n",
      "Batch 5985 - loss: 0.5219987034797668\n",
      "Batch 5986 - loss: 0.5048093199729919\n",
      "Batch 5987 - loss: 0.48838698863983154\n",
      "Batch 5988 - loss: 0.513469398021698\n",
      "Batch 5989 - loss: 0.5919028520584106\n",
      "Batch 5990 - loss: 0.4904618561267853\n",
      "Batch 5991 - loss: 0.5407165288925171\n",
      "Batch 5992 - loss: 0.5580650568008423\n",
      "Batch 5993 - loss: 0.519055187702179\n",
      "Batch 5994 - loss: 0.5713755488395691\n",
      "Batch 5995 - loss: 0.5405864119529724\n",
      "Batch 5996 - loss: 0.6189426779747009\n",
      "Batch 5997 - loss: 0.5007851123809814\n",
      "Batch 5998 - loss: 0.5198128819465637\n",
      "Batch 5999 - loss: 0.5091773867607117\n",
      "Batch 6000 - loss: 0.5126119256019592\n",
      "Batch 6001 - loss: 0.5468589067459106\n",
      "Batch 6002 - loss: 0.48114728927612305\n",
      "Batch 6003 - loss: 0.560649573802948\n",
      "Batch 6004 - loss: 0.6012123823165894\n",
      "Batch 6005 - loss: 0.5044267773628235\n",
      "Batch 6006 - loss: 0.4891543686389923\n",
      "Batch 6007 - loss: 0.5410593748092651\n",
      "Batch 6008 - loss: 0.5371243953704834\n",
      "Batch 6009 - loss: 0.5358217358589172\n",
      "Batch 6010 - loss: 0.5115460753440857\n",
      "Batch 6011 - loss: 0.5039141774177551\n",
      "Batch 6012 - loss: 0.4764498770236969\n",
      "Batch 6013 - loss: 0.511984646320343\n",
      "Batch 6014 - loss: 0.582554280757904\n",
      "Batch 6015 - loss: 0.5279638767242432\n",
      "Batch 6016 - loss: 0.5341578722000122\n",
      "Batch 6017 - loss: 0.5358814001083374\n",
      "Batch 6018 - loss: 0.519504189491272\n",
      "Batch 6019 - loss: 0.47225213050842285\n",
      "Batch 6020 - loss: 0.5067551732063293\n",
      "Batch 6021 - loss: 0.5081949830055237\n",
      "Batch 6022 - loss: 0.47111040353775024\n",
      "Batch 6023 - loss: 0.5332931280136108\n",
      "Batch 6024 - loss: 0.46750715374946594\n",
      "Batch 6025 - loss: 0.5119730234146118\n",
      "Batch 6026 - loss: 0.5390288829803467\n",
      "Batch 6027 - loss: 0.5659603476524353\n",
      "Batch 6028 - loss: 0.45382723212242126\n",
      "Batch 6029 - loss: 0.47981640696525574\n",
      "Batch 6030 - loss: 0.4769178628921509\n",
      "Batch 6031 - loss: 0.49344637989997864\n",
      "Batch 6032 - loss: 0.5838263630867004\n",
      "Batch 6033 - loss: 0.5939066410064697\n",
      "Batch 6034 - loss: 0.5581957101821899\n",
      "Batch 6035 - loss: 0.5131237506866455\n",
      "Batch 6036 - loss: 0.48679977655410767\n",
      "Batch 6037 - loss: 0.48507991433143616\n",
      "Batch 6038 - loss: 0.49611160159111023\n",
      "Batch 6039 - loss: 0.471319317817688\n",
      "Batch 6040 - loss: 0.5463912487030029\n",
      "Batch 6041 - loss: 0.5264226198196411\n",
      "Batch 6042 - loss: 0.49463051557540894\n",
      "Batch 6043 - loss: 0.529484212398529\n",
      "Batch 6044 - loss: 0.5249059796333313\n",
      "Batch 6045 - loss: 0.47708168625831604\n",
      "Batch 6046 - loss: 0.5041124224662781\n",
      "Batch 6047 - loss: 0.5178869366645813\n",
      "Batch 6048 - loss: 0.5117378830909729\n",
      "Batch 6049 - loss: 0.557537317276001\n",
      "Batch 6050 - loss: 0.5250993371009827\n",
      "Batch 6051 - loss: 0.6133707165718079\n",
      "Batch 6052 - loss: 0.5163758993148804\n",
      "Batch 6053 - loss: 0.510167121887207\n",
      "Batch 6054 - loss: 0.4812960624694824\n",
      "Batch 6055 - loss: 0.549338698387146\n",
      "Batch 6056 - loss: 0.4998658299446106\n",
      "Batch 6057 - loss: 0.5430775284767151\n",
      "Batch 6058 - loss: 0.5005682706832886\n",
      "Batch 6059 - loss: 0.5362820029258728\n",
      "Batch 6060 - loss: 0.5637507438659668\n",
      "Batch 6061 - loss: 0.5271487236022949\n",
      "Batch 6062 - loss: 0.5073937773704529\n",
      "Batch 6063 - loss: 0.4911923110485077\n",
      "Batch 6064 - loss: 0.5363344550132751\n",
      "Batch 6065 - loss: 0.6334234476089478\n",
      "Batch 6066 - loss: 0.5210980176925659\n",
      "Batch 6067 - loss: 0.5359148979187012\n",
      "Batch 6068 - loss: 0.5937931537628174\n",
      "Batch 6069 - loss: 0.4980752170085907\n",
      "Batch 6070 - loss: 0.5164634585380554\n",
      "Batch 6071 - loss: 0.5305917859077454\n",
      "Batch 6072 - loss: 0.5585751533508301\n",
      "Batch 6073 - loss: 0.6191096305847168\n",
      "Batch 6074 - loss: 0.4994356036186218\n",
      "Batch 6075 - loss: 0.4461628198623657\n",
      "Batch 6076 - loss: 0.48737460374832153\n",
      "Batch 6077 - loss: 0.5088438987731934\n",
      "Batch 6078 - loss: 0.5226801633834839\n",
      "Batch 6079 - loss: 0.5339017510414124\n",
      "Batch 6080 - loss: 0.4947170615196228\n",
      "Batch 6081 - loss: 0.5167461633682251\n",
      "Batch 6082 - loss: 0.5349803566932678\n",
      "Batch 6083 - loss: 0.4802204668521881\n",
      "Batch 6084 - loss: 0.5357045531272888\n",
      "Batch 6085 - loss: 0.5390079617500305\n",
      "Batch 6086 - loss: 0.5177018642425537\n",
      "Batch 6087 - loss: 0.457979679107666\n",
      "Batch 6088 - loss: 0.5399520993232727\n",
      "Batch 6089 - loss: 0.48268261551856995\n",
      "Batch 6090 - loss: 0.4986332952976227\n",
      "Batch 6091 - loss: 0.4869903028011322\n",
      "Batch 6092 - loss: 0.5412136316299438\n",
      "Batch 6093 - loss: 0.5128004550933838\n",
      "Batch 6094 - loss: 0.49371349811553955\n",
      "Batch 6095 - loss: 0.5159447193145752\n",
      "Batch 6096 - loss: 0.5076622366905212\n",
      "Batch 6097 - loss: 0.49626636505126953\n",
      "Batch 6098 - loss: 0.46581321954727173\n",
      "Batch 6099 - loss: 0.48522618412971497\n",
      "Batch 6100 - loss: 0.5013793706893921\n",
      "Batch 6101 - loss: 0.5371312499046326\n",
      "Batch 6102 - loss: 0.508709728717804\n",
      "Batch 6103 - loss: 0.5081126689910889\n",
      "Batch 6104 - loss: 0.4810037314891815\n",
      "Batch 6105 - loss: 0.5189826488494873\n",
      "Batch 6106 - loss: 0.4958083927631378\n",
      "Batch 6107 - loss: 0.5126618146896362\n",
      "Batch 6108 - loss: 0.5227707624435425\n",
      "Batch 6109 - loss: 0.530319094657898\n",
      "Batch 6110 - loss: 0.5523537397384644\n",
      "Batch 6111 - loss: 0.5256907343864441\n",
      "Batch 6112 - loss: 0.5493033528327942\n",
      "Batch 6113 - loss: 0.5436416864395142\n",
      "Batch 6114 - loss: 0.5425465703010559\n",
      "Batch 6115 - loss: 0.5141697525978088\n",
      "Batch 6116 - loss: 0.4963117241859436\n",
      "Batch 6117 - loss: 0.457564115524292\n",
      "Batch 6118 - loss: 0.54658043384552\n",
      "Batch 6119 - loss: 0.5165103077888489\n",
      "Batch 6120 - loss: 0.501384973526001\n",
      "Batch 6121 - loss: 0.4772570729255676\n",
      "Batch 6122 - loss: 0.4918688237667084\n",
      "Batch 6123 - loss: 0.5394827127456665\n",
      "Batch 6124 - loss: 0.5078829526901245\n",
      "Batch 6125 - loss: 0.5245044827461243\n",
      "Batch 6126 - loss: 0.4931257367134094\n",
      "Batch 6127 - loss: 0.5559326410293579\n",
      "Batch 6128 - loss: 0.5038935542106628\n",
      "Batch 6129 - loss: 0.5171487331390381\n",
      "Batch 6130 - loss: 0.4684855043888092\n",
      "Batch 6131 - loss: 0.5553432106971741\n",
      "Batch 6132 - loss: 0.5142117142677307\n",
      "Batch 6133 - loss: 0.48117440938949585\n",
      "Batch 6134 - loss: 0.4982748031616211\n",
      "Batch 6135 - loss: 0.4979005455970764\n",
      "Batch 6136 - loss: 0.5163714289665222\n",
      "Batch 6137 - loss: 0.5739763975143433\n",
      "Batch 6138 - loss: 0.5450226068496704\n",
      "Batch 6139 - loss: 0.49102869629859924\n",
      "Batch 6140 - loss: 0.5673589706420898\n",
      "Batch 6141 - loss: 0.45345446467399597\n",
      "Batch 6142 - loss: 0.6555266976356506\n",
      "Batch 6143 - loss: 0.5316535234451294\n",
      "Batch 6144 - loss: 0.4725029170513153\n",
      "Batch 6145 - loss: 0.5584759712219238\n",
      "Batch 6146 - loss: 0.5082916617393494\n",
      "Batch 6147 - loss: 0.5025600790977478\n",
      "Batch 6148 - loss: 0.5484883189201355\n",
      "Batch 6149 - loss: 0.4715716540813446\n",
      "Batch 6150 - loss: 0.5631154179573059\n",
      "Batch 6151 - loss: 0.4986879229545593\n",
      "Batch 6152 - loss: 0.5501207709312439\n",
      "Batch 6153 - loss: 0.4951779246330261\n",
      "Batch 6154 - loss: 0.5629772543907166\n",
      "Batch 6155 - loss: 0.5439145565032959\n",
      "Batch 6156 - loss: 0.5381540656089783\n",
      "Batch 6157 - loss: 0.52336585521698\n",
      "Batch 6158 - loss: 0.5505985021591187\n",
      "Batch 6159 - loss: 0.5765988826751709\n",
      "Batch 6160 - loss: 0.5130336284637451\n",
      "Batch 6161 - loss: 0.5192131996154785\n",
      "Batch 6162 - loss: 0.4934479594230652\n",
      "Batch 6163 - loss: 0.5305247902870178\n",
      "Batch 6164 - loss: 0.5311299562454224\n",
      "Batch 6165 - loss: 0.5099793672561646\n",
      "Batch 6166 - loss: 0.5604469180107117\n",
      "Batch 6167 - loss: 0.5568397641181946\n",
      "Batch 6168 - loss: 0.5561515688896179\n",
      "Batch 6169 - loss: 0.4816252291202545\n",
      "Batch 6170 - loss: 0.5564596652984619\n",
      "Batch 6171 - loss: 0.5158642530441284\n",
      "Batch 6172 - loss: 0.4843169152736664\n",
      "Batch 6173 - loss: 0.5050699710845947\n",
      "Batch 6174 - loss: 0.5188990235328674\n",
      "Batch 6175 - loss: 0.4838661551475525\n",
      "Batch 6176 - loss: 0.5457475185394287\n",
      "Batch 6177 - loss: 0.606033444404602\n",
      "Batch 6178 - loss: 0.584952175617218\n",
      "Batch 6179 - loss: 0.468921959400177\n",
      "Batch 6180 - loss: 0.49956974387168884\n",
      "Batch 6181 - loss: 0.5422676801681519\n",
      "Batch 6182 - loss: 0.4896533191204071\n",
      "Batch 6183 - loss: 0.5920153260231018\n",
      "Batch 6184 - loss: 0.4582662582397461\n",
      "Batch 6185 - loss: 0.547965943813324\n",
      "Batch 6186 - loss: 0.7400931715965271\n",
      "Batch 6187 - loss: 0.539143979549408\n",
      "Batch 6188 - loss: 0.5152088403701782\n",
      "Batch 6189 - loss: 0.5232402086257935\n",
      "Batch 6190 - loss: 0.5371259450912476\n",
      "Batch 6191 - loss: 0.5232758522033691\n",
      "Batch 6192 - loss: 0.5719795823097229\n",
      "Batch 6193 - loss: 0.5499925017356873\n",
      "Batch 6194 - loss: 0.49756312370300293\n",
      "Batch 6195 - loss: 0.4864279329776764\n",
      "Batch 6196 - loss: 0.49575668573379517\n",
      "Batch 6197 - loss: 0.5440917015075684\n",
      "Batch 6198 - loss: 0.58257657289505\n",
      "Batch 6199 - loss: 0.5315572619438171\n",
      "Batch 6200 - loss: 0.5075843334197998\n",
      "Batch 6201 - loss: 0.5247599482536316\n",
      "Batch 6202 - loss: 0.5372422337532043\n",
      "Batch 6203 - loss: 0.49310800433158875\n",
      "Batch 6204 - loss: 0.47632160782814026\n",
      "Batch 6205 - loss: 0.5793040990829468\n",
      "Batch 6206 - loss: 0.4903629422187805\n",
      "Batch 6207 - loss: 0.5013515949249268\n",
      "Batch 6208 - loss: 0.5017515420913696\n",
      "Batch 6209 - loss: 0.512627363204956\n",
      "Batch 6210 - loss: 0.46393057703971863\n",
      "Batch 6211 - loss: 0.5179434418678284\n",
      "Batch 6212 - loss: 0.4988301694393158\n",
      "Batch 6213 - loss: 0.5016711950302124\n",
      "Batch 6214 - loss: 0.5042579174041748\n",
      "Batch 6215 - loss: 0.5164995789527893\n",
      "Batch 6216 - loss: 0.5086287260055542\n",
      "Batch 6217 - loss: 0.5079944133758545\n",
      "Batch 6218 - loss: 0.5943744778633118\n",
      "Batch 6219 - loss: 0.5543787479400635\n",
      "Batch 6220 - loss: 0.45583200454711914\n",
      "Batch 6221 - loss: 0.5301805138587952\n",
      "Batch 6222 - loss: 0.5048733353614807\n",
      "Batch 6223 - loss: 0.5074269771575928\n",
      "Batch 6224 - loss: 0.5077307224273682\n",
      "Batch 6225 - loss: 0.5044283866882324\n",
      "Batch 6226 - loss: 0.48156028985977173\n",
      "Batch 6227 - loss: 0.47611114382743835\n",
      "Batch 6228 - loss: 0.5208615064620972\n",
      "Batch 6229 - loss: 0.5538374185562134\n",
      "Batch 6230 - loss: 0.579570472240448\n",
      "Batch 6231 - loss: 0.5154691934585571\n",
      "Batch 6232 - loss: 0.5116098523139954\n",
      "Batch 6233 - loss: 0.5249056816101074\n",
      "Batch 6234 - loss: 0.49862462282180786\n",
      "Batch 6235 - loss: 0.5405397415161133\n",
      "Batch 6236 - loss: 0.49648699164390564\n",
      "Batch 6237 - loss: 0.49802708625793457\n",
      "Batch 6238 - loss: 0.5124889612197876\n",
      "Batch 6239 - loss: 0.5176575779914856\n",
      "Batch 6240 - loss: 0.5725228190422058\n",
      "Batch 6241 - loss: 0.6007107496261597\n",
      "Batch 6242 - loss: 0.4712945520877838\n",
      "Batch 6243 - loss: 0.5593101978302002\n",
      "Batch 6244 - loss: 0.5568599104881287\n",
      "Batch 6245 - loss: 0.5405223965644836\n",
      "Batch 6246 - loss: 0.5377856492996216\n",
      "Batch 6247 - loss: 0.4857011139392853\n",
      "Batch 6248 - loss: 0.496538907289505\n",
      "Batch 6249 - loss: 0.47963622212409973\n",
      "Batch 6250 - loss: 0.5657990574836731\n",
      "Batch 6251 - loss: 0.4832909107208252\n",
      "Batch 6252 - loss: 0.5162448287010193\n",
      "Batch 6253 - loss: 0.5266780853271484\n",
      "Batch 6254 - loss: 0.5699297785758972\n",
      "Batch 6255 - loss: 0.608856737613678\n",
      "Batch 6256 - loss: 0.5389038324356079\n",
      "Batch 6257 - loss: 0.4663824737071991\n",
      "Batch 6258 - loss: 0.4883275330066681\n",
      "Batch 6259 - loss: 0.5412566065788269\n",
      "Batch 6260 - loss: 0.5100229382514954\n",
      "Batch 6261 - loss: 0.5021834969520569\n",
      "Batch 6262 - loss: 0.5259022116661072\n",
      "Batch 6263 - loss: 0.5158031582832336\n",
      "Batch 6264 - loss: 0.4688577950000763\n",
      "Batch 6265 - loss: 0.46580421924591064\n",
      "Batch 6266 - loss: 0.53171306848526\n",
      "Batch 6267 - loss: 0.5503573417663574\n",
      "Batch 6268 - loss: 0.5406304597854614\n",
      "Batch 6269 - loss: 0.5482193827629089\n",
      "Batch 6270 - loss: 0.5267071723937988\n",
      "Batch 6271 - loss: 0.5645235180854797\n",
      "Batch 6272 - loss: 0.5027163028717041\n",
      "Batch 6273 - loss: 0.5273833870887756\n",
      "Batch 6274 - loss: 0.5005340576171875\n",
      "Batch 6275 - loss: 0.5234265923500061\n",
      "Batch 6276 - loss: 0.5275400876998901\n",
      "Batch 6277 - loss: 0.5234429240226746\n",
      "Batch 6278 - loss: 0.5283248424530029\n",
      "Batch 6279 - loss: 0.5113850235939026\n",
      "Batch 6280 - loss: 0.5397461652755737\n",
      "Batch 6281 - loss: 0.5348159074783325\n",
      "Batch 6282 - loss: 0.5468199849128723\n",
      "Batch 6283 - loss: 0.547776997089386\n",
      "Batch 6284 - loss: 0.5066971182823181\n",
      "Batch 6285 - loss: 0.4740524888038635\n",
      "Batch 6286 - loss: 0.5595433115959167\n",
      "Batch 6287 - loss: 0.4884147644042969\n",
      "Batch 6288 - loss: 0.5141265988349915\n",
      "Batch 6289 - loss: 0.5445089936256409\n",
      "Batch 6290 - loss: 0.5296669602394104\n",
      "Batch 6291 - loss: 0.5934082865715027\n",
      "Batch 6292 - loss: 0.5520386695861816\n",
      "Batch 6293 - loss: 0.48120275139808655\n",
      "Batch 6294 - loss: 0.507877767086029\n",
      "Batch 6295 - loss: 0.5078749656677246\n",
      "Batch 6296 - loss: 0.5495725274085999\n",
      "Batch 6297 - loss: 0.521557629108429\n",
      "Batch 6298 - loss: 0.4928610622882843\n",
      "Batch 6299 - loss: 0.5032328367233276\n",
      "Batch 6300 - loss: 0.5360512733459473\n",
      "Batch 6301 - loss: 0.5268621444702148\n",
      "Batch 6302 - loss: 0.511641800403595\n",
      "Batch 6303 - loss: 0.527365505695343\n",
      "Batch 6304 - loss: 0.5585541725158691\n",
      "Batch 6305 - loss: 0.5752647519111633\n",
      "Batch 6306 - loss: 0.5124495029449463\n",
      "Batch 6307 - loss: 0.5051165223121643\n",
      "Batch 6308 - loss: 0.5144920349121094\n",
      "Batch 6309 - loss: 0.5086396932601929\n",
      "Batch 6310 - loss: 0.5208231210708618\n",
      "Batch 6311 - loss: 0.49810129404067993\n",
      "Batch 6312 - loss: 0.49893391132354736\n",
      "Batch 6313 - loss: 0.4985818564891815\n",
      "Batch 6314 - loss: 0.6202185750007629\n",
      "Batch 6315 - loss: 0.5369203686714172\n",
      "Batch 6316 - loss: 0.5009065866470337\n",
      "Batch 6317 - loss: 0.5568143129348755\n",
      "Batch 6318 - loss: 0.5258961915969849\n",
      "Batch 6319 - loss: 0.5176143050193787\n",
      "Batch 6320 - loss: 0.45816370844841003\n",
      "Batch 6321 - loss: 0.5699267983436584\n",
      "Batch 6322 - loss: 0.4509016275405884\n",
      "Batch 6323 - loss: 0.4526312053203583\n",
      "Batch 6324 - loss: 0.4737965166568756\n",
      "Batch 6325 - loss: 0.5045905709266663\n",
      "Batch 6326 - loss: 0.46312761306762695\n",
      "Batch 6327 - loss: 0.5313218235969543\n",
      "Batch 6328 - loss: 0.47006955742836\n",
      "Batch 6329 - loss: 0.5032720565795898\n",
      "Batch 6330 - loss: 0.4692032039165497\n",
      "Batch 6331 - loss: 0.4495532810688019\n",
      "Batch 6332 - loss: 0.5406510829925537\n",
      "Batch 6333 - loss: 0.5312409400939941\n",
      "Batch 6334 - loss: 0.5027864575386047\n",
      "Batch 6335 - loss: 0.5642457008361816\n",
      "Batch 6336 - loss: 0.5192705392837524\n",
      "Batch 6337 - loss: 0.4833281636238098\n",
      "Batch 6338 - loss: 0.512482225894928\n",
      "Batch 6339 - loss: 0.4697672426700592\n",
      "Batch 6340 - loss: 0.45679715275764465\n",
      "Batch 6341 - loss: 0.5196467041969299\n",
      "Batch 6342 - loss: 0.519136369228363\n",
      "Batch 6343 - loss: 0.5428402423858643\n",
      "Batch 6344 - loss: 0.5790284872055054\n",
      "Batch 6345 - loss: 0.5437427759170532\n",
      "Batch 6346 - loss: 0.5239405632019043\n",
      "Batch 6347 - loss: 0.5340169072151184\n",
      "Batch 6348 - loss: 0.5579745173454285\n",
      "Batch 6349 - loss: 0.5174063444137573\n",
      "Batch 6350 - loss: 0.49703794717788696\n",
      "Batch 6351 - loss: 0.567797839641571\n",
      "Batch 6352 - loss: 0.49814772605895996\n",
      "Batch 6353 - loss: 0.5561283230781555\n",
      "Batch 6354 - loss: 0.5024940967559814\n",
      "Batch 6355 - loss: 0.47361117601394653\n",
      "Batch 6356 - loss: 0.46874508261680603\n",
      "Batch 6357 - loss: 0.5573647022247314\n",
      "Batch 6358 - loss: 0.5429562330245972\n",
      "Batch 6359 - loss: 0.4601612389087677\n",
      "Batch 6360 - loss: 0.5059394836425781\n",
      "Batch 6361 - loss: 0.4918561279773712\n",
      "Batch 6362 - loss: 0.4926624596118927\n",
      "Batch 6363 - loss: 0.5069462656974792\n",
      "Batch 6364 - loss: 0.5256516933441162\n",
      "Batch 6365 - loss: 0.5120107531547546\n",
      "Batch 6366 - loss: 0.46621060371398926\n",
      "Batch 6367 - loss: 0.5030983090400696\n",
      "Batch 6368 - loss: 0.5090266466140747\n",
      "Batch 6369 - loss: 0.46766984462738037\n",
      "Batch 6370 - loss: 0.5238547325134277\n",
      "Batch 6371 - loss: 0.5413799285888672\n",
      "Batch 6372 - loss: 0.4728028178215027\n",
      "Batch 6373 - loss: 0.5774779319763184\n",
      "Batch 6374 - loss: 0.48645174503326416\n",
      "Batch 6375 - loss: 0.5316729545593262\n",
      "Batch 6376 - loss: 0.5669263601303101\n",
      "Batch 6377 - loss: 0.4822891056537628\n",
      "Batch 6378 - loss: 0.5336523652076721\n",
      "Batch 6379 - loss: 0.4921819269657135\n",
      "Batch 6380 - loss: 0.5212370157241821\n",
      "Batch 6381 - loss: 0.564034104347229\n",
      "Batch 6382 - loss: 0.5405825972557068\n",
      "Batch 6383 - loss: 0.5553479194641113\n",
      "Batch 6384 - loss: 0.5350114107131958\n",
      "Batch 6385 - loss: 0.5729775428771973\n",
      "Batch 6386 - loss: 0.5191959738731384\n",
      "Batch 6387 - loss: 0.4827876389026642\n",
      "Batch 6388 - loss: 0.4465106725692749\n",
      "Batch 6389 - loss: 0.5167081952095032\n",
      "Batch 6390 - loss: 0.5506276488304138\n",
      "Batch 6391 - loss: 0.4697740375995636\n",
      "Batch 6392 - loss: 0.5475311875343323\n",
      "Batch 6393 - loss: 0.5040056705474854\n",
      "Batch 6394 - loss: 0.5168865323066711\n",
      "Batch 6395 - loss: 0.5023829936981201\n",
      "Batch 6396 - loss: 0.5789315700531006\n",
      "Batch 6397 - loss: 0.5042100548744202\n",
      "Batch 6398 - loss: 0.49483588337898254\n",
      "Batch 6399 - loss: 0.5049580931663513\n",
      "Batch 6400 - loss: 0.5532440543174744\n",
      "Batch 6401 - loss: 0.5137584209442139\n",
      "Batch 6402 - loss: 0.5098702907562256\n",
      "Batch 6403 - loss: 0.4951353073120117\n",
      "Batch 6404 - loss: 0.5277047753334045\n",
      "Batch 6405 - loss: 0.4548467993736267\n",
      "Batch 6406 - loss: 0.5768246054649353\n",
      "Batch 6407 - loss: 0.5570032596588135\n",
      "Batch 6408 - loss: 0.5031128525733948\n",
      "Batch 6409 - loss: 0.4926195740699768\n",
      "Batch 6410 - loss: 0.49480608105659485\n",
      "Batch 6411 - loss: 0.48472511768341064\n",
      "Batch 6412 - loss: 0.4381214380264282\n",
      "Batch 6413 - loss: 0.5612614750862122\n",
      "Batch 6414 - loss: 0.5232865810394287\n",
      "Batch 6415 - loss: 0.5874952077865601\n",
      "Batch 6416 - loss: 0.5348573327064514\n",
      "Batch 6417 - loss: 0.543653130531311\n",
      "Batch 6418 - loss: 0.5625425577163696\n",
      "Batch 6419 - loss: 0.5097982883453369\n",
      "Batch 6420 - loss: 0.4721071422100067\n",
      "Batch 6421 - loss: 0.5100196003913879\n",
      "Batch 6422 - loss: 0.5119238495826721\n",
      "Batch 6423 - loss: 0.517671525478363\n",
      "Batch 6424 - loss: 0.4984065294265747\n",
      "Batch 6425 - loss: 0.48759159445762634\n",
      "Batch 6426 - loss: 0.5438599586486816\n",
      "Batch 6427 - loss: 0.5646905899047852\n",
      "Batch 6428 - loss: 0.5092241764068604\n",
      "Batch 6429 - loss: 0.5481849312782288\n",
      "Batch 6430 - loss: 0.5399800539016724\n",
      "Batch 6431 - loss: 0.5216683149337769\n",
      "Batch 6432 - loss: 0.5000113844871521\n",
      "Batch 6433 - loss: 0.5152754783630371\n",
      "Batch 6434 - loss: 0.4594135880470276\n",
      "Batch 6435 - loss: 0.5598242878913879\n",
      "Batch 6436 - loss: 0.48577743768692017\n",
      "Batch 6437 - loss: 0.49425575137138367\n",
      "Batch 6438 - loss: 0.5236057043075562\n",
      "Batch 6439 - loss: 0.46296483278274536\n",
      "Batch 6440 - loss: 0.5352827310562134\n",
      "Batch 6441 - loss: 0.5662339329719543\n",
      "Batch 6442 - loss: 0.5597274303436279\n",
      "Batch 6443 - loss: 0.5281721353530884\n",
      "Batch 6444 - loss: 0.4912474453449249\n",
      "Batch 6445 - loss: 0.5497229695320129\n",
      "Batch 6446 - loss: 0.5104262232780457\n",
      "Batch 6447 - loss: 0.4772374629974365\n",
      "Batch 6448 - loss: 0.483584463596344\n",
      "Batch 6449 - loss: 0.5022401213645935\n",
      "Batch 6450 - loss: 0.4618883728981018\n",
      "Batch 6451 - loss: 0.5389080047607422\n",
      "Batch 6452 - loss: 0.5213570594787598\n",
      "Batch 6453 - loss: 0.5099788904190063\n",
      "Batch 6454 - loss: 0.4598029851913452\n",
      "Batch 6455 - loss: 0.5139132142066956\n",
      "Batch 6456 - loss: 0.5151631832122803\n",
      "Batch 6457 - loss: 0.5296709537506104\n",
      "Batch 6458 - loss: 0.5392902493476868\n",
      "Batch 6459 - loss: 0.503609299659729\n",
      "Batch 6460 - loss: 0.527178168296814\n",
      "Batch 6461 - loss: 0.5114981532096863\n",
      "Batch 6462 - loss: 0.5634187459945679\n",
      "Batch 6463 - loss: 0.5366753935813904\n",
      "Batch 6464 - loss: 0.5625129342079163\n",
      "Batch 6465 - loss: 0.5519773364067078\n",
      "Batch 6466 - loss: 0.5099596381187439\n",
      "Batch 6467 - loss: 0.5210088491439819\n",
      "Batch 6468 - loss: 0.543065071105957\n",
      "Batch 6469 - loss: 0.47947371006011963\n",
      "Batch 6470 - loss: 0.4816056489944458\n",
      "Batch 6471 - loss: 0.5076418519020081\n",
      "Batch 6472 - loss: 0.5210091471672058\n",
      "Batch 6473 - loss: 0.46887362003326416\n",
      "Batch 6474 - loss: 0.5379816293716431\n",
      "Batch 6475 - loss: 0.5411526560783386\n",
      "Batch 6476 - loss: 0.4475013017654419\n",
      "Batch 6477 - loss: 0.449065625667572\n",
      "Batch 6478 - loss: 0.49358808994293213\n",
      "Batch 6479 - loss: 0.4787316918373108\n",
      "Batch 6480 - loss: 0.48930197954177856\n",
      "Batch 6481 - loss: 0.5864852666854858\n",
      "Batch 6482 - loss: 0.5439092516899109\n",
      "Batch 6483 - loss: 0.4749361574649811\n",
      "Batch 6484 - loss: 0.48055875301361084\n",
      "Batch 6485 - loss: 0.538799524307251\n",
      "Batch 6486 - loss: 0.5303329229354858\n",
      "Batch 6487 - loss: 0.5649256706237793\n",
      "Batch 6488 - loss: 0.4290350079536438\n",
      "Batch 6489 - loss: 0.49575695395469666\n",
      "Batch 6490 - loss: 0.477101594209671\n",
      "Batch 6491 - loss: 0.5193307399749756\n",
      "Batch 6492 - loss: 0.5481067299842834\n",
      "Batch 6493 - loss: 0.5329253077507019\n",
      "Batch 6494 - loss: 0.5956161022186279\n",
      "Batch 6495 - loss: 0.5162689089775085\n",
      "Batch 6496 - loss: 0.4935894012451172\n",
      "Batch 6497 - loss: 0.5326263904571533\n",
      "Batch 6498 - loss: 0.5706377625465393\n",
      "Batch 6499 - loss: 0.48063814640045166\n",
      "Batch 6500 - loss: 0.5229213237762451\n",
      "Batch 6501 - loss: 0.5056992173194885\n",
      "Batch 6502 - loss: 0.4781957268714905\n",
      "Batch 6503 - loss: 0.5667084455490112\n",
      "Batch 6504 - loss: 0.5508522987365723\n",
      "Batch 6505 - loss: 0.5461947321891785\n",
      "Batch 6506 - loss: 0.45105502009391785\n",
      "Batch 6507 - loss: 0.5389554500579834\n",
      "Batch 6508 - loss: 0.5246751308441162\n",
      "Batch 6509 - loss: 0.5706632733345032\n",
      "Batch 6510 - loss: 0.4976951777935028\n",
      "Batch 6511 - loss: 0.5026890635490417\n",
      "Batch 6512 - loss: 0.4645293354988098\n",
      "Batch 6513 - loss: 0.5538114905357361\n",
      "Batch 6514 - loss: 0.5073713660240173\n",
      "Batch 6515 - loss: 0.5710723400115967\n",
      "Batch 6516 - loss: 0.5501691699028015\n",
      "Batch 6517 - loss: 0.5490466952323914\n",
      "Batch 6518 - loss: 0.4992895722389221\n",
      "Batch 6519 - loss: 0.47899773716926575\n",
      "Batch 6520 - loss: 0.5073086023330688\n",
      "Batch 6521 - loss: 0.4815186858177185\n",
      "Batch 6522 - loss: 0.48715710639953613\n",
      "Batch 6523 - loss: 0.5392317175865173\n",
      "Batch 6524 - loss: 0.538377583026886\n",
      "Batch 6525 - loss: 0.5557489991188049\n",
      "Batch 6526 - loss: 0.487957626581192\n",
      "Batch 6527 - loss: 0.5232885479927063\n",
      "Batch 6528 - loss: 0.5406520962715149\n",
      "Batch 6529 - loss: 0.5115329623222351\n",
      "Batch 6530 - loss: 0.5001434683799744\n",
      "Batch 6531 - loss: 0.5640622973442078\n",
      "Batch 6532 - loss: 0.5661530494689941\n",
      "Batch 6533 - loss: 0.5049006342887878\n",
      "Batch 6534 - loss: 0.5540236830711365\n",
      "Batch 6535 - loss: 0.5384957790374756\n",
      "Batch 6536 - loss: 0.5726447105407715\n",
      "Batch 6537 - loss: 0.56694495677948\n",
      "Batch 6538 - loss: 0.5326597094535828\n",
      "Batch 6539 - loss: 0.5777217745780945\n",
      "Batch 6540 - loss: 0.5159055590629578\n",
      "Batch 6541 - loss: 0.5731914043426514\n",
      "Batch 6542 - loss: 0.5708267688751221\n",
      "Batch 6543 - loss: 0.5037428736686707\n",
      "Batch 6544 - loss: 0.5435378551483154\n",
      "Batch 6545 - loss: 0.5459867119789124\n",
      "Batch 6546 - loss: 0.5265129804611206\n",
      "Batch 6547 - loss: 0.4337954521179199\n",
      "Batch 6548 - loss: 0.5779295563697815\n",
      "Batch 6549 - loss: 0.5460309982299805\n",
      "Batch 6550 - loss: 0.4863952100276947\n",
      "Batch 6551 - loss: 0.5190870761871338\n",
      "Batch 6552 - loss: 0.4622076749801636\n",
      "Batch 6553 - loss: 0.4818207323551178\n",
      "Batch 6554 - loss: 0.5190050601959229\n",
      "Batch 6555 - loss: 0.5046001076698303\n",
      "Batch 6556 - loss: 0.4781554341316223\n",
      "Batch 6557 - loss: 0.4760113060474396\n",
      "Batch 6558 - loss: 0.4985693693161011\n",
      "Batch 6559 - loss: 0.5009593367576599\n",
      "Batch 6560 - loss: 0.46349242329597473\n",
      "Batch 6561 - loss: 0.5383370518684387\n",
      "Batch 6562 - loss: 0.541197657585144\n",
      "Batch 6563 - loss: 0.5298247337341309\n",
      "Batch 6564 - loss: 0.4809017777442932\n",
      "Batch 6565 - loss: 0.4935905933380127\n",
      "Batch 6566 - loss: 0.5501351952552795\n",
      "Batch 6567 - loss: 0.5274245738983154\n",
      "Batch 6568 - loss: 0.5470535755157471\n",
      "Batch 6569 - loss: 0.5003857016563416\n",
      "Batch 6570 - loss: 0.49223604798316956\n",
      "Batch 6571 - loss: 0.573185384273529\n",
      "Batch 6572 - loss: 0.5720837116241455\n",
      "Batch 6573 - loss: 0.4973036050796509\n",
      "Batch 6574 - loss: 0.6300380825996399\n",
      "Batch 6575 - loss: 0.5639512538909912\n",
      "Batch 6576 - loss: 0.48366573452949524\n",
      "Batch 6577 - loss: 0.4643417000770569\n",
      "Batch 6578 - loss: 0.5333393812179565\n",
      "Batch 6579 - loss: 0.5445142388343811\n",
      "Batch 6580 - loss: 0.524676501750946\n",
      "Batch 6581 - loss: 0.5061326622962952\n",
      "Batch 6582 - loss: 0.5096831321716309\n",
      "Batch 6583 - loss: 0.5092207193374634\n",
      "Batch 6584 - loss: 0.6000093817710876\n",
      "Batch 6585 - loss: 0.5108951330184937\n",
      "Batch 6586 - loss: 0.4770553708076477\n",
      "Batch 6587 - loss: 0.49838751554489136\n",
      "Batch 6588 - loss: 0.5610020160675049\n",
      "Batch 6589 - loss: 0.5400519371032715\n",
      "Batch 6590 - loss: 0.5228203535079956\n",
      "Batch 6591 - loss: 0.4996333718299866\n",
      "Batch 6592 - loss: 0.4918980896472931\n",
      "Batch 6593 - loss: 0.5570282340049744\n",
      "Batch 6594 - loss: 0.5316624045372009\n",
      "Batch 6595 - loss: 0.47360923886299133\n",
      "Batch 6596 - loss: 0.5267490148544312\n",
      "Batch 6597 - loss: 0.5088344812393188\n",
      "Batch 6598 - loss: 0.5057232975959778\n",
      "Batch 6599 - loss: 0.5058135390281677\n",
      "Batch 6600 - loss: 0.6052049994468689\n",
      "Batch 6601 - loss: 0.5269591808319092\n",
      "Batch 6602 - loss: 0.477900892496109\n",
      "Batch 6603 - loss: 0.5712061524391174\n",
      "Batch 6604 - loss: 0.5644117593765259\n",
      "Batch 6605 - loss: 0.4781751334667206\n",
      "Batch 6606 - loss: 0.5313885807991028\n",
      "Batch 6607 - loss: 0.5477014780044556\n",
      "Batch 6608 - loss: 0.53041672706604\n",
      "Batch 6609 - loss: 0.5125107169151306\n",
      "Batch 6610 - loss: 0.48225176334381104\n",
      "Batch 6611 - loss: 0.5339609980583191\n",
      "Batch 6612 - loss: 0.49126100540161133\n",
      "Batch 6613 - loss: 0.4589162766933441\n",
      "Batch 6614 - loss: 0.5043023228645325\n",
      "Batch 6615 - loss: 0.5141094923019409\n",
      "Batch 6616 - loss: 0.48531651496887207\n",
      "Batch 6617 - loss: 0.5545743107795715\n",
      "Batch 6618 - loss: 0.5016488432884216\n",
      "Batch 6619 - loss: 0.5221300721168518\n",
      "Batch 6620 - loss: 0.5323547124862671\n",
      "Batch 6621 - loss: 0.5646364688873291\n",
      "Batch 6622 - loss: 0.5232272148132324\n",
      "Batch 6623 - loss: 0.4860144555568695\n",
      "Batch 6624 - loss: 0.513486921787262\n",
      "Batch 6625 - loss: 0.540848970413208\n",
      "Batch 6626 - loss: 0.4493502080440521\n",
      "Batch 6627 - loss: 0.5105459094047546\n",
      "Batch 6628 - loss: 0.5217289328575134\n",
      "Batch 6629 - loss: 0.4966179132461548\n",
      "Batch 6630 - loss: 0.45082250237464905\n",
      "Batch 6631 - loss: 0.4528389871120453\n",
      "Batch 6632 - loss: 0.49781763553619385\n",
      "Batch 6633 - loss: 0.6059151887893677\n",
      "Batch 6634 - loss: 0.4673292338848114\n",
      "Batch 6635 - loss: 0.5337967872619629\n",
      "Batch 6636 - loss: 0.4479709267616272\n",
      "Batch 6637 - loss: 0.5192182660102844\n",
      "Batch 6638 - loss: 0.5450927019119263\n",
      "Batch 6639 - loss: 0.5349943041801453\n",
      "Batch 6640 - loss: 0.4761921763420105\n",
      "Batch 6641 - loss: 0.48929598927497864\n",
      "Batch 6642 - loss: 0.4978024959564209\n",
      "Batch 6643 - loss: 0.5000184178352356\n",
      "Batch 6644 - loss: 0.5208349227905273\n",
      "Batch 6645 - loss: 0.5537844300270081\n",
      "Batch 6646 - loss: 0.5581501722335815\n",
      "Batch 6647 - loss: 0.48807185888290405\n",
      "Batch 6648 - loss: 0.5158540606498718\n",
      "Batch 6649 - loss: 0.4569416046142578\n",
      "Batch 6650 - loss: 0.4975872039794922\n",
      "Batch 6651 - loss: 0.48321375250816345\n",
      "Batch 6652 - loss: 0.5007891654968262\n",
      "Batch 6653 - loss: 0.5225940942764282\n",
      "Batch 6654 - loss: 0.536095380783081\n",
      "Batch 6655 - loss: 0.4527069330215454\n",
      "Batch 6656 - loss: 0.5054820775985718\n",
      "Batch 6657 - loss: 0.507509171962738\n",
      "Batch 6658 - loss: 0.48207923769950867\n",
      "Batch 6659 - loss: 0.520672082901001\n",
      "Batch 6660 - loss: 0.4499645531177521\n",
      "Batch 6661 - loss: 0.5152136087417603\n",
      "Batch 6662 - loss: 0.4751622676849365\n",
      "Batch 6663 - loss: 0.49851152300834656\n",
      "Batch 6664 - loss: 0.539060115814209\n",
      "Batch 6665 - loss: 0.49288409948349\n",
      "Batch 6666 - loss: 0.5024961233139038\n",
      "Batch 6667 - loss: 0.51728355884552\n",
      "Batch 6668 - loss: 0.5150176286697388\n",
      "Batch 6669 - loss: 0.5050469040870667\n",
      "Batch 6670 - loss: 0.5376519560813904\n",
      "Batch 6671 - loss: 0.5077637434005737\n",
      "Batch 6672 - loss: 0.5735152959823608\n",
      "Batch 6673 - loss: 0.5070526003837585\n",
      "Batch 6674 - loss: 0.49971237778663635\n",
      "Batch 6675 - loss: 0.523932158946991\n",
      "Batch 6676 - loss: 0.4551081955432892\n",
      "Batch 6677 - loss: 0.49056297540664673\n",
      "Batch 6678 - loss: 0.5019427537918091\n",
      "Batch 6679 - loss: 0.4970504939556122\n",
      "Batch 6680 - loss: 0.4800131916999817\n",
      "Batch 6681 - loss: 0.5259665250778198\n",
      "Batch 6682 - loss: 0.5083948969841003\n",
      "Batch 6683 - loss: 0.5481049418449402\n",
      "Batch 6684 - loss: 0.5529987812042236\n",
      "Batch 6685 - loss: 0.5553289651870728\n",
      "Batch 6686 - loss: 0.5683284997940063\n",
      "Batch 6687 - loss: 0.578887939453125\n",
      "Batch 6688 - loss: 0.44318947196006775\n",
      "Batch 6689 - loss: 0.47621557116508484\n",
      "Batch 6690 - loss: 0.47916144132614136\n",
      "Batch 6691 - loss: 0.5476273894309998\n",
      "Batch 6692 - loss: 0.4902666211128235\n",
      "Batch 6693 - loss: 0.546740710735321\n",
      "Batch 6694 - loss: 0.47922009229660034\n",
      "Batch 6695 - loss: 0.5331520438194275\n",
      "Batch 6696 - loss: 0.5059986710548401\n",
      "Batch 6697 - loss: 0.5030225515365601\n",
      "Batch 6698 - loss: 0.5176488757133484\n",
      "Batch 6699 - loss: 0.4894697070121765\n",
      "Batch 6700 - loss: 0.5101763606071472\n",
      "Batch 6701 - loss: 0.4757750630378723\n",
      "Batch 6702 - loss: 0.5326721668243408\n",
      "Batch 6703 - loss: 0.5387855172157288\n",
      "Batch 6704 - loss: 0.5220481753349304\n",
      "Batch 6705 - loss: 0.5014392137527466\n",
      "Batch 6706 - loss: 0.46262267231941223\n",
      "Batch 6707 - loss: 0.4584690034389496\n",
      "Batch 6708 - loss: 0.5031717419624329\n",
      "Batch 6709 - loss: 0.5380013585090637\n",
      "Batch 6710 - loss: 0.5320284962654114\n",
      "Batch 6711 - loss: 0.49244293570518494\n",
      "Batch 6712 - loss: 0.547966480255127\n",
      "Batch 6713 - loss: 0.5308729410171509\n",
      "Batch 6714 - loss: 0.5289471745491028\n",
      "Batch 6715 - loss: 0.4744718074798584\n",
      "Batch 6716 - loss: 0.5047904849052429\n",
      "Batch 6717 - loss: 0.5006456971168518\n",
      "Batch 6718 - loss: 0.5302892327308655\n",
      "Batch 6719 - loss: 0.49379345774650574\n",
      "Batch 6720 - loss: 0.4966028332710266\n",
      "Batch 6721 - loss: 0.5155255794525146\n",
      "Batch 6722 - loss: 0.6094849705696106\n",
      "Batch 6723 - loss: 0.48406919836997986\n",
      "Batch 6724 - loss: 0.4933275282382965\n",
      "Batch 6725 - loss: 0.5389041900634766\n",
      "Batch 6726 - loss: 0.47614842653274536\n",
      "Batch 6727 - loss: 0.5425719022750854\n",
      "Batch 6728 - loss: 0.4323703348636627\n",
      "Batch 6729 - loss: 0.5212473273277283\n",
      "Batch 6730 - loss: 0.49623578786849976\n",
      "Batch 6731 - loss: 0.5495968461036682\n",
      "Batch 6732 - loss: 0.5577924251556396\n",
      "Batch 6733 - loss: 0.5023956894874573\n",
      "Batch 6734 - loss: 0.5195867419242859\n",
      "Batch 6735 - loss: 0.500856876373291\n",
      "Batch 6736 - loss: 0.5482968091964722\n",
      "Batch 6737 - loss: 0.5010368824005127\n",
      "Batch 6738 - loss: 0.47764071822166443\n",
      "Batch 6739 - loss: 0.4757559895515442\n",
      "Batch 6740 - loss: 0.5654380917549133\n",
      "Batch 6741 - loss: 0.4826247990131378\n",
      "Batch 6742 - loss: 0.5208625197410583\n",
      "Batch 6743 - loss: 0.459937185049057\n",
      "Batch 6744 - loss: 0.5155006051063538\n",
      "Batch 6745 - loss: 0.6024565100669861\n",
      "Batch 6746 - loss: 0.48659762740135193\n",
      "Batch 6747 - loss: 0.4981420934200287\n",
      "Batch 6748 - loss: 0.5113046169281006\n",
      "Batch 6749 - loss: 0.45323389768600464\n",
      "Batch 6750 - loss: 0.4907582104206085\n",
      "Batch 6751 - loss: 0.5601031184196472\n",
      "Batch 6752 - loss: 0.5428076386451721\n",
      "Batch 6753 - loss: 0.54172682762146\n",
      "Batch 6754 - loss: 0.490200012922287\n",
      "Batch 6755 - loss: 0.5592845678329468\n",
      "Batch 6756 - loss: 0.5297200679779053\n",
      "Batch 6757 - loss: 0.5123245120048523\n",
      "Batch 6758 - loss: 0.5855591893196106\n",
      "Batch 6759 - loss: 0.501398503780365\n",
      "Batch 6760 - loss: 0.49016812443733215\n",
      "Batch 6761 - loss: 0.5008390545845032\n",
      "Batch 6762 - loss: 0.5071636438369751\n",
      "Batch 6763 - loss: 0.5333002209663391\n",
      "Batch 6764 - loss: 0.48013201355934143\n",
      "Batch 6765 - loss: 0.5156775712966919\n",
      "Batch 6766 - loss: 0.4971180856227875\n",
      "Batch 6767 - loss: 0.5539770722389221\n",
      "Batch 6768 - loss: 0.5097435116767883\n",
      "Batch 6769 - loss: 0.5147373676300049\n",
      "Batch 6770 - loss: 0.47124651074409485\n",
      "Batch 6771 - loss: 0.5047909021377563\n",
      "Batch 6772 - loss: 0.5272324681282043\n",
      "Batch 6773 - loss: 0.47367438673973083\n",
      "Batch 6774 - loss: 0.5104649662971497\n",
      "Batch 6775 - loss: 0.546266496181488\n",
      "Batch 6776 - loss: 0.48324739933013916\n",
      "Batch 6777 - loss: 0.5829293727874756\n",
      "Batch 6778 - loss: 0.5000647306442261\n",
      "Batch 6779 - loss: 0.5297437310218811\n",
      "Batch 6780 - loss: 0.42613133788108826\n",
      "Batch 6781 - loss: 0.5257658958435059\n",
      "Batch 6782 - loss: 0.5166702270507812\n",
      "Batch 6783 - loss: 0.5405601859092712\n",
      "Batch 6784 - loss: 0.48435887694358826\n",
      "Batch 6785 - loss: 0.5099345445632935\n",
      "Batch 6786 - loss: 0.5227727890014648\n",
      "Batch 6787 - loss: 0.5248723030090332\n",
      "Batch 6788 - loss: 0.45397448539733887\n",
      "Batch 6789 - loss: 0.5237475037574768\n",
      "Batch 6790 - loss: 0.4938221275806427\n",
      "Batch 6791 - loss: 0.5463283658027649\n",
      "Batch 6792 - loss: 0.5132869482040405\n",
      "Batch 6793 - loss: 0.5495253205299377\n",
      "Batch 6794 - loss: 0.6220415830612183\n",
      "Batch 6795 - loss: 0.5076426267623901\n",
      "Batch 6796 - loss: 0.516128420829773\n",
      "Batch 6797 - loss: 0.5097757577896118\n",
      "Batch 6798 - loss: 0.510799765586853\n",
      "Batch 6799 - loss: 0.4898736774921417\n",
      "Batch 6800 - loss: 0.4973541796207428\n",
      "Batch 6801 - loss: 0.4759804904460907\n",
      "Batch 6802 - loss: 0.4967896640300751\n",
      "Batch 6803 - loss: 0.5511443018913269\n",
      "Batch 6804 - loss: 0.5246765613555908\n",
      "Batch 6805 - loss: 0.4980325996875763\n",
      "Batch 6806 - loss: 0.5302709341049194\n",
      "Batch 6807 - loss: 0.4746462404727936\n",
      "Batch 6808 - loss: 0.4928589165210724\n",
      "Batch 6809 - loss: 0.5311171412467957\n",
      "Batch 6810 - loss: 0.5207521915435791\n",
      "Batch 6811 - loss: 0.5125570893287659\n",
      "Batch 6812 - loss: 0.5024316906929016\n",
      "Batch 6813 - loss: 0.5423306226730347\n",
      "Batch 6814 - loss: 0.5172758102416992\n",
      "Batch 6815 - loss: 0.4959784746170044\n",
      "Batch 6816 - loss: 0.4909246861934662\n",
      "Batch 6817 - loss: 0.4842570126056671\n",
      "Batch 6818 - loss: 0.5461816787719727\n",
      "Batch 6819 - loss: 0.5257325172424316\n",
      "Batch 6820 - loss: 0.518779993057251\n",
      "Batch 6821 - loss: 0.5667765140533447\n",
      "Batch 6822 - loss: 0.5555149912834167\n",
      "Batch 6823 - loss: 0.4493364095687866\n",
      "Batch 6824 - loss: 0.4324623942375183\n",
      "Batch 6825 - loss: 0.4854275584220886\n",
      "Batch 6826 - loss: 0.5122677087783813\n",
      "Batch 6827 - loss: 0.5411505103111267\n",
      "Batch 6828 - loss: 0.48815155029296875\n",
      "Batch 6829 - loss: 0.49618178606033325\n",
      "Batch 6830 - loss: 0.4675830602645874\n",
      "Batch 6831 - loss: 0.5080208778381348\n",
      "Batch 6832 - loss: 0.4913024604320526\n",
      "Batch 6833 - loss: 0.49508729577064514\n",
      "Batch 6834 - loss: 0.5907130837440491\n",
      "Batch 6835 - loss: 0.5234224200248718\n",
      "Batch 6836 - loss: 0.5060827136039734\n",
      "Batch 6837 - loss: 0.5072237849235535\n",
      "Batch 6838 - loss: 0.47699299454689026\n",
      "Batch 6839 - loss: 0.4740237593650818\n",
      "Batch 6840 - loss: 0.49879565834999084\n",
      "Batch 6841 - loss: 0.4868040680885315\n",
      "Batch 6842 - loss: 0.5404911637306213\n",
      "Batch 6843 - loss: 0.5839797854423523\n",
      "Batch 6844 - loss: 0.5469257235527039\n",
      "Batch 6845 - loss: 0.4949345588684082\n",
      "Batch 6846 - loss: 0.5292693376541138\n",
      "Batch 6847 - loss: 0.46557489037513733\n",
      "Batch 6848 - loss: 0.5433459281921387\n",
      "Batch 6849 - loss: 0.47595396637916565\n",
      "Batch 6850 - loss: 0.5433273315429688\n",
      "Batch 6851 - loss: 0.5272643566131592\n",
      "Batch 6852 - loss: 0.5352173447608948\n",
      "Batch 6853 - loss: 0.5320072770118713\n",
      "Batch 6854 - loss: 0.4789842963218689\n",
      "Batch 6855 - loss: 0.5410584807395935\n",
      "Batch 6856 - loss: 0.5681792497634888\n",
      "Batch 6857 - loss: 0.5444983839988708\n",
      "Batch 6858 - loss: 0.4984423816204071\n",
      "Batch 6859 - loss: 0.47732844948768616\n",
      "Batch 6860 - loss: 0.55353844165802\n",
      "Batch 6861 - loss: 0.5884771943092346\n",
      "Batch 6862 - loss: 0.5451679825782776\n",
      "Batch 6863 - loss: 0.4711415469646454\n",
      "Batch 6864 - loss: 0.5737175941467285\n",
      "Batch 6865 - loss: 0.5761671662330627\n",
      "Batch 6866 - loss: 0.522327184677124\n",
      "Batch 6867 - loss: 0.5114247798919678\n",
      "Batch 6868 - loss: 0.5457967519760132\n",
      "Batch 6869 - loss: 0.5060299038887024\n",
      "Batch 6870 - loss: 0.5311611890792847\n",
      "Batch 6871 - loss: 0.5258393287658691\n",
      "Batch 6872 - loss: 0.5951730608940125\n",
      "Batch 6873 - loss: 0.5170261263847351\n",
      "Batch 6874 - loss: 0.519131600856781\n",
      "Batch 6875 - loss: 0.5326119661331177\n",
      "Batch 6876 - loss: 0.5301454067230225\n",
      "Batch 6877 - loss: 0.5140920877456665\n",
      "Batch 6878 - loss: 0.5095492601394653\n",
      "Batch 6879 - loss: 0.4808497428894043\n",
      "Batch 6880 - loss: 0.5060999393463135\n",
      "Batch 6881 - loss: 0.49474212527275085\n",
      "Batch 6882 - loss: 0.5696874260902405\n",
      "Batch 6883 - loss: 0.4979078769683838\n",
      "Batch 6884 - loss: 0.5412042737007141\n",
      "Batch 6885 - loss: 0.5649372339248657\n",
      "Batch 6886 - loss: 0.5067135095596313\n",
      "Batch 6887 - loss: 0.5247020721435547\n",
      "Batch 6888 - loss: 0.48645323514938354\n",
      "Batch 6889 - loss: 0.521622359752655\n",
      "Batch 6890 - loss: 0.5279834270477295\n",
      "Batch 6891 - loss: 0.5861882567405701\n",
      "Batch 6892 - loss: 0.5282423496246338\n",
      "Batch 6893 - loss: 0.5352092981338501\n",
      "Batch 6894 - loss: 0.5595057606697083\n",
      "Batch 6895 - loss: 0.4703623354434967\n",
      "Batch 6896 - loss: 0.50990891456604\n",
      "Batch 6897 - loss: 0.4813554883003235\n",
      "Batch 6898 - loss: 0.5261312127113342\n",
      "Batch 6899 - loss: 0.48967623710632324\n",
      "Batch 6900 - loss: 0.49457404017448425\n",
      "Batch 6901 - loss: 0.5141383409500122\n",
      "Batch 6902 - loss: 0.5218421816825867\n",
      "Batch 6903 - loss: 0.5095685124397278\n",
      "Batch 6904 - loss: 0.47984743118286133\n",
      "Batch 6905 - loss: 0.5358576774597168\n",
      "Batch 6906 - loss: 0.5494240522384644\n",
      "Batch 6907 - loss: 0.5430658459663391\n",
      "Batch 6908 - loss: 0.5718000531196594\n",
      "Batch 6909 - loss: 0.5062546730041504\n",
      "Batch 6910 - loss: 0.5209184885025024\n",
      "Batch 6911 - loss: 0.5453920960426331\n",
      "Batch 6912 - loss: 0.5705593228340149\n",
      "Batch 6913 - loss: 0.522146999835968\n",
      "Batch 6914 - loss: 0.5617228150367737\n",
      "Batch 6915 - loss: 0.5668242573738098\n",
      "Batch 6916 - loss: 0.5375435948371887\n",
      "Batch 6917 - loss: 0.5622275471687317\n",
      "Batch 6918 - loss: 0.5567516088485718\n",
      "Batch 6919 - loss: 0.4975167214870453\n",
      "Batch 6920 - loss: 0.5260036587715149\n",
      "Batch 6921 - loss: 0.5120881795883179\n",
      "Batch 6922 - loss: 0.517953634262085\n",
      "Batch 6923 - loss: 0.5105373859405518\n",
      "Batch 6924 - loss: 0.5205590128898621\n",
      "Batch 6925 - loss: 0.5427948236465454\n",
      "Batch 6926 - loss: 0.5214206576347351\n",
      "Batch 6927 - loss: 0.6002004742622375\n",
      "Batch 6928 - loss: 0.5519793033599854\n",
      "Batch 6929 - loss: 0.47870153188705444\n",
      "Batch 6930 - loss: 0.5082365274429321\n",
      "Batch 6931 - loss: 0.5020096898078918\n",
      "Batch 6932 - loss: 0.4865487515926361\n",
      "Batch 6933 - loss: 0.490875244140625\n",
      "Batch 6934 - loss: 0.5112373232841492\n",
      "Batch 6935 - loss: 0.537954568862915\n",
      "Batch 6936 - loss: 0.5115588307380676\n",
      "Batch 6937 - loss: 0.578890860080719\n",
      "Batch 6938 - loss: 0.478725403547287\n",
      "Batch 6939 - loss: 0.5297906398773193\n",
      "Batch 6940 - loss: 0.5000261068344116\n",
      "Batch 6941 - loss: 0.5714204907417297\n",
      "Batch 6942 - loss: 0.5428471565246582\n",
      "Batch 6943 - loss: 0.4602188467979431\n",
      "Batch 6944 - loss: 0.5188307166099548\n",
      "Batch 6945 - loss: 0.4494638741016388\n",
      "Batch 6946 - loss: 0.4874948561191559\n",
      "Batch 6947 - loss: 0.5460992455482483\n",
      "Batch 6948 - loss: 0.5848971009254456\n",
      "Batch 6949 - loss: 0.509304404258728\n",
      "Batch 6950 - loss: 0.49335983395576477\n",
      "Batch 6951 - loss: 0.5120237469673157\n",
      "Batch 6952 - loss: 0.4985356330871582\n",
      "Batch 6953 - loss: 0.4702567160129547\n",
      "Batch 6954 - loss: 0.5013665556907654\n",
      "Batch 6955 - loss: 0.5029358863830566\n",
      "Batch 6956 - loss: 0.4934405982494354\n",
      "Batch 6957 - loss: 0.5411384105682373\n",
      "Batch 6958 - loss: 0.48876234889030457\n",
      "Batch 6959 - loss: 0.5466716885566711\n",
      "Batch 6960 - loss: 0.4721960425376892\n",
      "Batch 6961 - loss: 0.48851945996284485\n",
      "Batch 6962 - loss: 0.5203912258148193\n",
      "Batch 6963 - loss: 0.4859830439090729\n",
      "Batch 6964 - loss: 0.5556157827377319\n",
      "Batch 6965 - loss: 0.5243832468986511\n",
      "Batch 6966 - loss: 0.5043857097625732\n",
      "Batch 6967 - loss: 0.4721623659133911\n",
      "Batch 6968 - loss: 0.5169468522071838\n",
      "Batch 6969 - loss: 0.4754963219165802\n",
      "Batch 6970 - loss: 0.49438247084617615\n",
      "Batch 6971 - loss: 0.49646231532096863\n",
      "Batch 6972 - loss: 0.4702436029911041\n",
      "Batch 6973 - loss: 0.5292146801948547\n",
      "Batch 6974 - loss: 0.46280714869499207\n",
      "Batch 6975 - loss: 0.4478313624858856\n",
      "Batch 6976 - loss: 0.5282706618309021\n",
      "Batch 6977 - loss: 0.4666960835456848\n",
      "Batch 6978 - loss: 0.5405298471450806\n",
      "Batch 6979 - loss: 0.4980938732624054\n",
      "Batch 6980 - loss: 0.4552016258239746\n",
      "Batch 6981 - loss: 0.5790146589279175\n",
      "Batch 6982 - loss: 0.48084011673927307\n",
      "Batch 6983 - loss: 0.5106067061424255\n",
      "Batch 6984 - loss: 0.5308170318603516\n",
      "Batch 6985 - loss: 0.5574249029159546\n",
      "Batch 6986 - loss: 0.49215346574783325\n",
      "Batch 6987 - loss: 0.5184409022331238\n",
      "Batch 6988 - loss: 0.5448835492134094\n",
      "Batch 6989 - loss: 0.5519766211509705\n",
      "Batch 6990 - loss: 0.47695910930633545\n",
      "Batch 6991 - loss: 0.541845977306366\n",
      "Batch 6992 - loss: 0.4869299829006195\n",
      "Batch 6993 - loss: 0.4620632231235504\n",
      "Batch 6994 - loss: 0.45787543058395386\n",
      "Batch 6995 - loss: 0.53182452917099\n",
      "Batch 6996 - loss: 0.5057441592216492\n",
      "Batch 6997 - loss: 0.5370972156524658\n",
      "Batch 6998 - loss: 0.504203736782074\n",
      "Batch 6999 - loss: 0.48947492241859436\n",
      "Batch 7000 - loss: 0.5123917460441589\n",
      "Batch 7001 - loss: 0.5162724256515503\n",
      "Batch 7002 - loss: 0.5052145719528198\n",
      "Batch 7003 - loss: 0.5189074873924255\n",
      "Batch 7004 - loss: 0.533359169960022\n",
      "Batch 7005 - loss: 0.5442670583724976\n",
      "Batch 7006 - loss: 0.4692831337451935\n",
      "Batch 7007 - loss: 0.5219877362251282\n",
      "Batch 7008 - loss: 0.5570595860481262\n",
      "Batch 7009 - loss: 0.5088827610015869\n",
      "Batch 7010 - loss: 0.48434212803840637\n",
      "Batch 7011 - loss: 0.5158894658088684\n",
      "Batch 7012 - loss: 0.5548933148384094\n",
      "Batch 7013 - loss: 0.5556221008300781\n",
      "Batch 7014 - loss: 0.5336492657661438\n",
      "Batch 7015 - loss: 0.5260628461837769\n",
      "Batch 7016 - loss: 0.5075150728225708\n",
      "Batch 7017 - loss: 0.480882465839386\n",
      "Batch 7018 - loss: 0.49068012833595276\n",
      "Batch 7019 - loss: 0.45785725116729736\n",
      "Batch 7020 - loss: 0.506964921951294\n",
      "Batch 7021 - loss: 0.5163913369178772\n",
      "Batch 7022 - loss: 0.4951622188091278\n",
      "Batch 7023 - loss: 0.5336868166923523\n",
      "Batch 7024 - loss: 0.5514368414878845\n",
      "Batch 7025 - loss: 0.5476793646812439\n",
      "Batch 7026 - loss: 0.5129980444908142\n",
      "Batch 7027 - loss: 0.5353245139122009\n",
      "Batch 7028 - loss: 0.4958125352859497\n",
      "Batch 7029 - loss: 0.49581262469291687\n",
      "Batch 7030 - loss: 0.49550095200538635\n",
      "Batch 7031 - loss: 0.5916572213172913\n",
      "Batch 7032 - loss: 0.4891411364078522\n",
      "Batch 7033 - loss: 0.5405793190002441\n",
      "Batch 7034 - loss: 0.5368068814277649\n",
      "Batch 7035 - loss: 0.5034623146057129\n",
      "Batch 7036 - loss: 0.5375974774360657\n",
      "Batch 7037 - loss: 0.5467066764831543\n",
      "Batch 7038 - loss: 0.48951664566993713\n",
      "Batch 7039 - loss: 0.49858614802360535\n",
      "Batch 7040 - loss: 0.5459250807762146\n",
      "Batch 7041 - loss: 0.5312067866325378\n",
      "Batch 7042 - loss: 0.5035995841026306\n",
      "Batch 7043 - loss: 0.4910045266151428\n",
      "Batch 7044 - loss: 0.48324304819107056\n",
      "Batch 7045 - loss: 0.49298495054244995\n",
      "Batch 7046 - loss: 0.5560529232025146\n",
      "Batch 7047 - loss: 0.5049574971199036\n",
      "Batch 7048 - loss: 0.5246654152870178\n",
      "Batch 7049 - loss: 0.44995591044425964\n",
      "Batch 7050 - loss: 0.5305002927780151\n",
      "Batch 7051 - loss: 0.522480309009552\n",
      "Batch 7052 - loss: 0.5116132497787476\n",
      "Batch 7053 - loss: 0.6023882031440735\n",
      "Batch 7054 - loss: 0.5122727155685425\n",
      "Batch 7055 - loss: 0.5210614204406738\n",
      "Batch 7056 - loss: 0.4656555652618408\n",
      "Batch 7057 - loss: 0.49787554144859314\n",
      "Batch 7058 - loss: 0.5396987795829773\n",
      "Batch 7059 - loss: 0.5817214846611023\n",
      "Batch 7060 - loss: 0.5428842902183533\n",
      "Batch 7061 - loss: 0.5348777770996094\n",
      "Batch 7062 - loss: 0.5053699612617493\n",
      "Batch 7063 - loss: 0.5171961188316345\n",
      "Batch 7064 - loss: 0.4727669060230255\n",
      "Batch 7065 - loss: 0.5191425681114197\n",
      "Batch 7066 - loss: 0.5215467214584351\n",
      "Batch 7067 - loss: 0.515457272529602\n",
      "Batch 7068 - loss: 0.5023090243339539\n",
      "Batch 7069 - loss: 0.5173355937004089\n",
      "Batch 7070 - loss: 0.5483685731887817\n",
      "Batch 7071 - loss: 0.5641850829124451\n",
      "Batch 7072 - loss: 0.5430562496185303\n",
      "Batch 7073 - loss: 0.4790651500225067\n",
      "Batch 7074 - loss: 0.5841538310050964\n",
      "Batch 7075 - loss: 0.4817621111869812\n",
      "Batch 7076 - loss: 0.5254868268966675\n",
      "Batch 7077 - loss: 0.5021237134933472\n",
      "Batch 7078 - loss: 0.4936414361000061\n",
      "Batch 7079 - loss: 0.5396227240562439\n",
      "Batch 7080 - loss: 0.5139148235321045\n",
      "Batch 7081 - loss: 0.5295966267585754\n",
      "Batch 7082 - loss: 0.5009216666221619\n",
      "Batch 7083 - loss: 0.48411402106285095\n",
      "Batch 7084 - loss: 0.5124603509902954\n",
      "Batch 7085 - loss: 0.5003744959831238\n",
      "Batch 7086 - loss: 0.5287500619888306\n",
      "Batch 7087 - loss: 0.5426939725875854\n",
      "Batch 7088 - loss: 0.496229350566864\n",
      "Batch 7089 - loss: 0.4858075976371765\n",
      "Batch 7090 - loss: 0.5250314474105835\n",
      "Batch 7091 - loss: 0.545639157295227\n",
      "Batch 7092 - loss: 0.5108529329299927\n",
      "Batch 7093 - loss: 0.5171283483505249\n",
      "Batch 7094 - loss: 0.5079947710037231\n",
      "Batch 7095 - loss: 0.5586968064308167\n",
      "Batch 7096 - loss: 0.5131774544715881\n",
      "Batch 7097 - loss: 0.482860267162323\n",
      "Batch 7098 - loss: 0.5101292729377747\n",
      "Batch 7099 - loss: 0.5118117928504944\n",
      "Batch 7100 - loss: 0.49495217204093933\n",
      "Batch 7101 - loss: 0.5125634670257568\n",
      "Batch 7102 - loss: 0.5583131313323975\n",
      "Batch 7103 - loss: 0.4305463433265686\n",
      "Batch 7104 - loss: 0.45001220703125\n",
      "Batch 7105 - loss: 0.522691547870636\n",
      "Batch 7106 - loss: 0.5317418575286865\n",
      "Batch 7107 - loss: 0.528022050857544\n",
      "Batch 7108 - loss: 0.524511456489563\n",
      "Batch 7109 - loss: 0.47601643204689026\n",
      "Batch 7110 - loss: 0.46355006098747253\n",
      "Batch 7111 - loss: 0.5391839742660522\n",
      "Batch 7112 - loss: 0.5339472889900208\n",
      "Batch 7113 - loss: 0.5156374573707581\n",
      "Batch 7114 - loss: 0.5418725609779358\n",
      "Batch 7115 - loss: 0.5029767751693726\n",
      "Batch 7116 - loss: 0.5211710333824158\n",
      "Batch 7117 - loss: 0.4858091175556183\n",
      "Batch 7118 - loss: 0.49818384647369385\n",
      "Batch 7119 - loss: 0.5174848437309265\n",
      "Batch 7120 - loss: 0.5134469270706177\n",
      "Batch 7121 - loss: 0.4657132029533386\n",
      "Batch 7122 - loss: 0.4743400812149048\n",
      "Batch 7123 - loss: 0.48459935188293457\n",
      "Batch 7124 - loss: 0.5280239582061768\n",
      "Batch 7125 - loss: 0.49643513560295105\n",
      "Batch 7126 - loss: 0.50398850440979\n",
      "Batch 7127 - loss: 0.4667187035083771\n",
      "Batch 7128 - loss: 0.516143798828125\n",
      "Batch 7129 - loss: 0.5011084675788879\n",
      "Batch 7130 - loss: 0.4973562955856323\n",
      "Batch 7131 - loss: 0.4505295753479004\n",
      "Batch 7132 - loss: 0.5181892514228821\n",
      "Batch 7133 - loss: 0.4765368700027466\n",
      "Batch 7134 - loss: 0.5527104139328003\n",
      "Batch 7135 - loss: 0.5526210069656372\n",
      "Batch 7136 - loss: 0.5636512637138367\n",
      "Batch 7137 - loss: 0.47816184163093567\n",
      "Batch 7138 - loss: 0.46159908175468445\n",
      "Batch 7139 - loss: 0.48998674750328064\n",
      "Batch 7140 - loss: 0.5157092213630676\n",
      "Batch 7141 - loss: 0.5914378762245178\n",
      "Batch 7142 - loss: 0.4951326251029968\n",
      "Batch 7143 - loss: 0.499200701713562\n",
      "Batch 7144 - loss: 0.5045801401138306\n",
      "Batch 7145 - loss: 0.570120096206665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5027ec11d44db693f83c0bbae4275b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7146 - loss: 0.4789775609970093\n",
      "Batch 7147 - loss: 0.581805408000946\n",
      "Batch 7148 - loss: 0.5245980620384216\n",
      "Batch 7149 - loss: 0.5132439732551575\n",
      "Batch 7150 - loss: 0.5542837381362915\n",
      "Batch 7151 - loss: 0.4987819790840149\n",
      "Batch 7152 - loss: 0.5228250026702881\n",
      "Batch 7153 - loss: 0.4786161482334137\n",
      "Batch 7154 - loss: 0.5244561433792114\n",
      "Batch 7155 - loss: 0.5402600765228271\n",
      "Batch 7156 - loss: 0.5231190919876099\n",
      "Batch 7157 - loss: 0.5150835514068604\n",
      "Batch 7158 - loss: 0.5437225699424744\n",
      "Batch 7159 - loss: 0.5432289242744446\n",
      "Batch 7160 - loss: 0.49089494347572327\n",
      "Batch 7161 - loss: 0.520121157169342\n",
      "Batch 7162 - loss: 0.5078195929527283\n",
      "Batch 7163 - loss: 0.525007963180542\n",
      "Batch 7164 - loss: 0.4917588233947754\n",
      "Batch 7165 - loss: 0.49032890796661377\n",
      "Batch 7166 - loss: 0.5001788139343262\n",
      "Batch 7167 - loss: 0.5655504465103149\n",
      "Batch 7168 - loss: 0.5450198650360107\n",
      "Batch 7169 - loss: 0.48923224210739136\n",
      "Batch 7170 - loss: 0.5008350610733032\n",
      "Batch 7171 - loss: 0.49365508556365967\n",
      "Batch 7172 - loss: 0.4865068793296814\n",
      "Batch 7173 - loss: 0.4755084812641144\n",
      "Batch 7174 - loss: 0.5689747929573059\n",
      "Batch 7175 - loss: 0.5032925605773926\n",
      "Batch 7176 - loss: 0.5148443579673767\n",
      "Batch 7177 - loss: 0.5109092593193054\n",
      "Batch 7178 - loss: 0.5199052691459656\n",
      "Batch 7179 - loss: 0.506838858127594\n",
      "Batch 7180 - loss: 0.518837571144104\n",
      "Batch 7181 - loss: 0.5393518805503845\n",
      "Batch 7182 - loss: 0.5275291800498962\n",
      "Batch 7183 - loss: 0.5456926822662354\n",
      "Batch 7184 - loss: 0.5548800230026245\n",
      "Batch 7185 - loss: 0.5316610336303711\n",
      "Batch 7186 - loss: 0.5779374241828918\n",
      "Batch 7187 - loss: 0.48843681812286377\n",
      "Batch 7188 - loss: 0.5283643007278442\n",
      "Batch 7189 - loss: 0.5494044423103333\n",
      "Batch 7190 - loss: 0.5113442540168762\n",
      "Batch 7191 - loss: 0.5236585140228271\n",
      "Batch 7192 - loss: 0.4933834373950958\n",
      "Batch 7193 - loss: 0.46031197905540466\n",
      "Batch 7194 - loss: 0.5436816215515137\n",
      "Batch 7195 - loss: 0.516125500202179\n",
      "Batch 7196 - loss: 0.5017184615135193\n",
      "Batch 7197 - loss: 0.621407151222229\n",
      "Batch 7198 - loss: 0.5087670087814331\n",
      "Batch 7199 - loss: 0.49897345900535583\n",
      "Batch 7200 - loss: 0.5228160619735718\n",
      "Batch 7201 - loss: 0.5294186472892761\n",
      "Batch 7202 - loss: 0.5663420557975769\n",
      "Batch 7203 - loss: 0.4870835244655609\n",
      "Batch 7204 - loss: 0.45306769013404846\n",
      "Batch 7205 - loss: 0.5339822769165039\n",
      "Batch 7206 - loss: 0.5462979674339294\n",
      "Batch 7207 - loss: 0.5480522513389587\n",
      "Batch 7208 - loss: 0.4807010591030121\n",
      "Batch 7209 - loss: 0.5248082280158997\n",
      "Batch 7210 - loss: 0.4855390191078186\n",
      "Batch 7211 - loss: 0.47886937856674194\n",
      "Batch 7212 - loss: 0.5412576794624329\n",
      "Batch 7213 - loss: 0.5592048764228821\n",
      "Batch 7214 - loss: 0.4740571677684784\n",
      "Batch 7215 - loss: 0.527815580368042\n",
      "Batch 7216 - loss: 0.5190710425376892\n",
      "Batch 7217 - loss: 0.5347465872764587\n",
      "Batch 7218 - loss: 0.518953800201416\n",
      "Batch 7219 - loss: 0.48247799277305603\n",
      "Batch 7220 - loss: 0.5400607585906982\n",
      "Batch 7221 - loss: 0.5102707743644714\n",
      "Batch 7222 - loss: 0.49426108598709106\n",
      "Batch 7223 - loss: 0.4893036484718323\n",
      "Batch 7224 - loss: 0.5421459674835205\n",
      "Batch 7225 - loss: 0.48263198137283325\n",
      "Batch 7226 - loss: 0.45906704664230347\n",
      "Batch 7227 - loss: 0.5074403285980225\n",
      "Batch 7228 - loss: 0.4602169394493103\n",
      "Batch 7229 - loss: 0.4815574586391449\n",
      "Batch 7230 - loss: 0.5498616099357605\n",
      "Batch 7231 - loss: 0.500839114189148\n",
      "Batch 7232 - loss: 0.4793080687522888\n",
      "Batch 7233 - loss: 0.480567067861557\n",
      "Batch 7234 - loss: 0.5247918367385864\n",
      "Batch 7235 - loss: 0.4631434679031372\n",
      "Batch 7236 - loss: 0.5246391892433167\n",
      "Batch 7237 - loss: 0.4686598479747772\n",
      "Batch 7238 - loss: 0.4412960112094879\n",
      "Batch 7239 - loss: 0.5207464098930359\n",
      "Batch 7240 - loss: 0.5481460094451904\n",
      "Batch 7241 - loss: 0.5613213777542114\n",
      "Batch 7242 - loss: 0.4797135591506958\n",
      "Batch 7243 - loss: 0.4912504553794861\n",
      "Batch 7244 - loss: 0.5557959675788879\n",
      "Batch 7245 - loss: 0.4749336540699005\n",
      "Batch 7246 - loss: 0.5119305849075317\n",
      "Batch 7247 - loss: 0.521457850933075\n",
      "Batch 7248 - loss: 0.5309479832649231\n",
      "Batch 7249 - loss: 0.5563927292823792\n",
      "Batch 7250 - loss: 0.45938974618911743\n",
      "Batch 7251 - loss: 0.511468768119812\n",
      "Batch 7252 - loss: 0.49025970697402954\n",
      "Batch 7253 - loss: 0.4822416603565216\n",
      "Batch 7254 - loss: 0.5263492465019226\n",
      "Batch 7255 - loss: 0.5190304517745972\n",
      "Batch 7256 - loss: 0.5426889061927795\n",
      "Batch 7257 - loss: 0.43929731845855713\n",
      "Batch 7258 - loss: 0.4604891538619995\n",
      "Batch 7259 - loss: 0.47281134128570557\n",
      "Batch 7260 - loss: 0.4821549355983734\n",
      "Batch 7261 - loss: 0.495462030172348\n",
      "Batch 7262 - loss: 0.5339322686195374\n",
      "Batch 7263 - loss: 0.48467427492141724\n",
      "Batch 7264 - loss: 0.48729613423347473\n",
      "Batch 7265 - loss: 0.5071844458580017\n",
      "Batch 7266 - loss: 0.5275781750679016\n",
      "Batch 7267 - loss: 0.546089231967926\n",
      "Batch 7268 - loss: 0.5016476511955261\n",
      "Batch 7269 - loss: 0.4883371591567993\n",
      "Batch 7270 - loss: 0.5180537700653076\n",
      "Batch 7271 - loss: 0.5128127336502075\n",
      "Batch 7272 - loss: 0.5978040099143982\n",
      "Batch 7273 - loss: 0.4898885488510132\n",
      "Batch 7274 - loss: 0.4865448772907257\n",
      "Batch 7275 - loss: 0.5366602540016174\n",
      "Batch 7276 - loss: 0.45470166206359863\n",
      "Batch 7277 - loss: 0.5732740759849548\n",
      "Batch 7278 - loss: 0.5208503603935242\n",
      "Batch 7279 - loss: 0.464609831571579\n",
      "Batch 7280 - loss: 0.4793207049369812\n",
      "Batch 7281 - loss: 0.5402355194091797\n",
      "Batch 7282 - loss: 0.49084582924842834\n",
      "Batch 7283 - loss: 0.4927535653114319\n",
      "Batch 7284 - loss: 0.4914313554763794\n",
      "Batch 7285 - loss: 0.547743558883667\n",
      "Batch 7286 - loss: 0.4803091287612915\n",
      "Batch 7287 - loss: 0.5086964964866638\n",
      "Batch 7288 - loss: 0.5062370896339417\n",
      "Batch 7289 - loss: 0.5419467687606812\n",
      "Batch 7290 - loss: 0.4818899631500244\n",
      "Batch 7291 - loss: 0.5435442924499512\n",
      "Batch 7292 - loss: 0.49779558181762695\n",
      "Batch 7293 - loss: 0.5465031266212463\n",
      "Batch 7294 - loss: 0.4660798907279968\n",
      "Batch 7295 - loss: 0.5071048736572266\n",
      "Batch 7296 - loss: 0.47064629197120667\n",
      "Batch 7297 - loss: 0.44925346970558167\n",
      "Batch 7298 - loss: 0.4423483610153198\n",
      "Batch 7299 - loss: 0.44142669439315796\n",
      "Batch 7300 - loss: 0.5267360806465149\n",
      "Batch 7301 - loss: 0.5474429726600647\n",
      "Batch 7302 - loss: 0.5584948062896729\n",
      "Batch 7303 - loss: 0.5366401076316833\n",
      "Batch 7304 - loss: 0.5706520080566406\n",
      "Batch 7305 - loss: 0.49807339906692505\n",
      "Batch 7306 - loss: 0.4949570894241333\n",
      "Batch 7307 - loss: 0.48082202672958374\n",
      "Batch 7308 - loss: 0.4802505373954773\n",
      "Batch 7309 - loss: 0.5129671692848206\n",
      "Batch 7310 - loss: 0.5479801297187805\n",
      "Batch 7311 - loss: 0.5289686918258667\n",
      "Batch 7312 - loss: 0.5072253346443176\n",
      "Batch 7313 - loss: 0.5390573143959045\n",
      "Batch 7314 - loss: 0.5430613160133362\n",
      "Batch 7315 - loss: 0.48108774423599243\n",
      "Batch 7316 - loss: 0.5087533593177795\n",
      "Batch 7317 - loss: 0.49103549122810364\n",
      "Batch 7318 - loss: 0.5245089530944824\n",
      "Batch 7319 - loss: 0.5216682553291321\n",
      "Batch 7320 - loss: 0.501689612865448\n",
      "Batch 7321 - loss: 0.47780922055244446\n",
      "Batch 7322 - loss: 0.48710882663726807\n",
      "Batch 7323 - loss: 0.49026772379875183\n",
      "Batch 7324 - loss: 0.5099292993545532\n",
      "Batch 7325 - loss: 0.5110459923744202\n",
      "Batch 7326 - loss: 0.5169431567192078\n",
      "Batch 7327 - loss: 0.46007898449897766\n",
      "Batch 7328 - loss: 0.49568870663642883\n",
      "Batch 7329 - loss: 0.5018734335899353\n",
      "Batch 7330 - loss: 0.45763787627220154\n",
      "Batch 7331 - loss: 0.5286462306976318\n",
      "Batch 7332 - loss: 0.597920298576355\n",
      "Batch 7333 - loss: 0.5126134753227234\n",
      "Batch 7334 - loss: 0.5190302729606628\n",
      "Batch 7335 - loss: 0.5602824091911316\n",
      "Batch 7336 - loss: 0.4539574980735779\n",
      "Batch 7337 - loss: 0.534508228302002\n",
      "Batch 7338 - loss: 0.5430063009262085\n",
      "Batch 7339 - loss: 0.5037944912910461\n",
      "Batch 7340 - loss: 0.4803786873817444\n",
      "Batch 7341 - loss: 0.5329924821853638\n",
      "Batch 7342 - loss: 0.5476164817810059\n",
      "Batch 7343 - loss: 0.5669575929641724\n",
      "Batch 7344 - loss: 0.5296102166175842\n",
      "Batch 7345 - loss: 0.5721271634101868\n",
      "Batch 7346 - loss: 0.5009083151817322\n",
      "Batch 7347 - loss: 0.47516074776649475\n",
      "Batch 7348 - loss: 0.5060085654258728\n",
      "Batch 7349 - loss: 0.5391099452972412\n",
      "Batch 7350 - loss: 0.506236732006073\n",
      "Batch 7351 - loss: 0.45284339785575867\n",
      "Batch 7352 - loss: 0.5315397381782532\n",
      "Batch 7353 - loss: 0.4548652470111847\n",
      "Batch 7354 - loss: 0.5291959047317505\n",
      "Batch 7355 - loss: 0.5077624917030334\n",
      "Batch 7356 - loss: 0.4703529179096222\n",
      "Batch 7357 - loss: 0.5162746906280518\n",
      "Batch 7358 - loss: 0.6082858443260193\n",
      "Batch 7359 - loss: 0.5356618165969849\n",
      "Batch 7360 - loss: 0.5104777812957764\n",
      "Batch 7361 - loss: 0.5004499554634094\n",
      "Batch 7362 - loss: 0.4639376699924469\n",
      "Batch 7363 - loss: 0.48680582642555237\n",
      "Batch 7364 - loss: 0.5626490116119385\n",
      "Batch 7365 - loss: 0.5493010878562927\n",
      "Batch 7366 - loss: 0.5029634833335876\n",
      "Batch 7367 - loss: 0.5589280724525452\n",
      "Batch 7368 - loss: 0.49660810828208923\n",
      "Batch 7369 - loss: 0.4901514947414398\n",
      "Batch 7370 - loss: 0.5117663145065308\n",
      "Batch 7371 - loss: 0.4772925078868866\n",
      "Batch 7372 - loss: 0.5209649801254272\n",
      "Batch 7373 - loss: 0.4854169487953186\n",
      "Batch 7374 - loss: 0.5309311747550964\n",
      "Batch 7375 - loss: 0.5269879698753357\n",
      "Batch 7376 - loss: 0.4918060600757599\n",
      "Batch 7377 - loss: 0.4941255748271942\n",
      "Batch 7378 - loss: 0.5213887095451355\n",
      "Batch 7379 - loss: 0.48510316014289856\n",
      "Batch 7380 - loss: 0.5131699442863464\n",
      "Batch 7381 - loss: 0.5106936097145081\n",
      "Batch 7382 - loss: 0.47290802001953125\n",
      "Batch 7383 - loss: 0.4932229220867157\n",
      "Batch 7384 - loss: 0.5029990673065186\n",
      "Batch 7385 - loss: 0.46152251958847046\n",
      "Batch 7386 - loss: 0.514297604560852\n",
      "Batch 7387 - loss: 0.5459849834442139\n",
      "Batch 7388 - loss: 0.44284456968307495\n",
      "Batch 7389 - loss: 0.5369988083839417\n",
      "Batch 7390 - loss: 0.5118938684463501\n",
      "Batch 7391 - loss: 0.4625869691371918\n",
      "Batch 7392 - loss: 0.504612386226654\n",
      "Batch 7393 - loss: 0.5283870100975037\n",
      "Batch 7394 - loss: 0.5201467871665955\n",
      "Batch 7395 - loss: 0.45610934495925903\n",
      "Batch 7396 - loss: 0.5299453139305115\n",
      "Batch 7397 - loss: 0.6334277391433716\n",
      "Batch 7398 - loss: 0.5001490116119385\n",
      "Batch 7399 - loss: 0.5199294090270996\n",
      "Batch 7400 - loss: 0.5362533926963806\n",
      "Batch 7401 - loss: 0.532712996006012\n",
      "Batch 7402 - loss: 0.5401637554168701\n",
      "Batch 7403 - loss: 0.5319432616233826\n",
      "Batch 7404 - loss: 0.5276159048080444\n",
      "Batch 7405 - loss: 0.5291052460670471\n",
      "Batch 7406 - loss: 0.523386538028717\n",
      "Batch 7407 - loss: 0.5306304097175598\n",
      "Batch 7408 - loss: 0.5307137370109558\n",
      "Batch 7409 - loss: 0.4870525300502777\n",
      "Batch 7410 - loss: 0.5673326849937439\n",
      "Batch 7411 - loss: 0.5209428668022156\n",
      "Batch 7412 - loss: 0.5261675715446472\n",
      "Batch 7413 - loss: 0.5203954577445984\n",
      "Batch 7414 - loss: 0.5168198943138123\n",
      "Batch 7415 - loss: 0.506085216999054\n",
      "Batch 7416 - loss: 0.524422824382782\n",
      "Batch 7417 - loss: 0.537456750869751\n",
      "Batch 7418 - loss: 0.5015116930007935\n",
      "Batch 7419 - loss: 0.5276094079017639\n",
      "Batch 7420 - loss: 0.5842863321304321\n",
      "Batch 7421 - loss: 0.48261404037475586\n",
      "Batch 7422 - loss: 0.475066214799881\n",
      "Batch 7423 - loss: 0.48144254088401794\n",
      "Batch 7424 - loss: 0.5238784551620483\n",
      "Batch 7425 - loss: 0.5851874947547913\n",
      "Batch 7426 - loss: 0.5476973652839661\n",
      "Batch 7427 - loss: 0.515671968460083\n",
      "Batch 7428 - loss: 0.4498273730278015\n",
      "Batch 7429 - loss: 0.528935968875885\n",
      "Batch 7430 - loss: 0.5312855243682861\n",
      "Batch 7431 - loss: 0.5162146687507629\n",
      "Batch 7432 - loss: 0.47790661454200745\n",
      "Batch 7433 - loss: 0.5293923616409302\n",
      "Batch 7434 - loss: 0.4570217728614807\n",
      "Batch 7435 - loss: 0.5907111167907715\n",
      "Batch 7436 - loss: 0.5159448385238647\n",
      "Batch 7437 - loss: 0.5305910110473633\n",
      "Batch 7438 - loss: 0.4980129599571228\n",
      "Batch 7439 - loss: 0.5881709456443787\n",
      "Batch 7440 - loss: 0.5450611710548401\n",
      "Batch 7441 - loss: 0.5152220129966736\n",
      "Batch 7442 - loss: 0.5552085041999817\n",
      "Batch 7443 - loss: 0.49879294633865356\n",
      "Batch 7444 - loss: 0.5052829384803772\n",
      "Batch 7445 - loss: 0.5213117003440857\n",
      "Batch 7446 - loss: 0.4859219491481781\n",
      "Batch 7447 - loss: 0.5428702235221863\n",
      "Batch 7448 - loss: 0.5167531967163086\n",
      "Batch 7449 - loss: 0.5084242224693298\n",
      "Batch 7450 - loss: 0.5652999877929688\n",
      "Batch 7451 - loss: 0.5378484129905701\n",
      "Batch 7452 - loss: 0.5591057538986206\n",
      "Batch 7453 - loss: 0.5285468101501465\n",
      "Batch 7454 - loss: 0.5313887596130371\n",
      "Batch 7455 - loss: 0.5102675557136536\n",
      "Batch 7456 - loss: 0.4349428117275238\n",
      "Batch 7457 - loss: 0.5430617332458496\n",
      "Batch 7458 - loss: 0.47200343012809753\n",
      "Batch 7459 - loss: 0.4963104724884033\n",
      "Batch 7460 - loss: 0.48363977670669556\n",
      "Batch 7461 - loss: 0.4984234571456909\n",
      "Batch 7462 - loss: 0.522972822189331\n",
      "Batch 7463 - loss: 0.5697325468063354\n",
      "Batch 7464 - loss: 0.4764065742492676\n",
      "Batch 7465 - loss: 0.4762798845767975\n",
      "Batch 7466 - loss: 0.5126211643218994\n",
      "Batch 7467 - loss: 0.5262312293052673\n",
      "Batch 7468 - loss: 0.4607941508293152\n",
      "Batch 7469 - loss: 0.5350005030632019\n",
      "Batch 7470 - loss: 0.4988718628883362\n",
      "Batch 7471 - loss: 0.5092695355415344\n",
      "Batch 7472 - loss: 0.5525501370429993\n",
      "Batch 7473 - loss: 0.5451563596725464\n",
      "Batch 7474 - loss: 0.474117249250412\n",
      "Batch 7475 - loss: 0.470389187335968\n",
      "Batch 7476 - loss: 0.50107342004776\n",
      "Batch 7477 - loss: 0.5689154863357544\n",
      "Batch 7478 - loss: 0.48597651720046997\n",
      "Batch 7479 - loss: 0.5364187359809875\n",
      "Batch 7480 - loss: 0.47922655940055847\n",
      "Batch 7481 - loss: 0.49262887239456177\n",
      "Batch 7482 - loss: 0.5274513363838196\n",
      "Batch 7483 - loss: 0.5131016969680786\n",
      "Batch 7484 - loss: 0.5304892063140869\n",
      "Batch 7485 - loss: 0.494340181350708\n",
      "Batch 7486 - loss: 0.5226321220397949\n",
      "Batch 7487 - loss: 0.46779683232307434\n",
      "Batch 7488 - loss: 0.4667954742908478\n",
      "Batch 7489 - loss: 0.48743948340415955\n",
      "Batch 7490 - loss: 0.5287033915519714\n",
      "Batch 7491 - loss: 0.5207635164260864\n",
      "Batch 7492 - loss: 0.536257266998291\n",
      "Batch 7493 - loss: 0.5294255614280701\n",
      "Batch 7494 - loss: 0.5520731806755066\n",
      "Batch 7495 - loss: 0.5082718729972839\n",
      "Batch 7496 - loss: 0.5068071484565735\n",
      "Batch 7497 - loss: 0.5770183205604553\n",
      "Batch 7498 - loss: 0.5044678449630737\n",
      "Batch 7499 - loss: 0.5074912309646606\n",
      "Batch 7500 - loss: 0.5520658493041992\n",
      "Batch 7501 - loss: 0.4908713400363922\n",
      "Batch 7502 - loss: 0.5403746962547302\n",
      "Batch 7503 - loss: 0.5758504271507263\n",
      "Batch 7504 - loss: 0.5291489958763123\n",
      "Batch 7505 - loss: 0.5204871296882629\n",
      "Batch 7506 - loss: 0.5586040616035461\n",
      "Batch 7507 - loss: 0.46249961853027344\n",
      "Batch 7508 - loss: 0.5963456630706787\n",
      "Batch 7509 - loss: 0.5493804216384888\n",
      "Batch 7510 - loss: 0.5448310375213623\n",
      "Batch 7511 - loss: 0.5504753589630127\n",
      "Batch 7512 - loss: 0.5515331029891968\n",
      "Batch 7513 - loss: 0.5283147692680359\n",
      "Batch 7514 - loss: 0.5268389582633972\n",
      "Batch 7515 - loss: 0.5748989582061768\n",
      "Batch 7516 - loss: 0.521084725856781\n",
      "Batch 7517 - loss: 0.5322909951210022\n",
      "Batch 7518 - loss: 0.4744085967540741\n",
      "Batch 7519 - loss: 0.5131113529205322\n",
      "Batch 7520 - loss: 0.4740527272224426\n",
      "Batch 7521 - loss: 0.5172976851463318\n",
      "Batch 7522 - loss: 0.5156014561653137\n",
      "Batch 7523 - loss: 0.520121157169342\n",
      "Batch 7524 - loss: 0.505248486995697\n",
      "Batch 7525 - loss: 0.5645689964294434\n",
      "Batch 7526 - loss: 0.5190919041633606\n",
      "Batch 7527 - loss: 0.5129695534706116\n",
      "Batch 7528 - loss: 0.5348221659660339\n",
      "Batch 7529 - loss: 0.5111820101737976\n",
      "Batch 7530 - loss: 0.48905086517333984\n",
      "Batch 7531 - loss: 0.5394065380096436\n",
      "Batch 7532 - loss: 0.48782211542129517\n",
      "Batch 7533 - loss: 0.5234082937240601\n",
      "Batch 7534 - loss: 0.5202949047088623\n",
      "Batch 7535 - loss: 0.4915337562561035\n",
      "Batch 7536 - loss: 0.4610595107078552\n",
      "Batch 7537 - loss: 0.5047518014907837\n",
      "Batch 7538 - loss: 0.5520873665809631\n",
      "Batch 7539 - loss: 0.5138797163963318\n",
      "Batch 7540 - loss: 0.5429303646087646\n",
      "Batch 7541 - loss: 0.4823545813560486\n",
      "Batch 7542 - loss: 0.51478511095047\n",
      "Batch 7543 - loss: 0.5548591613769531\n",
      "Batch 7544 - loss: 0.494669646024704\n",
      "Batch 7545 - loss: 0.5498368740081787\n",
      "Batch 7546 - loss: 0.5303849577903748\n",
      "Batch 7547 - loss: 0.49999329447746277\n",
      "Batch 7548 - loss: 0.5029746294021606\n",
      "Batch 7549 - loss: 0.48055770993232727\n",
      "Batch 7550 - loss: 0.45963799953460693\n",
      "Batch 7551 - loss: 0.571821928024292\n",
      "Batch 7552 - loss: 0.49513956904411316\n",
      "Batch 7553 - loss: 0.5331224799156189\n",
      "Batch 7554 - loss: 0.5502782464027405\n",
      "Batch 7555 - loss: 0.5185235142707825\n",
      "Batch 7556 - loss: 0.5025373101234436\n",
      "Batch 7557 - loss: 0.490817666053772\n",
      "Batch 7558 - loss: 0.4848023056983948\n",
      "Batch 7559 - loss: 0.5969346761703491\n",
      "Batch 7560 - loss: 0.4700538218021393\n",
      "Batch 7561 - loss: 0.495105117559433\n",
      "Batch 7562 - loss: 0.516298770904541\n",
      "Batch 7563 - loss: 0.43177610635757446\n",
      "Batch 7564 - loss: 0.5404281616210938\n",
      "Batch 7565 - loss: 0.49102291464805603\n",
      "Batch 7566 - loss: 0.5276076197624207\n",
      "Batch 7567 - loss: 0.508552610874176\n",
      "Batch 7568 - loss: 0.5123147964477539\n",
      "Batch 7569 - loss: 0.4868345260620117\n",
      "Batch 7570 - loss: 0.5320391058921814\n",
      "Batch 7571 - loss: 0.4487064480781555\n",
      "Batch 7572 - loss: 0.4961690306663513\n",
      "Batch 7573 - loss: 0.5653551816940308\n",
      "Batch 7574 - loss: 0.5038082599639893\n",
      "Batch 7575 - loss: 0.500124454498291\n",
      "Batch 7576 - loss: 0.4846194088459015\n",
      "Batch 7577 - loss: 0.48237645626068115\n",
      "Batch 7578 - loss: 0.5515879392623901\n",
      "Batch 7579 - loss: 0.5815158486366272\n",
      "Batch 7580 - loss: 0.5090267062187195\n",
      "Batch 7581 - loss: 0.5683072209358215\n",
      "Batch 7582 - loss: 0.5209759473800659\n",
      "Batch 7583 - loss: 0.4611726999282837\n",
      "Batch 7584 - loss: 0.5459862947463989\n",
      "Batch 7585 - loss: 0.5150863528251648\n",
      "Batch 7586 - loss: 0.5046468377113342\n",
      "Batch 7587 - loss: 0.5447601675987244\n",
      "Batch 7588 - loss: 0.5239095687866211\n",
      "Batch 7589 - loss: 0.556505024433136\n",
      "Batch 7590 - loss: 0.5214656591415405\n",
      "Batch 7591 - loss: 0.4704691171646118\n",
      "Batch 7592 - loss: 0.5009053349494934\n",
      "Batch 7593 - loss: 0.48392704129219055\n",
      "Batch 7594 - loss: 0.5299692153930664\n",
      "Batch 7595 - loss: 0.502170979976654\n",
      "Batch 7596 - loss: 0.5069741010665894\n",
      "Batch 7597 - loss: 0.49809369444847107\n",
      "Batch 7598 - loss: 0.5012168288230896\n",
      "Batch 7599 - loss: 0.532574474811554\n",
      "Batch 7600 - loss: 0.5254193544387817\n",
      "Batch 7601 - loss: 0.468458354473114\n",
      "Batch 7602 - loss: 0.49582794308662415\n",
      "Batch 7603 - loss: 0.4832516312599182\n",
      "Batch 7604 - loss: 0.5404144525527954\n",
      "Batch 7605 - loss: 0.5743066072463989\n",
      "Batch 7606 - loss: 0.6208436489105225\n",
      "Batch 7607 - loss: 0.45264291763305664\n",
      "Batch 7608 - loss: 0.5402399301528931\n",
      "Batch 7609 - loss: 0.4682619869709015\n",
      "Batch 7610 - loss: 0.5360273122787476\n",
      "Batch 7611 - loss: 0.5047018527984619\n",
      "Batch 7612 - loss: 0.5053761005401611\n",
      "Batch 7613 - loss: 0.5235303640365601\n",
      "Batch 7614 - loss: 0.5184863209724426\n",
      "Batch 7615 - loss: 0.4995281398296356\n",
      "Batch 7616 - loss: 0.5850400328636169\n",
      "Batch 7617 - loss: 0.5788174867630005\n",
      "Batch 7618 - loss: 0.48883751034736633\n",
      "Batch 7619 - loss: 0.5086064338684082\n",
      "Batch 7620 - loss: 0.5285807847976685\n",
      "Batch 7621 - loss: 0.49386876821517944\n",
      "Batch 7622 - loss: 0.4847428798675537\n",
      "Batch 7623 - loss: 0.5208940505981445\n",
      "Batch 7624 - loss: 0.4654809236526489\n",
      "Batch 7625 - loss: 0.5153574347496033\n",
      "Batch 7626 - loss: 0.5697949528694153\n",
      "Batch 7627 - loss: 0.5385558605194092\n",
      "Batch 7628 - loss: 0.5041734576225281\n",
      "Batch 7629 - loss: 0.462007999420166\n",
      "Batch 7630 - loss: 0.5417824387550354\n",
      "Batch 7631 - loss: 0.538538932800293\n",
      "Batch 7632 - loss: 0.47486695647239685\n",
      "Batch 7633 - loss: 0.4603740870952606\n",
      "Batch 7634 - loss: 0.6210933923721313\n",
      "Batch 7635 - loss: 0.511501133441925\n",
      "Batch 7636 - loss: 0.4900445342063904\n",
      "Batch 7637 - loss: 0.48337772488594055\n",
      "Batch 7638 - loss: 0.49515944719314575\n",
      "Batch 7639 - loss: 0.5617329478263855\n",
      "Batch 7640 - loss: 0.5370206236839294\n",
      "Batch 7641 - loss: 0.49761536717414856\n",
      "Batch 7642 - loss: 0.5225679874420166\n",
      "Batch 7643 - loss: 0.5612014532089233\n",
      "Batch 7644 - loss: 0.5279566049575806\n",
      "Batch 7645 - loss: 0.4867391288280487\n",
      "Batch 7646 - loss: 0.4309552013874054\n",
      "Batch 7647 - loss: 0.5232939124107361\n",
      "Batch 7648 - loss: 0.448665976524353\n",
      "Batch 7649 - loss: 0.4765879213809967\n",
      "Batch 7650 - loss: 0.4979524612426758\n",
      "Batch 7651 - loss: 0.5571399331092834\n",
      "Batch 7652 - loss: 0.5381290316581726\n",
      "Batch 7653 - loss: 0.5137893557548523\n",
      "Batch 7654 - loss: 0.5055530667304993\n",
      "Batch 7655 - loss: 0.48200327157974243\n",
      "Batch 7656 - loss: 0.5363430976867676\n",
      "Batch 7657 - loss: 0.4731404483318329\n",
      "Batch 7658 - loss: 0.4608214199542999\n",
      "Batch 7659 - loss: 0.47931793332099915\n",
      "Batch 7660 - loss: 0.4718354642391205\n",
      "Batch 7661 - loss: 0.5495513677597046\n",
      "Batch 7662 - loss: 0.5351132750511169\n",
      "Batch 7663 - loss: 0.5476369261741638\n",
      "Batch 7664 - loss: 0.5213214755058289\n",
      "Batch 7665 - loss: 0.5576727390289307\n",
      "Batch 7666 - loss: 0.5298064351081848\n",
      "Batch 7667 - loss: 0.4796036183834076\n",
      "Batch 7668 - loss: 0.4819070100784302\n",
      "Batch 7669 - loss: 0.4921768009662628\n",
      "Batch 7670 - loss: 0.5711491107940674\n",
      "Batch 7671 - loss: 0.5606163144111633\n",
      "Batch 7672 - loss: 0.4523014426231384\n",
      "Batch 7673 - loss: 0.5069587230682373\n",
      "Batch 7674 - loss: 0.48907729983329773\n",
      "Batch 7675 - loss: 0.540393054485321\n",
      "Batch 7676 - loss: 0.5076239109039307\n",
      "Batch 7677 - loss: 0.4997299015522003\n",
      "Batch 7678 - loss: 0.5125232934951782\n",
      "Batch 7679 - loss: 0.5017520189285278\n",
      "Batch 7680 - loss: 0.504101037979126\n",
      "Batch 7681 - loss: 0.5072677135467529\n",
      "Batch 7682 - loss: 0.5231820344924927\n",
      "Batch 7683 - loss: 0.5288581252098083\n",
      "Batch 7684 - loss: 0.5346223711967468\n",
      "Batch 7685 - loss: 0.5223363637924194\n",
      "Batch 7686 - loss: 0.42852094769477844\n",
      "Batch 7687 - loss: 0.520906388759613\n",
      "Batch 7688 - loss: 0.5141275525093079\n",
      "Batch 7689 - loss: 0.42659178376197815\n",
      "Batch 7690 - loss: 0.5374213457107544\n",
      "Batch 7691 - loss: 0.4738835096359253\n",
      "Batch 7692 - loss: 0.46739107370376587\n",
      "Batch 7693 - loss: 0.5348982214927673\n",
      "Batch 7694 - loss: 0.48319846391677856\n",
      "Batch 7695 - loss: 0.4805261790752411\n",
      "Batch 7696 - loss: 0.5042320489883423\n",
      "Batch 7697 - loss: 0.5530067682266235\n",
      "Batch 7698 - loss: 0.5080997943878174\n",
      "Batch 7699 - loss: 0.4899817705154419\n",
      "Batch 7700 - loss: 0.5429185628890991\n",
      "Batch 7701 - loss: 0.5832536220550537\n",
      "Batch 7702 - loss: 0.5179259777069092\n",
      "Batch 7703 - loss: 0.44399815797805786\n",
      "Batch 7704 - loss: 0.548590362071991\n",
      "Batch 7705 - loss: 0.49559199810028076\n",
      "Batch 7706 - loss: 0.5721733570098877\n",
      "Batch 7707 - loss: 0.5280598402023315\n",
      "Batch 7708 - loss: 0.5354036688804626\n",
      "Batch 7709 - loss: 0.46560829877853394\n",
      "Batch 7710 - loss: 0.5369752049446106\n",
      "Batch 7711 - loss: 0.5223711133003235\n",
      "Batch 7712 - loss: 0.5572121739387512\n",
      "Batch 7713 - loss: 0.5062140822410583\n",
      "Batch 7714 - loss: 0.5658925771713257\n",
      "Batch 7715 - loss: 0.5372684597969055\n",
      "Batch 7716 - loss: 0.49750185012817383\n",
      "Batch 7717 - loss: 0.5130903124809265\n",
      "Batch 7718 - loss: 0.43173056840896606\n",
      "Batch 7719 - loss: 0.5610916018486023\n",
      "Batch 7720 - loss: 0.5277438759803772\n",
      "Batch 7721 - loss: 0.5376315712928772\n",
      "Batch 7722 - loss: 0.4763854742050171\n",
      "Batch 7723 - loss: 0.5448855757713318\n",
      "Batch 7724 - loss: 0.5429348945617676\n",
      "Batch 7725 - loss: 0.5422160625457764\n",
      "Batch 7726 - loss: 0.5569522380828857\n",
      "Batch 7727 - loss: 0.5295827388763428\n",
      "Batch 7728 - loss: 0.47899144887924194\n",
      "Batch 7729 - loss: 0.5341593027114868\n",
      "Batch 7730 - loss: 0.49377599358558655\n",
      "Batch 7731 - loss: 0.5148748159408569\n",
      "Batch 7732 - loss: 0.48654913902282715\n",
      "Batch 7733 - loss: 0.459219366312027\n",
      "Batch 7734 - loss: 0.49248287081718445\n",
      "Batch 7735 - loss: 0.572655200958252\n",
      "Batch 7736 - loss: 0.5354373455047607\n",
      "Batch 7737 - loss: 0.4943888187408447\n",
      "Batch 7738 - loss: 0.5676149129867554\n",
      "Batch 7739 - loss: 0.5216629505157471\n",
      "Batch 7740 - loss: 0.5009157061576843\n",
      "Batch 7741 - loss: 0.5275208950042725\n",
      "Batch 7742 - loss: 0.4701194763183594\n",
      "Batch 7743 - loss: 0.5445260405540466\n",
      "Batch 7744 - loss: 0.5653514266014099\n",
      "Batch 7745 - loss: 0.4993194341659546\n",
      "Batch 7746 - loss: 0.5052179098129272\n",
      "Batch 7747 - loss: 0.5312650203704834\n",
      "Batch 7748 - loss: 0.5780054330825806\n",
      "Batch 7749 - loss: 0.5128675699234009\n",
      "Batch 7750 - loss: 0.44357195496559143\n",
      "Batch 7751 - loss: 0.524895966053009\n",
      "Batch 7752 - loss: 0.4751729965209961\n",
      "Batch 7753 - loss: 0.5152571797370911\n",
      "Batch 7754 - loss: 0.5439608693122864\n",
      "Batch 7755 - loss: 0.4702944755554199\n",
      "Batch 7756 - loss: 0.4989174008369446\n",
      "Batch 7757 - loss: 0.4689377546310425\n",
      "Batch 7758 - loss: 0.5338348746299744\n",
      "Batch 7759 - loss: 0.5199202299118042\n",
      "Batch 7760 - loss: 0.4811291992664337\n",
      "Batch 7761 - loss: 0.5341910719871521\n",
      "Batch 7762 - loss: 0.4825948178768158\n",
      "Batch 7763 - loss: 0.5567154884338379\n",
      "Batch 7764 - loss: 0.4936178922653198\n",
      "Batch 7765 - loss: 0.4970236122608185\n",
      "Batch 7766 - loss: 0.45901089906692505\n",
      "Batch 7767 - loss: 0.5237064361572266\n",
      "Batch 7768 - loss: 0.514353334903717\n",
      "Batch 7769 - loss: 0.4793597161769867\n",
      "Batch 7770 - loss: 0.5029019713401794\n",
      "Batch 7771 - loss: 0.5241870284080505\n",
      "Batch 7772 - loss: 0.4924424886703491\n",
      "Batch 7773 - loss: 0.48655423521995544\n",
      "Batch 7774 - loss: 0.4774284362792969\n",
      "Batch 7775 - loss: 0.4857533574104309\n",
      "Batch 7776 - loss: 0.49834179878234863\n",
      "Batch 7777 - loss: 0.46545347571372986\n",
      "Batch 7778 - loss: 0.500074028968811\n",
      "Batch 7779 - loss: 0.4593755900859833\n",
      "Batch 7780 - loss: 0.5095428824424744\n",
      "Batch 7781 - loss: 0.43846848607063293\n",
      "Batch 7782 - loss: 0.5352781414985657\n",
      "Batch 7783 - loss: 0.5073540806770325\n",
      "Batch 7784 - loss: 0.45429179072380066\n",
      "Batch 7785 - loss: 0.48983126878738403\n",
      "Batch 7786 - loss: 0.4787529408931732\n",
      "Batch 7787 - loss: 0.533374011516571\n",
      "Batch 7788 - loss: 0.5152533650398254\n",
      "Batch 7789 - loss: 0.5280952453613281\n",
      "Batch 7790 - loss: 0.5309492349624634\n",
      "Batch 7791 - loss: 0.4521748721599579\n",
      "Batch 7792 - loss: 0.638645589351654\n",
      "Batch 7793 - loss: 0.5078805685043335\n",
      "Batch 7794 - loss: 0.41282033920288086\n",
      "Batch 7795 - loss: 0.5662505626678467\n",
      "Batch 7796 - loss: 0.5271932482719421\n",
      "Batch 7797 - loss: 0.546364426612854\n",
      "Batch 7798 - loss: 0.5067814588546753\n",
      "Batch 7799 - loss: 0.48563912510871887\n",
      "Batch 7800 - loss: 0.5818904638290405\n",
      "Batch 7801 - loss: 0.4523611068725586\n",
      "Batch 7802 - loss: 0.5063136219978333\n",
      "Batch 7803 - loss: 0.49884718656539917\n",
      "Batch 7804 - loss: 0.540981113910675\n",
      "Batch 7805 - loss: 0.5838673114776611\n",
      "Batch 7806 - loss: 0.514288067817688\n",
      "Batch 7807 - loss: 0.5075353384017944\n",
      "Batch 7808 - loss: 0.5054882168769836\n",
      "Batch 7809 - loss: 0.49285659193992615\n",
      "Batch 7810 - loss: 0.5325676202774048\n",
      "Batch 7811 - loss: 0.5335921049118042\n",
      "Batch 7812 - loss: 0.5309702157974243\n",
      "Batch 7813 - loss: 0.49617999792099\n",
      "Batch 7814 - loss: 0.5167949199676514\n",
      "Batch 7815 - loss: 0.5472858548164368\n",
      "Batch 7816 - loss: 0.5017586946487427\n",
      "Batch 7817 - loss: 0.5194072127342224\n",
      "Batch 7818 - loss: 0.48311060667037964\n",
      "Batch 7819 - loss: 0.4997435212135315\n",
      "Batch 7820 - loss: 0.5771575570106506\n",
      "Batch 7821 - loss: 0.5876093506813049\n",
      "Batch 7822 - loss: 0.5048484206199646\n",
      "Batch 7823 - loss: 0.4822375178337097\n",
      "Batch 7824 - loss: 0.44444936513900757\n",
      "Batch 7825 - loss: 0.47110715508461\n",
      "Batch 7826 - loss: 0.522831916809082\n",
      "Batch 7827 - loss: 0.4578218460083008\n",
      "Batch 7828 - loss: 0.5140687227249146\n",
      "Batch 7829 - loss: 0.47807204723358154\n",
      "Batch 7830 - loss: 0.5638737082481384\n",
      "Batch 7831 - loss: 0.564969539642334\n",
      "Batch 7832 - loss: 0.507267951965332\n",
      "Batch 7833 - loss: 0.5636864304542542\n",
      "Batch 7834 - loss: 0.47113069891929626\n",
      "Batch 7835 - loss: 0.5177919864654541\n",
      "Batch 7836 - loss: 0.5446577072143555\n",
      "Batch 7837 - loss: 0.5558062791824341\n",
      "Batch 7838 - loss: 0.5136176347732544\n",
      "Batch 7839 - loss: 0.49129927158355713\n",
      "Batch 7840 - loss: 0.508272111415863\n",
      "Batch 7841 - loss: 0.5529094934463501\n",
      "Batch 7842 - loss: 0.5061648488044739\n",
      "Batch 7843 - loss: 0.5609194040298462\n",
      "Batch 7844 - loss: 0.48142316937446594\n",
      "Batch 7845 - loss: 0.452767938375473\n",
      "Batch 7846 - loss: 0.4946347773075104\n",
      "Batch 7847 - loss: 0.5316123962402344\n",
      "Batch 7848 - loss: 0.5616651177406311\n",
      "Batch 7849 - loss: 0.5007675290107727\n",
      "Batch 7850 - loss: 0.4753826856613159\n",
      "Batch 7851 - loss: 0.5089641213417053\n",
      "Batch 7852 - loss: 0.506101667881012\n",
      "Batch 7853 - loss: 0.541887104511261\n",
      "Batch 7854 - loss: 0.5006440281867981\n",
      "Batch 7855 - loss: 0.4973272979259491\n",
      "Batch 7856 - loss: 0.508659303188324\n",
      "Batch 7857 - loss: 0.5876399874687195\n",
      "Batch 7858 - loss: 0.5706894993782043\n",
      "Batch 7859 - loss: 0.5305270552635193\n",
      "Batch 7860 - loss: 0.49789750576019287\n",
      "Batch 7861 - loss: 0.48234182596206665\n",
      "Batch 7862 - loss: 0.4847157597541809\n",
      "Batch 7863 - loss: 0.45405808091163635\n",
      "Batch 7864 - loss: 0.6067038178443909\n",
      "Batch 7865 - loss: 0.5686265826225281\n",
      "Batch 7866 - loss: 0.5164410471916199\n",
      "Batch 7867 - loss: 0.47913503646850586\n",
      "Batch 7868 - loss: 0.5258626937866211\n",
      "Batch 7869 - loss: 0.5245425701141357\n",
      "Batch 7870 - loss: 0.4500124752521515\n",
      "Batch 7871 - loss: 0.517209529876709\n",
      "Batch 7872 - loss: 0.5486387610435486\n",
      "Batch 7873 - loss: 0.5117735862731934\n",
      "Batch 7874 - loss: 0.4823685586452484\n",
      "Batch 7875 - loss: 0.46995314955711365\n",
      "Batch 7876 - loss: 0.49788710474967957\n",
      "Batch 7877 - loss: 0.5421903729438782\n",
      "Batch 7878 - loss: 0.5376534461975098\n",
      "Batch 7879 - loss: 0.6249071359634399\n",
      "Batch 7880 - loss: 0.5576852560043335\n",
      "Batch 7881 - loss: 0.48762354254722595\n",
      "Batch 7882 - loss: 0.5606707334518433\n",
      "Batch 7883 - loss: 0.4681093394756317\n",
      "Batch 7884 - loss: 0.5097893476486206\n",
      "Batch 7885 - loss: 0.5382998585700989\n",
      "Batch 7886 - loss: 0.5223029255867004\n",
      "Batch 7887 - loss: 0.5597012639045715\n",
      "Batch 7888 - loss: 0.5938446521759033\n",
      "Batch 7889 - loss: 0.5055139660835266\n",
      "Batch 7890 - loss: 0.48383796215057373\n",
      "Batch 7891 - loss: 0.46764957904815674\n",
      "Batch 7892 - loss: 0.5123929381370544\n",
      "Batch 7893 - loss: 0.4903953969478607\n",
      "Batch 7894 - loss: 0.5208367705345154\n",
      "Batch 7895 - loss: 0.4698389172554016\n",
      "Batch 7896 - loss: 0.4568142592906952\n",
      "Batch 7897 - loss: 0.49439072608947754\n",
      "Batch 7898 - loss: 0.5039576292037964\n",
      "Batch 7899 - loss: 0.4847344756126404\n",
      "Batch 7900 - loss: 0.5725354552268982\n",
      "Batch 7901 - loss: 0.5587876439094543\n",
      "Batch 7902 - loss: 0.5604755878448486\n",
      "Batch 7903 - loss: 0.48070815205574036\n",
      "Batch 7904 - loss: 0.5228413343429565\n",
      "Batch 7905 - loss: 0.5048683881759644\n",
      "Batch 7906 - loss: 0.5241092443466187\n",
      "Batch 7907 - loss: 0.5672606229782104\n",
      "Batch 7908 - loss: 0.4850841164588928\n",
      "Batch 7909 - loss: 0.5158957839012146\n",
      "Batch 7910 - loss: 0.5560159087181091\n",
      "Batch 7911 - loss: 0.47949570417404175\n",
      "Batch 7912 - loss: 0.4655870497226715\n",
      "Batch 7913 - loss: 0.514897882938385\n",
      "Batch 7914 - loss: 0.5440331697463989\n",
      "Batch 7915 - loss: 0.5639947652816772\n",
      "Batch 7916 - loss: 0.470969021320343\n",
      "Batch 7917 - loss: 0.5355232357978821\n",
      "Batch 7918 - loss: 0.5369181036949158\n",
      "Batch 7919 - loss: 0.5029460191726685\n",
      "Batch 7920 - loss: 0.5396002531051636\n",
      "Batch 7921 - loss: 0.47654372453689575\n",
      "Batch 7922 - loss: 0.47764700651168823\n",
      "Batch 7923 - loss: 0.4924904704093933\n",
      "Batch 7924 - loss: 0.5000380873680115\n",
      "Batch 7925 - loss: 0.6069851517677307\n",
      "Batch 7926 - loss: 0.5271903276443481\n",
      "Batch 7927 - loss: 0.5457578301429749\n",
      "Batch 7928 - loss: 0.539192795753479\n",
      "Batch 7929 - loss: 0.49696338176727295\n",
      "Batch 7930 - loss: 0.4792843163013458\n",
      "Batch 7931 - loss: 0.52001953125\n",
      "Batch 7932 - loss: 0.5883911848068237\n",
      "Batch 7933 - loss: 0.5161468982696533\n",
      "Batch 7934 - loss: 0.4726816713809967\n",
      "Batch 7935 - loss: 0.5215408205986023\n",
      "Batch 7936 - loss: 0.5302496552467346\n",
      "Batch 7937 - loss: 0.5370332598686218\n",
      "Batch 7938 - loss: 0.46398529410362244\n",
      "Batch 7939 - loss: 0.5182144045829773\n",
      "Batch 0 - loss: 0.46873170137405396\n",
      "Batch 1 - loss: 0.5109956860542297\n",
      "Batch 2 - loss: 0.5516843199729919\n",
      "Batch 3 - loss: 0.5051245093345642\n",
      "Batch 4 - loss: 0.5240659713745117\n",
      "Batch 5 - loss: 0.5125250816345215\n",
      "Batch 6 - loss: 0.5231495499610901\n",
      "Batch 7 - loss: 0.5238989591598511\n",
      "Batch 8 - loss: 0.5165398716926575\n",
      "Batch 9 - loss: 0.482519268989563\n",
      "Batch 10 - loss: 0.5393201112747192\n",
      "Batch 11 - loss: 0.4841797649860382\n",
      "Batch 12 - loss: 0.5445327162742615\n",
      "Batch 13 - loss: 0.528336226940155\n",
      "Batch 14 - loss: 0.5411672592163086\n",
      "Batch 15 - loss: 0.5387470722198486\n",
      "Batch 16 - loss: 0.44040510058403015\n",
      "Batch 17 - loss: 0.5111070275306702\n",
      "Batch 18 - loss: 0.5223267078399658\n",
      "Batch 19 - loss: 0.5516642332077026\n",
      "Batch 20 - loss: 0.5282332301139832\n",
      "Batch 21 - loss: 0.47014015913009644\n",
      "Batch 22 - loss: 0.533492922782898\n",
      "Batch 23 - loss: 0.5325808525085449\n",
      "Batch 24 - loss: 0.5018388628959656\n",
      "Batch 25 - loss: 0.501943051815033\n",
      "Batch 26 - loss: 0.5360395312309265\n",
      "Batch 27 - loss: 0.4871029853820801\n",
      "Batch 28 - loss: 0.5411569476127625\n",
      "Batch 29 - loss: 0.45560315251350403\n",
      "Batch 30 - loss: 0.4742528796195984\n",
      "Batch 31 - loss: 0.48625898361206055\n",
      "Batch 32 - loss: 0.4913688600063324\n",
      "Batch 33 - loss: 0.5219410061836243\n",
      "Batch 34 - loss: 0.4403301179409027\n",
      "Batch 35 - loss: 0.5670431852340698\n",
      "Batch 36 - loss: 0.5385721921920776\n",
      "Batch 37 - loss: 0.4952281713485718\n",
      "Batch 38 - loss: 0.5593951344490051\n",
      "Batch 39 - loss: 0.5195382833480835\n",
      "Batch 40 - loss: 0.4936842620372772\n",
      "Batch 41 - loss: 0.5513367056846619\n",
      "Batch 42 - loss: 0.49769583344459534\n",
      "Batch 43 - loss: 0.5184677243232727\n",
      "Batch 44 - loss: 0.5108489394187927\n",
      "Batch 45 - loss: 0.48279374837875366\n",
      "Batch 46 - loss: 0.5172701478004456\n",
      "Batch 47 - loss: 0.46919935941696167\n",
      "Batch 48 - loss: 0.5411187410354614\n",
      "Batch 49 - loss: 0.49785417318344116\n",
      "Batch 50 - loss: 0.47365617752075195\n",
      "Batch 51 - loss: 0.5581974983215332\n",
      "Batch 52 - loss: 0.5911550521850586\n",
      "Batch 53 - loss: 0.5302692651748657\n",
      "Batch 54 - loss: 0.47431886196136475\n",
      "Batch 55 - loss: 0.5534915924072266\n",
      "Batch 56 - loss: 0.5142708420753479\n",
      "Batch 57 - loss: 0.4605705142021179\n",
      "Batch 58 - loss: 0.5161296129226685\n",
      "Batch 59 - loss: 0.49169921875\n",
      "Batch 60 - loss: 0.5157851576805115\n",
      "Batch 61 - loss: 0.5106621384620667\n",
      "Batch 62 - loss: 0.5493865609169006\n",
      "Batch 63 - loss: 0.48533111810684204\n",
      "Batch 64 - loss: 0.4841531813144684\n",
      "Batch 65 - loss: 0.5233019590377808\n",
      "Batch 66 - loss: 0.5373588800430298\n",
      "Batch 67 - loss: 0.48180893063545227\n",
      "Batch 68 - loss: 0.5144854784011841\n",
      "Batch 69 - loss: 0.5022582411766052\n",
      "Batch 70 - loss: 0.5485552549362183\n",
      "Batch 71 - loss: 0.5017582178115845\n",
      "Batch 72 - loss: 0.5718283653259277\n",
      "Batch 73 - loss: 0.5571926832199097\n",
      "Batch 74 - loss: 0.5026577711105347\n",
      "Batch 75 - loss: 0.45926380157470703\n",
      "Batch 76 - loss: 0.5018109083175659\n",
      "Batch 77 - loss: 0.5704807639122009\n",
      "Batch 78 - loss: 0.5301662087440491\n",
      "Batch 79 - loss: 0.5155335664749146\n",
      "Batch 80 - loss: 0.51567143201828\n",
      "Batch 81 - loss: 0.5243422985076904\n",
      "Batch 82 - loss: 0.48472559452056885\n",
      "Batch 83 - loss: 0.4850657284259796\n",
      "Batch 84 - loss: 0.4716034233570099\n",
      "Batch 85 - loss: 0.5538947582244873\n",
      "Batch 86 - loss: 0.43438541889190674\n",
      "Batch 87 - loss: 0.5396239161491394\n",
      "Batch 88 - loss: 0.5184396505355835\n",
      "Batch 89 - loss: 0.49872609972953796\n",
      "Batch 90 - loss: 0.5025468468666077\n",
      "Batch 91 - loss: 0.5018284320831299\n",
      "Batch 92 - loss: 0.5006637573242188\n",
      "Batch 93 - loss: 0.5948960185050964\n",
      "Batch 94 - loss: 0.4890531003475189\n",
      "Batch 95 - loss: 0.48398861289024353\n",
      "Batch 96 - loss: 0.517733097076416\n",
      "Batch 97 - loss: 0.49623891711235046\n",
      "Batch 98 - loss: 0.47379425168037415\n",
      "Batch 99 - loss: 0.5308129787445068\n",
      "Batch 100 - loss: 0.5164629817008972\n",
      "Batch 101 - loss: 0.5200493335723877\n",
      "Batch 102 - loss: 0.5406864881515503\n",
      "Batch 103 - loss: 0.4558793008327484\n",
      "Batch 104 - loss: 0.46539372205734253\n",
      "Batch 105 - loss: 0.49047333002090454\n",
      "Batch 106 - loss: 0.5082272291183472\n",
      "Batch 107 - loss: 0.5420148968696594\n",
      "Batch 108 - loss: 0.5002008080482483\n",
      "Batch 109 - loss: 0.46569401025772095\n",
      "Batch 110 - loss: 0.5297483801841736\n",
      "Batch 111 - loss: 0.5444183945655823\n",
      "Batch 112 - loss: 0.5835769176483154\n",
      "Batch 113 - loss: 0.5041463971138\n",
      "Batch 114 - loss: 0.4714607894420624\n",
      "Batch 115 - loss: 0.5318430066108704\n",
      "Batch 116 - loss: 0.5013464689254761\n",
      "Batch 117 - loss: 0.5070644617080688\n",
      "Batch 118 - loss: 0.4946710467338562\n",
      "Batch 119 - loss: 0.4813860058784485\n",
      "Batch 120 - loss: 0.5094349384307861\n",
      "Batch 121 - loss: 0.5173292756080627\n",
      "Batch 122 - loss: 0.5062570571899414\n",
      "Batch 123 - loss: 0.4868466258049011\n",
      "Batch 124 - loss: 0.5428277254104614\n",
      "Batch 125 - loss: 0.520850658416748\n",
      "Batch 126 - loss: 0.5165727734565735\n",
      "Batch 127 - loss: 0.5226677656173706\n",
      "Batch 128 - loss: 0.5263440608978271\n",
      "Batch 129 - loss: 0.5017877221107483\n",
      "Batch 130 - loss: 0.5115103721618652\n",
      "Batch 131 - loss: 0.5514540672302246\n",
      "Batch 132 - loss: 0.6092240214347839\n",
      "Batch 133 - loss: 0.4930771589279175\n",
      "Batch 134 - loss: 0.5360609889030457\n",
      "Batch 135 - loss: 0.5107086300849915\n",
      "Batch 136 - loss: 0.5072183609008789\n",
      "Batch 137 - loss: 0.4930879473686218\n",
      "Batch 138 - loss: 0.5271289348602295\n",
      "Batch 139 - loss: 0.49416863918304443\n",
      "Batch 140 - loss: 0.5090130567550659\n",
      "Batch 141 - loss: 0.45704343914985657\n",
      "Batch 142 - loss: 0.5295165777206421\n",
      "Batch 143 - loss: 0.4751591682434082\n",
      "Batch 144 - loss: 0.4977206587791443\n",
      "Batch 145 - loss: 0.5384292602539062\n",
      "Batch 146 - loss: 0.4948073625564575\n",
      "Batch 147 - loss: 0.545740008354187\n",
      "Batch 148 - loss: 0.4855101406574249\n",
      "Batch 149 - loss: 0.4613805413246155\n",
      "Batch 150 - loss: 0.5225078463554382\n",
      "Batch 151 - loss: 0.49199649691581726\n",
      "Batch 152 - loss: 0.4928329288959503\n",
      "Batch 153 - loss: 0.5064142346382141\n",
      "Batch 154 - loss: 0.5095444321632385\n",
      "Batch 155 - loss: 0.4992917776107788\n",
      "Batch 156 - loss: 0.48437821865081787\n",
      "Batch 157 - loss: 0.5102867484092712\n",
      "Batch 158 - loss: 0.43504562973976135\n",
      "Batch 159 - loss: 0.4598657786846161\n",
      "Batch 160 - loss: 0.5120428204536438\n",
      "Batch 161 - loss: 0.5113446116447449\n",
      "Batch 162 - loss: 0.5264095664024353\n",
      "Batch 163 - loss: 0.5375673770904541\n",
      "Batch 164 - loss: 0.5275140404701233\n",
      "Batch 165 - loss: 0.44020789861679077\n",
      "Batch 166 - loss: 0.5171557068824768\n",
      "Batch 167 - loss: 0.5018165707588196\n",
      "Batch 168 - loss: 0.5312944054603577\n",
      "Batch 169 - loss: 0.5604438781738281\n",
      "Batch 170 - loss: 0.4879576563835144\n",
      "Batch 171 - loss: 0.5302346348762512\n",
      "Batch 172 - loss: 0.4723280966281891\n",
      "Batch 173 - loss: 0.46905219554901123\n",
      "Batch 174 - loss: 0.5565838813781738\n",
      "Batch 175 - loss: 0.5211240649223328\n",
      "Batch 176 - loss: 0.527679443359375\n",
      "Batch 177 - loss: 0.5006445050239563\n",
      "Batch 178 - loss: 0.49550291895866394\n",
      "Batch 179 - loss: 0.4701528251171112\n",
      "Batch 180 - loss: 0.43652090430259705\n",
      "Batch 181 - loss: 0.45611584186553955\n",
      "Batch 182 - loss: 0.5263134837150574\n",
      "Batch 183 - loss: 0.45698946714401245\n",
      "Batch 184 - loss: 0.5463736057281494\n",
      "Batch 185 - loss: 0.4756067991256714\n",
      "Batch 186 - loss: 0.480827659368515\n",
      "Batch 187 - loss: 0.504983127117157\n",
      "Batch 188 - loss: 0.43523669242858887\n",
      "Batch 189 - loss: 0.5097350478172302\n",
      "Batch 190 - loss: 0.47883033752441406\n",
      "Batch 191 - loss: 0.45788806676864624\n",
      "Batch 192 - loss: 0.5559860467910767\n",
      "Batch 193 - loss: 0.4571077525615692\n",
      "Batch 194 - loss: 0.48529207706451416\n",
      "Batch 195 - loss: 0.5277349948883057\n",
      "Batch 196 - loss: 0.5353114604949951\n",
      "Batch 197 - loss: 0.5287466645240784\n",
      "Batch 198 - loss: 0.4828205704689026\n",
      "Batch 199 - loss: 0.5062318444252014\n",
      "Batch 200 - loss: 0.482061505317688\n",
      "Batch 201 - loss: 0.4595036506652832\n",
      "Batch 202 - loss: 0.530211329460144\n",
      "Batch 203 - loss: 0.4528532028198242\n",
      "Batch 204 - loss: 0.47908735275268555\n",
      "Batch 205 - loss: 0.4895171523094177\n",
      "Batch 206 - loss: 0.5710188150405884\n",
      "Batch 207 - loss: 0.5042312741279602\n",
      "Batch 208 - loss: 0.46543946862220764\n",
      "Batch 209 - loss: 0.5049027800559998\n",
      "Batch 210 - loss: 0.5653258562088013\n",
      "Batch 211 - loss: 0.5048711895942688\n",
      "Batch 212 - loss: 0.5761627554893494\n",
      "Batch 213 - loss: 0.5537068843841553\n",
      "Batch 214 - loss: 0.4980391263961792\n",
      "Batch 215 - loss: 0.45169612765312195\n",
      "Batch 216 - loss: 0.5004380941390991\n",
      "Batch 217 - loss: 0.4971183240413666\n",
      "Batch 218 - loss: 0.4548276662826538\n",
      "Batch 219 - loss: 0.4847446382045746\n",
      "Batch 220 - loss: 0.548883318901062\n",
      "Batch 221 - loss: 0.5125987529754639\n",
      "Batch 222 - loss: 0.4830545485019684\n",
      "Batch 223 - loss: 0.4715498685836792\n",
      "Batch 224 - loss: 0.5347678661346436\n",
      "Batch 225 - loss: 0.5025948882102966\n",
      "Batch 226 - loss: 0.5149458050727844\n",
      "Batch 227 - loss: 0.5183994174003601\n",
      "Batch 228 - loss: 0.5992712378501892\n",
      "Batch 229 - loss: 0.5515983700752258\n",
      "Batch 230 - loss: 0.5309034585952759\n",
      "Batch 231 - loss: 0.4629180431365967\n",
      "Batch 232 - loss: 0.4468645453453064\n",
      "Batch 233 - loss: 0.49623045325279236\n",
      "Batch 234 - loss: 0.5075968503952026\n",
      "Batch 235 - loss: 0.5438216328620911\n",
      "Batch 236 - loss: 0.503376305103302\n",
      "Batch 237 - loss: 0.5178432464599609\n",
      "Batch 238 - loss: 0.4877559244632721\n",
      "Batch 239 - loss: 0.5593499541282654\n",
      "Batch 240 - loss: 0.48865991830825806\n",
      "Batch 241 - loss: 0.539674699306488\n",
      "Batch 242 - loss: 0.44994214177131653\n",
      "Batch 243 - loss: 0.4909338355064392\n",
      "Batch 244 - loss: 0.46164533495903015\n",
      "Batch 245 - loss: 0.48879995942115784\n",
      "Batch 246 - loss: 0.4679696261882782\n",
      "Batch 247 - loss: 0.5411210656166077\n",
      "Batch 248 - loss: 0.5276244282722473\n",
      "Batch 249 - loss: 0.49679499864578247\n",
      "Batch 250 - loss: 0.46740907430648804\n",
      "Batch 251 - loss: 0.4763188362121582\n",
      "Batch 252 - loss: 0.48891547322273254\n",
      "Batch 253 - loss: 0.5225470662117004\n",
      "Batch 254 - loss: 0.4764275848865509\n",
      "Batch 255 - loss: 0.5464353561401367\n",
      "Batch 256 - loss: 0.49582967162132263\n",
      "Batch 257 - loss: 0.46993449330329895\n",
      "Batch 258 - loss: 0.49313420057296753\n",
      "Batch 259 - loss: 0.4424668550491333\n",
      "Batch 260 - loss: 0.5554355382919312\n",
      "Batch 261 - loss: 0.518061637878418\n",
      "Batch 262 - loss: 0.47022169828414917\n",
      "Batch 263 - loss: 0.5278159976005554\n",
      "Batch 264 - loss: 0.5717006921768188\n",
      "Batch 265 - loss: 0.49263811111450195\n",
      "Batch 266 - loss: 0.5061947107315063\n",
      "Batch 267 - loss: 0.4889136850833893\n",
      "Batch 268 - loss: 0.5089074373245239\n",
      "Batch 269 - loss: 0.5802043080329895\n",
      "Batch 270 - loss: 0.5197083950042725\n",
      "Batch 271 - loss: 0.5129459500312805\n",
      "Batch 272 - loss: 0.4821617007255554\n",
      "Batch 273 - loss: 0.4716571569442749\n",
      "Batch 274 - loss: 0.5441325306892395\n",
      "Batch 275 - loss: 0.5024230480194092\n",
      "Batch 276 - loss: 0.5348750948905945\n",
      "Batch 277 - loss: 0.5068787932395935\n",
      "Batch 278 - loss: 0.5090809464454651\n",
      "Batch 279 - loss: 0.4721128046512604\n",
      "Batch 280 - loss: 0.4985654652118683\n",
      "Batch 281 - loss: 0.5648304224014282\n",
      "Batch 282 - loss: 0.5192785263061523\n",
      "Batch 283 - loss: 0.5814920663833618\n",
      "Batch 284 - loss: 0.5260204672813416\n",
      "Batch 285 - loss: 0.5084945559501648\n",
      "Batch 286 - loss: 0.4814010560512543\n",
      "Batch 287 - loss: 0.4776851236820221\n",
      "Batch 288 - loss: 0.5254477262496948\n",
      "Batch 289 - loss: 0.5504442453384399\n",
      "Batch 290 - loss: 0.4530543386936188\n",
      "Batch 291 - loss: 0.4984694719314575\n",
      "Batch 292 - loss: 0.5008735656738281\n",
      "Batch 293 - loss: 0.5560098886489868\n",
      "Batch 294 - loss: 0.4857935607433319\n",
      "Batch 295 - loss: 0.505418598651886\n",
      "Batch 296 - loss: 0.5694627165794373\n",
      "Batch 297 - loss: 0.5740581154823303\n",
      "Batch 298 - loss: 0.5166376233100891\n",
      "Batch 299 - loss: 0.5055056810379028\n",
      "Batch 300 - loss: 0.47165167331695557\n",
      "Batch 301 - loss: 0.4846698045730591\n",
      "Batch 302 - loss: 0.5555649399757385\n",
      "Batch 303 - loss: 0.5316766500473022\n",
      "Batch 304 - loss: 0.5648978352546692\n",
      "Batch 305 - loss: 0.5169181227684021\n",
      "Batch 306 - loss: 0.47967472672462463\n",
      "Batch 307 - loss: 0.5254358649253845\n",
      "Batch 308 - loss: 0.5324062705039978\n",
      "Batch 309 - loss: 0.5422842502593994\n",
      "Batch 310 - loss: 0.4989914894104004\n",
      "Batch 311 - loss: 0.5019740462303162\n",
      "Batch 312 - loss: 0.5619207620620728\n",
      "Batch 313 - loss: 0.4769291281700134\n",
      "Batch 314 - loss: 0.5079085230827332\n",
      "Batch 315 - loss: 0.5174063444137573\n",
      "Batch 316 - loss: 0.523374617099762\n",
      "Batch 317 - loss: 0.5031073093414307\n",
      "Batch 318 - loss: 0.5086150169372559\n",
      "Batch 319 - loss: 0.5126750469207764\n",
      "Batch 320 - loss: 0.5256839394569397\n",
      "Batch 321 - loss: 0.5760253071784973\n",
      "Batch 322 - loss: 0.47754761576652527\n",
      "Batch 323 - loss: 0.4978371560573578\n",
      "Batch 324 - loss: 0.5792748332023621\n",
      "Batch 325 - loss: 0.5451259016990662\n",
      "Batch 326 - loss: 0.5120546221733093\n",
      "Batch 327 - loss: 0.47988393902778625\n",
      "Batch 328 - loss: 0.5341311097145081\n",
      "Batch 329 - loss: 0.502474844455719\n",
      "Batch 330 - loss: 0.47180646657943726\n",
      "Batch 331 - loss: 0.5227566361427307\n",
      "Batch 332 - loss: 0.5204951167106628\n",
      "Batch 333 - loss: 0.549018144607544\n",
      "Batch 334 - loss: 0.5114231705665588\n",
      "Batch 335 - loss: 0.5160741209983826\n",
      "Batch 336 - loss: 0.4858384132385254\n",
      "Batch 337 - loss: 0.549115777015686\n",
      "Batch 338 - loss: 0.5497970581054688\n",
      "Batch 339 - loss: 0.4782555103302002\n",
      "Batch 340 - loss: 0.46494758129119873\n",
      "Batch 341 - loss: 0.5697723627090454\n",
      "Batch 342 - loss: 0.4983469545841217\n",
      "Batch 343 - loss: 0.5340603590011597\n",
      "Batch 344 - loss: 0.5057492852210999\n",
      "Batch 345 - loss: 0.4820432960987091\n",
      "Batch 346 - loss: 0.49685245752334595\n",
      "Batch 347 - loss: 0.5213595628738403\n",
      "Batch 348 - loss: 0.4649254083633423\n",
      "Batch 349 - loss: 0.4775177836418152\n",
      "Batch 350 - loss: 0.5561593174934387\n",
      "Batch 351 - loss: 0.5028592944145203\n",
      "Batch 352 - loss: 0.5632750988006592\n",
      "Batch 353 - loss: 0.48784008622169495\n",
      "Batch 354 - loss: 0.4796377718448639\n",
      "Batch 355 - loss: 0.5060235261917114\n",
      "Batch 356 - loss: 0.4718371033668518\n",
      "Batch 357 - loss: 0.47507616877555847\n",
      "Batch 358 - loss: 0.5938289165496826\n",
      "Batch 359 - loss: 0.47259172797203064\n",
      "Batch 360 - loss: 0.5080453157424927\n",
      "Batch 361 - loss: 0.5526260733604431\n",
      "Batch 362 - loss: 0.46443310379981995\n",
      "Batch 363 - loss: 0.488109827041626\n",
      "Batch 364 - loss: 0.5578387975692749\n",
      "Batch 365 - loss: 0.4791620075702667\n",
      "Batch 366 - loss: 0.5636608004570007\n",
      "Batch 367 - loss: 0.49454522132873535\n",
      "Batch 368 - loss: 0.5720581412315369\n",
      "Batch 369 - loss: 0.5021853446960449\n",
      "Batch 370 - loss: 0.46667224168777466\n",
      "Batch 371 - loss: 0.4598028063774109\n",
      "Batch 372 - loss: 0.4770553708076477\n",
      "Batch 373 - loss: 0.4736367166042328\n",
      "Batch 374 - loss: 0.5286231637001038\n",
      "Batch 375 - loss: 0.48735594749450684\n",
      "Batch 376 - loss: 0.48272427916526794\n",
      "Batch 377 - loss: 0.5119736790657043\n",
      "Batch 378 - loss: 0.4657442271709442\n",
      "Batch 379 - loss: 0.47607454657554626\n",
      "Batch 380 - loss: 0.4982718825340271\n",
      "Batch 381 - loss: 0.533824622631073\n",
      "Batch 382 - loss: 0.5352357029914856\n",
      "Batch 383 - loss: 0.5263134241104126\n",
      "Batch 384 - loss: 0.46080631017684937\n",
      "Batch 385 - loss: 0.572466254234314\n",
      "Batch 386 - loss: 0.4917507767677307\n",
      "Batch 387 - loss: 0.5603446960449219\n",
      "Batch 388 - loss: 0.4879121780395508\n",
      "Batch 389 - loss: 0.4894337058067322\n",
      "Batch 390 - loss: 0.5424572825431824\n",
      "Batch 391 - loss: 0.46391308307647705\n",
      "Batch 392 - loss: 0.5342283844947815\n",
      "Batch 393 - loss: 0.487470418214798\n",
      "Batch 394 - loss: 0.5050129294395447\n",
      "Batch 395 - loss: 0.5113792419433594\n",
      "Batch 396 - loss: 0.5602835416793823\n",
      "Batch 397 - loss: 0.48298388719558716\n",
      "Batch 398 - loss: 0.5204885601997375\n",
      "Batch 399 - loss: 0.5353018641471863\n",
      "Batch 400 - loss: 0.5424931049346924\n",
      "Batch 401 - loss: 0.5309633612632751\n",
      "Batch 402 - loss: 0.47263631224632263\n",
      "Batch 403 - loss: 0.5018724799156189\n",
      "Batch 404 - loss: 0.5008754134178162\n",
      "Batch 405 - loss: 0.5239433646202087\n",
      "Batch 406 - loss: 0.4876900911331177\n",
      "Batch 407 - loss: 0.5114180445671082\n",
      "Batch 408 - loss: 0.48559269309043884\n",
      "Batch 409 - loss: 0.5335114598274231\n",
      "Batch 410 - loss: 0.6096118688583374\n",
      "Batch 411 - loss: 0.49642354249954224\n",
      "Batch 412 - loss: 0.569831132888794\n",
      "Batch 413 - loss: 0.49649372696876526\n",
      "Batch 414 - loss: 0.4549202620983124\n",
      "Batch 415 - loss: 0.5209563970565796\n",
      "Batch 416 - loss: 0.5756868720054626\n",
      "Batch 417 - loss: 0.4714967906475067\n",
      "Batch 418 - loss: 0.4581584334373474\n",
      "Batch 419 - loss: 0.4374880790710449\n",
      "Batch 420 - loss: 0.5266995429992676\n",
      "Batch 421 - loss: 0.5327886939048767\n",
      "Batch 422 - loss: 0.5206962823867798\n",
      "Batch 423 - loss: 0.4857463836669922\n",
      "Batch 424 - loss: 0.4920416474342346\n",
      "Batch 425 - loss: 0.5568535327911377\n",
      "Batch 426 - loss: 0.520887017250061\n",
      "Batch 427 - loss: 0.5038852691650391\n",
      "Batch 428 - loss: 0.5442745685577393\n",
      "Batch 429 - loss: 0.521910548210144\n",
      "Batch 430 - loss: 0.5335813760757446\n",
      "Batch 431 - loss: 0.5448193550109863\n",
      "Batch 432 - loss: 0.4519501030445099\n",
      "Batch 433 - loss: 0.5012131929397583\n",
      "Batch 434 - loss: 0.46625638008117676\n",
      "Batch 435 - loss: 0.5313273668289185\n",
      "Batch 436 - loss: 0.5695790648460388\n",
      "Batch 437 - loss: 0.4905644357204437\n",
      "Batch 438 - loss: 0.5406761169433594\n",
      "Batch 439 - loss: 0.5648710131645203\n",
      "Batch 440 - loss: 0.5445942282676697\n",
      "Batch 441 - loss: 0.5663127303123474\n",
      "Batch 442 - loss: 0.5169906616210938\n",
      "Batch 443 - loss: 0.5024363994598389\n",
      "Batch 444 - loss: 0.5150319933891296\n",
      "Batch 445 - loss: 0.47637155652046204\n",
      "Batch 446 - loss: 0.5204323530197144\n",
      "Batch 447 - loss: 0.5396198034286499\n",
      "Batch 448 - loss: 0.5546204447746277\n",
      "Batch 449 - loss: 0.5143743753433228\n",
      "Batch 450 - loss: 0.509191632270813\n",
      "Batch 451 - loss: 0.5076719522476196\n",
      "Batch 452 - loss: 0.46584513783454895\n",
      "Batch 453 - loss: 0.5117288827896118\n",
      "Batch 454 - loss: 0.456333726644516\n",
      "Batch 455 - loss: 0.49345430731773376\n",
      "Batch 456 - loss: 0.5286396741867065\n",
      "Batch 457 - loss: 0.5920324921607971\n",
      "Batch 458 - loss: 0.4961991608142853\n",
      "Batch 459 - loss: 0.49976488947868347\n",
      "Batch 460 - loss: 0.5017778873443604\n",
      "Batch 461 - loss: 0.55150306224823\n",
      "Batch 462 - loss: 0.5228058099746704\n",
      "Batch 463 - loss: 0.48452672362327576\n",
      "Batch 464 - loss: 0.5210733413696289\n",
      "Batch 465 - loss: 0.46036916971206665\n",
      "Batch 466 - loss: 0.4766015410423279\n",
      "Batch 467 - loss: 0.5662928819656372\n",
      "Batch 468 - loss: 0.5281198620796204\n",
      "Batch 469 - loss: 0.5715288519859314\n",
      "Batch 470 - loss: 0.4785395860671997\n",
      "Batch 471 - loss: 0.5230667591094971\n",
      "Batch 472 - loss: 0.5269908905029297\n",
      "Batch 473 - loss: 0.5627955198287964\n",
      "Batch 474 - loss: 0.5018713474273682\n",
      "Batch 475 - loss: 0.43557441234588623\n",
      "Batch 476 - loss: 0.5573256015777588\n",
      "Batch 477 - loss: 0.5516635179519653\n",
      "Batch 478 - loss: 0.4986906349658966\n",
      "Batch 479 - loss: 0.570370614528656\n",
      "Batch 480 - loss: 0.5356419086456299\n",
      "Batch 481 - loss: 0.5628235340118408\n",
      "Batch 482 - loss: 0.49874505400657654\n",
      "Batch 483 - loss: 0.5039881467819214\n",
      "Batch 484 - loss: 0.554899275302887\n",
      "Batch 485 - loss: 0.5872043967247009\n",
      "Batch 486 - loss: 0.5607397556304932\n",
      "Batch 487 - loss: 0.5319722294807434\n",
      "Batch 488 - loss: 0.550125241279602\n",
      "Batch 489 - loss: 0.4954404830932617\n",
      "Batch 490 - loss: 0.527118444442749\n",
      "Batch 491 - loss: 0.5206886529922485\n",
      "Batch 492 - loss: 0.4818737208843231\n",
      "Batch 493 - loss: 0.471559077501297\n",
      "Batch 494 - loss: 0.5120763778686523\n",
      "Batch 495 - loss: 0.46864229440689087\n",
      "Batch 496 - loss: 0.5007807016372681\n",
      "Batch 497 - loss: 0.5713683366775513\n",
      "Batch 498 - loss: 0.5454721450805664\n",
      "Batch 499 - loss: 0.5649084448814392\n",
      "Batch 500 - loss: 0.5378119945526123\n",
      "Batch 501 - loss: 0.575721800327301\n",
      "Batch 502 - loss: 0.5008047223091125\n",
      "Batch 503 - loss: 0.5175503492355347\n",
      "Batch 504 - loss: 0.49936729669570923\n",
      "Batch 505 - loss: 0.5037339329719543\n",
      "Batch 506 - loss: 0.5236809849739075\n",
      "Batch 507 - loss: 0.4906637668609619\n",
      "Batch 508 - loss: 0.5037514567375183\n",
      "Batch 509 - loss: 0.5182223916053772\n",
      "Batch 510 - loss: 0.4437450170516968\n",
      "Batch 511 - loss: 0.5462362766265869\n",
      "Batch 512 - loss: 0.44513067603111267\n",
      "Batch 513 - loss: 0.5321938395500183\n",
      "Batch 514 - loss: 0.44866952300071716\n",
      "Batch 515 - loss: 0.42854464054107666\n",
      "Batch 516 - loss: 0.5186039209365845\n",
      "Batch 517 - loss: 0.5030262470245361\n",
      "Batch 518 - loss: 0.4749312102794647\n",
      "Batch 519 - loss: 0.503194272518158\n",
      "Batch 520 - loss: 0.48874154686927795\n",
      "Batch 521 - loss: 0.4648430049419403\n",
      "Batch 522 - loss: 0.49738845229148865\n",
      "Batch 523 - loss: 0.5306650400161743\n",
      "Batch 524 - loss: 0.5072797536849976\n",
      "Batch 525 - loss: 0.4371930956840515\n",
      "Batch 526 - loss: 0.47324854135513306\n",
      "Batch 527 - loss: 0.4944832921028137\n",
      "Batch 528 - loss: 0.559597373008728\n",
      "Batch 529 - loss: 0.47166961431503296\n",
      "Batch 530 - loss: 0.5402137637138367\n",
      "Batch 531 - loss: 0.5627875924110413\n",
      "Batch 532 - loss: 0.4643934667110443\n",
      "Batch 533 - loss: 0.4741782546043396\n",
      "Batch 534 - loss: 0.5102309584617615\n",
      "Batch 535 - loss: 0.551516056060791\n",
      "Batch 536 - loss: 0.5013942718505859\n",
      "Batch 537 - loss: 0.5157862901687622\n",
      "Batch 538 - loss: 0.5414914488792419\n",
      "Batch 539 - loss: 0.4781968891620636\n",
      "Batch 540 - loss: 0.4863707721233368\n",
      "Batch 541 - loss: 0.4819730222225189\n",
      "Batch 542 - loss: 0.5150362253189087\n",
      "Batch 543 - loss: 0.4505656957626343\n",
      "Batch 544 - loss: 0.4911364018917084\n",
      "Batch 545 - loss: 0.45145905017852783\n",
      "Batch 546 - loss: 0.5165221095085144\n",
      "Batch 547 - loss: 0.48067232966423035\n",
      "Batch 548 - loss: 0.5364902019500732\n",
      "Batch 549 - loss: 0.5097545981407166\n",
      "Batch 550 - loss: 0.5033196806907654\n",
      "Batch 551 - loss: 0.47262173891067505\n",
      "Batch 552 - loss: 0.5033272504806519\n",
      "Batch 553 - loss: 0.4531051814556122\n",
      "Batch 554 - loss: 0.5163090229034424\n",
      "Batch 555 - loss: 0.4805552065372467\n",
      "Batch 556 - loss: 0.5014199018478394\n",
      "Batch 557 - loss: 0.5082560777664185\n",
      "Batch 558 - loss: 0.5307750105857849\n",
      "Batch 559 - loss: 0.5592151880264282\n",
      "Batch 560 - loss: 0.5105769634246826\n",
      "Batch 561 - loss: 0.44544342160224915\n",
      "Batch 562 - loss: 0.5366272330284119\n",
      "Batch 563 - loss: 0.4902377426624298\n",
      "Batch 564 - loss: 0.47967347502708435\n",
      "Batch 565 - loss: 0.5721551179885864\n",
      "Batch 566 - loss: 0.5021299123764038\n",
      "Batch 567 - loss: 0.4454982578754425\n",
      "Batch 568 - loss: 0.5105480551719666\n",
      "Batch 569 - loss: 0.4908687174320221\n",
      "Batch 570 - loss: 0.5104432702064514\n",
      "Batch 571 - loss: 0.5142300128936768\n",
      "Batch 572 - loss: 0.5385637879371643\n",
      "Batch 573 - loss: 0.5167452096939087\n",
      "Batch 574 - loss: 0.49957650899887085\n",
      "Batch 575 - loss: 0.5164470672607422\n",
      "Batch 576 - loss: 0.5125153064727783\n",
      "Batch 577 - loss: 0.5763705968856812\n",
      "Batch 578 - loss: 0.5230850577354431\n",
      "Batch 579 - loss: 0.4939829111099243\n",
      "Batch 580 - loss: 0.4511643946170807\n",
      "Batch 581 - loss: 0.4503110349178314\n",
      "Batch 582 - loss: 0.4895959496498108\n",
      "Batch 583 - loss: 0.5213010907173157\n",
      "Batch 584 - loss: 0.4927947521209717\n",
      "Batch 585 - loss: 0.5803017616271973\n",
      "Batch 586 - loss: 0.5514665246009827\n",
      "Batch 587 - loss: 0.47784194350242615\n",
      "Batch 588 - loss: 0.4557383358478546\n",
      "Batch 589 - loss: 0.520357608795166\n",
      "Batch 590 - loss: 0.5235063433647156\n",
      "Batch 591 - loss: 0.5252597332000732\n",
      "Batch 592 - loss: 0.48665404319763184\n",
      "Batch 593 - loss: 0.5228338837623596\n",
      "Batch 594 - loss: 0.5639743804931641\n",
      "Batch 595 - loss: 0.5034016370773315\n",
      "Batch 596 - loss: 0.47822868824005127\n",
      "Batch 597 - loss: 0.48715001344680786\n",
      "Batch 598 - loss: 0.4659714698791504\n",
      "Batch 599 - loss: 0.4902859330177307\n",
      "Batch 600 - loss: 0.4838881194591522\n",
      "Batch 601 - loss: 0.48814311623573303\n",
      "Batch 602 - loss: 0.45767807960510254\n",
      "Batch 603 - loss: 0.4668835401535034\n",
      "Batch 604 - loss: 0.5093473196029663\n",
      "Batch 605 - loss: 0.5614957809448242\n",
      "Batch 606 - loss: 0.5262125134468079\n",
      "Batch 607 - loss: 0.4658712148666382\n",
      "Batch 608 - loss: 0.5278255939483643\n",
      "Batch 609 - loss: 0.4788234531879425\n",
      "Batch 610 - loss: 0.5781769156455994\n",
      "Batch 611 - loss: 0.5629764795303345\n",
      "Batch 612 - loss: 0.5738245844841003\n",
      "Batch 613 - loss: 0.5440757870674133\n",
      "Batch 614 - loss: 0.5418277978897095\n",
      "Batch 615 - loss: 0.5106498599052429\n",
      "Batch 616 - loss: 0.5066727995872498\n",
      "Batch 617 - loss: 0.5042042136192322\n",
      "Batch 618 - loss: 0.5389103293418884\n",
      "Batch 619 - loss: 0.49499261379241943\n",
      "Batch 620 - loss: 0.4645513892173767\n",
      "Batch 621 - loss: 0.5002942681312561\n",
      "Batch 622 - loss: 0.5405167937278748\n",
      "Batch 623 - loss: 0.5430483818054199\n",
      "Batch 624 - loss: 0.5202797055244446\n",
      "Batch 625 - loss: 0.5590904951095581\n",
      "Batch 626 - loss: 0.5061466097831726\n",
      "Batch 627 - loss: 0.5608291625976562\n",
      "Batch 628 - loss: 0.46836596727371216\n",
      "Batch 629 - loss: 0.5665584206581116\n",
      "Batch 630 - loss: 0.4695059657096863\n",
      "Batch 631 - loss: 0.4999813437461853\n",
      "Batch 632 - loss: 0.4910231828689575\n",
      "Batch 633 - loss: 0.5023439526557922\n",
      "Batch 634 - loss: 0.4920445680618286\n",
      "Batch 635 - loss: 0.4688570201396942\n",
      "Batch 636 - loss: 0.49453005194664\n",
      "Batch 637 - loss: 0.5324366092681885\n",
      "Batch 638 - loss: 0.5217877626419067\n",
      "Batch 639 - loss: 0.4549928605556488\n",
      "Batch 640 - loss: 0.5494765043258667\n",
      "Batch 641 - loss: 0.472976952791214\n",
      "Batch 642 - loss: 0.5267754197120667\n",
      "Batch 643 - loss: 0.4789317846298218\n",
      "Batch 644 - loss: 0.5206926465034485\n",
      "Batch 645 - loss: 0.47962111234664917\n",
      "Batch 646 - loss: 0.5318526029586792\n",
      "Batch 647 - loss: 0.5198094248771667\n",
      "Batch 648 - loss: 0.4770940840244293\n",
      "Batch 649 - loss: 0.5639220476150513\n",
      "Batch 650 - loss: 0.4983628988265991\n",
      "Batch 651 - loss: 0.5027873516082764\n",
      "Batch 652 - loss: 0.5046777129173279\n",
      "Batch 653 - loss: 0.5480135083198547\n",
      "Batch 654 - loss: 0.552018940448761\n",
      "Batch 655 - loss: 0.48660531640052795\n",
      "Batch 656 - loss: 0.5374743938446045\n",
      "Batch 657 - loss: 0.511379063129425\n",
      "Batch 658 - loss: 0.5002114176750183\n",
      "Batch 659 - loss: 0.5738288760185242\n",
      "Batch 660 - loss: 0.4564918577671051\n",
      "Batch 661 - loss: 0.4916672706604004\n",
      "Batch 662 - loss: 0.4645240008831024\n",
      "Batch 663 - loss: 0.5535352826118469\n",
      "Batch 664 - loss: 0.5455881357192993\n",
      "Batch 665 - loss: 0.5219367742538452\n",
      "Batch 666 - loss: 0.47915226221084595\n",
      "Batch 667 - loss: 0.546632707118988\n",
      "Batch 668 - loss: 0.5759851932525635\n",
      "Batch 669 - loss: 0.5431897044181824\n",
      "Batch 670 - loss: 0.5888547301292419\n",
      "Batch 671 - loss: 0.5055519938468933\n",
      "Batch 672 - loss: 0.4823778569698334\n",
      "Batch 673 - loss: 0.575527548789978\n",
      "Batch 674 - loss: 0.5113916993141174\n",
      "Batch 675 - loss: 0.5283503532409668\n",
      "Batch 676 - loss: 0.5020668506622314\n",
      "Batch 677 - loss: 0.508700430393219\n",
      "Batch 678 - loss: 0.4513319134712219\n",
      "Batch 679 - loss: 0.5378751158714294\n",
      "Batch 680 - loss: 0.48690539598464966\n",
      "Batch 681 - loss: 0.5384371280670166\n",
      "Batch 682 - loss: 0.5167623162269592\n",
      "Batch 683 - loss: 0.5051878094673157\n",
      "Batch 684 - loss: 0.4866180121898651\n",
      "Batch 685 - loss: 0.48607364296913147\n",
      "Batch 686 - loss: 0.552789568901062\n",
      "Batch 687 - loss: 0.502291202545166\n",
      "Batch 688 - loss: 0.5058808326721191\n",
      "Batch 689 - loss: 0.5423330068588257\n",
      "Batch 690 - loss: 0.4974123537540436\n",
      "Batch 691 - loss: 0.5309194922447205\n",
      "Batch 692 - loss: 0.5378180742263794\n",
      "Batch 693 - loss: 0.5479894280433655\n",
      "Batch 694 - loss: 0.5756548047065735\n",
      "Batch 695 - loss: 0.562667191028595\n",
      "Batch 696 - loss: 0.4558873772621155\n",
      "Batch 697 - loss: 0.4795766770839691\n",
      "Batch 698 - loss: 0.48603299260139465\n",
      "Batch 699 - loss: 0.592201292514801\n",
      "Batch 700 - loss: 0.5191440582275391\n",
      "Batch 701 - loss: 0.5335144400596619\n",
      "Batch 702 - loss: 0.45003756880760193\n",
      "Batch 703 - loss: 0.5238426327705383\n",
      "Batch 704 - loss: 0.4512110650539398\n",
      "Batch 705 - loss: 0.4766131341457367\n",
      "Batch 706 - loss: 0.5560286641120911\n",
      "Batch 707 - loss: 0.484702467918396\n",
      "Batch 708 - loss: 0.45086658000946045\n",
      "Batch 709 - loss: 0.4915795922279358\n",
      "Batch 710 - loss: 0.5352644324302673\n",
      "Batch 711 - loss: 0.45762869715690613\n",
      "Batch 712 - loss: 0.48863092064857483\n",
      "Batch 713 - loss: 0.47206801176071167\n",
      "Batch 714 - loss: 0.5651195645332336\n",
      "Batch 715 - loss: 0.4801761507987976\n",
      "Batch 716 - loss: 0.5088520050048828\n",
      "Batch 717 - loss: 0.4665336310863495\n",
      "Batch 718 - loss: 0.5199577808380127\n",
      "Batch 719 - loss: 0.5417470932006836\n",
      "Batch 720 - loss: 0.5514177083969116\n",
      "Batch 721 - loss: 0.5100226998329163\n",
      "Batch 722 - loss: 0.6577659249305725\n",
      "Batch 723 - loss: 0.5479864478111267\n",
      "Batch 724 - loss: 0.5226989984512329\n",
      "Batch 725 - loss: 0.520833432674408\n",
      "Batch 726 - loss: 0.4760589003562927\n",
      "Batch 727 - loss: 0.5409913063049316\n",
      "Batch 728 - loss: 0.5213016867637634\n",
      "Batch 729 - loss: 0.47669342160224915\n",
      "Batch 730 - loss: 0.5366992950439453\n",
      "Batch 731 - loss: 0.5610466599464417\n",
      "Batch 732 - loss: 0.5157437920570374\n",
      "Batch 733 - loss: 0.49939095973968506\n",
      "Batch 734 - loss: 0.4793543219566345\n",
      "Batch 735 - loss: 0.5078956484794617\n",
      "Batch 736 - loss: 0.5362674593925476\n",
      "Batch 737 - loss: 0.5147334933280945\n",
      "Batch 738 - loss: 0.5326696634292603\n",
      "Batch 739 - loss: 0.5340518355369568\n",
      "Batch 740 - loss: 0.5307773947715759\n",
      "Batch 741 - loss: 0.5206459164619446\n",
      "Batch 742 - loss: 0.5352396965026855\n",
      "Batch 743 - loss: 0.4873470067977905\n",
      "Batch 744 - loss: 0.5172114968299866\n",
      "Batch 745 - loss: 0.5132074356079102\n",
      "Batch 746 - loss: 0.4928516447544098\n",
      "Batch 747 - loss: 0.5181684494018555\n",
      "Batch 748 - loss: 0.5118117332458496\n",
      "Batch 749 - loss: 0.4964246451854706\n",
      "Batch 750 - loss: 0.4826851487159729\n",
      "Batch 751 - loss: 0.5310038328170776\n",
      "Batch 752 - loss: 0.5709950923919678\n",
      "Batch 753 - loss: 0.49896860122680664\n",
      "Batch 754 - loss: 0.5291551947593689\n",
      "Batch 755 - loss: 0.506869912147522\n",
      "Batch 756 - loss: 0.5478032231330872\n",
      "Batch 757 - loss: 0.5197063684463501\n",
      "Batch 758 - loss: 0.5184099078178406\n",
      "Batch 759 - loss: 0.49197590351104736\n",
      "Batch 760 - loss: 0.5001659393310547\n",
      "Batch 761 - loss: 0.4868861734867096\n",
      "Batch 762 - loss: 0.45660898089408875\n",
      "Batch 763 - loss: 0.4955066740512848\n",
      "Batch 764 - loss: 0.5533829927444458\n",
      "Batch 765 - loss: 0.46343499422073364\n",
      "Batch 766 - loss: 0.539972186088562\n",
      "Batch 767 - loss: 0.4658831059932709\n",
      "Batch 768 - loss: 0.4844953715801239\n",
      "Batch 769 - loss: 0.4699802100658417\n",
      "Batch 770 - loss: 0.5230772495269775\n",
      "Batch 771 - loss: 0.4753563106060028\n",
      "Batch 772 - loss: 0.549644947052002\n",
      "Batch 773 - loss: 0.5028979182243347\n",
      "Batch 774 - loss: 0.46682727336883545\n",
      "Batch 775 - loss: 0.4902980923652649\n",
      "Batch 776 - loss: 0.48147398233413696\n",
      "Batch 777 - loss: 0.5220112204551697\n",
      "Batch 778 - loss: 0.48910582065582275\n",
      "Batch 779 - loss: 0.47144967317581177\n",
      "Batch 780 - loss: 0.5015288591384888\n",
      "Batch 781 - loss: 0.5661624073982239\n",
      "Batch 782 - loss: 0.5533285737037659\n",
      "Batch 783 - loss: 0.48575806617736816\n",
      "Batch 784 - loss: 0.5431231260299683\n",
      "Batch 785 - loss: 0.5421879887580872\n",
      "Batch 786 - loss: 0.5245797038078308\n",
      "Batch 787 - loss: 0.5477415323257446\n",
      "Batch 788 - loss: 0.6060614585876465\n",
      "Batch 789 - loss: 0.5730083584785461\n",
      "Batch 790 - loss: 0.5341116189956665\n",
      "Batch 791 - loss: 0.49466609954833984\n",
      "Batch 792 - loss: 0.5581766963005066\n",
      "Batch 793 - loss: 0.5043066143989563\n",
      "Batch 794 - loss: 0.4910982549190521\n",
      "Batch 795 - loss: 0.5109559297561646\n",
      "Batch 796 - loss: 0.49036794900894165\n",
      "Batch 797 - loss: 0.5327167510986328\n",
      "Batch 798 - loss: 0.4680955708026886\n",
      "Batch 799 - loss: 0.4986910820007324\n",
      "Batch 800 - loss: 0.49970871210098267\n",
      "Batch 801 - loss: 0.5067801475524902\n",
      "Batch 802 - loss: 0.4935668408870697\n",
      "Batch 803 - loss: 0.5276336073875427\n",
      "Batch 804 - loss: 0.5121935606002808\n",
      "Batch 805 - loss: 0.5405462980270386\n",
      "Batch 806 - loss: 0.533432126045227\n",
      "Batch 807 - loss: 0.41122302412986755\n",
      "Batch 808 - loss: 0.579339861869812\n",
      "Batch 809 - loss: 0.5082855224609375\n",
      "Batch 810 - loss: 0.5609579086303711\n",
      "Batch 811 - loss: 0.43668073415756226\n",
      "Batch 812 - loss: 0.48520898818969727\n",
      "Batch 813 - loss: 0.5061894655227661\n",
      "Batch 814 - loss: 0.5561156868934631\n",
      "Batch 815 - loss: 0.5210325121879578\n",
      "Batch 816 - loss: 0.4559067487716675\n",
      "Batch 817 - loss: 0.49826154112815857\n",
      "Batch 818 - loss: 0.47042202949523926\n",
      "Batch 819 - loss: 0.5499961376190186\n",
      "Batch 820 - loss: 0.48448479175567627\n",
      "Batch 821 - loss: 0.5661450624465942\n",
      "Batch 822 - loss: 0.527159571647644\n",
      "Batch 823 - loss: 0.5299564003944397\n",
      "Batch 824 - loss: 0.4926634728908539\n",
      "Batch 825 - loss: 0.4847371280193329\n",
      "Batch 826 - loss: 0.5210954546928406\n",
      "Batch 827 - loss: 0.5488911271095276\n",
      "Batch 828 - loss: 0.48850780725479126\n",
      "Batch 829 - loss: 0.570391058921814\n",
      "Batch 830 - loss: 0.516590416431427\n",
      "Batch 831 - loss: 0.559653639793396\n",
      "Batch 832 - loss: 0.47949886322021484\n",
      "Batch 833 - loss: 0.47257447242736816\n",
      "Batch 834 - loss: 0.6107540130615234\n",
      "Batch 835 - loss: 0.498720645904541\n",
      "Batch 836 - loss: 0.5086485743522644\n",
      "Batch 837 - loss: 0.46959614753723145\n",
      "Batch 838 - loss: 0.4827626943588257\n",
      "Batch 839 - loss: 0.5088691711425781\n",
      "Batch 840 - loss: 0.48241907358169556\n",
      "Batch 841 - loss: 0.6011874079704285\n",
      "Batch 842 - loss: 0.5572957992553711\n",
      "Batch 843 - loss: 0.523937463760376\n",
      "Batch 844 - loss: 0.536598265171051\n",
      "Batch 845 - loss: 0.5107705593109131\n",
      "Batch 846 - loss: 0.49143943190574646\n",
      "Batch 847 - loss: 0.5780094265937805\n",
      "Batch 848 - loss: 0.4645281732082367\n",
      "Batch 849 - loss: 0.5282080173492432\n",
      "Batch 850 - loss: 0.5295523405075073\n",
      "Batch 851 - loss: 0.47495490312576294\n",
      "Batch 852 - loss: 0.501096785068512\n",
      "Batch 853 - loss: 0.5065951347351074\n",
      "Batch 854 - loss: 0.47245579957962036\n",
      "Batch 855 - loss: 0.47070327401161194\n",
      "Batch 856 - loss: 0.4705410897731781\n",
      "Batch 857 - loss: 0.4831410348415375\n",
      "Batch 858 - loss: 0.4719078540802002\n",
      "Batch 859 - loss: 0.5038679242134094\n",
      "Batch 860 - loss: 0.507253885269165\n",
      "Batch 861 - loss: 0.582368016242981\n",
      "Batch 862 - loss: 0.5330924987792969\n",
      "Batch 863 - loss: 0.4574737250804901\n",
      "Batch 864 - loss: 0.5056303143501282\n",
      "Batch 865 - loss: 0.5092087984085083\n",
      "Batch 866 - loss: 0.4907095730304718\n",
      "Batch 867 - loss: 0.5178125500679016\n",
      "Batch 868 - loss: 0.5104314684867859\n",
      "Batch 869 - loss: 0.4795505106449127\n",
      "Batch 870 - loss: 0.4640078842639923\n",
      "Batch 871 - loss: 0.5109208226203918\n",
      "Batch 872 - loss: 0.5439075231552124\n",
      "Batch 873 - loss: 0.4549485445022583\n",
      "Batch 874 - loss: 0.4993726909160614\n",
      "Batch 875 - loss: 0.4855305552482605\n",
      "Batch 876 - loss: 0.6032952666282654\n",
      "Batch 877 - loss: 0.4915320873260498\n",
      "Batch 878 - loss: 0.5447927117347717\n",
      "Batch 879 - loss: 0.514453113079071\n",
      "Batch 880 - loss: 0.5419637560844421\n",
      "Batch 881 - loss: 0.49955761432647705\n",
      "Batch 882 - loss: 0.5121344327926636\n",
      "Batch 883 - loss: 0.5028396248817444\n",
      "Batch 884 - loss: 0.5176720023155212\n",
      "Batch 885 - loss: 0.5211984515190125\n",
      "Batch 886 - loss: 0.5321090817451477\n",
      "Batch 887 - loss: 0.5553745031356812\n",
      "Batch 888 - loss: 0.5303421020507812\n",
      "Batch 889 - loss: 0.4823111891746521\n",
      "Batch 890 - loss: 0.5311776995658875\n",
      "Batch 891 - loss: 0.4699825346469879\n",
      "Batch 892 - loss: 0.5428003668785095\n",
      "Batch 893 - loss: 0.494749516248703\n",
      "Batch 894 - loss: 0.5096011161804199\n",
      "Batch 895 - loss: 0.4692517817020416\n",
      "Batch 896 - loss: 0.5182798504829407\n",
      "Batch 897 - loss: 0.5141407251358032\n",
      "Batch 898 - loss: 0.5129842162132263\n",
      "Batch 899 - loss: 0.5587243437767029\n",
      "Batch 900 - loss: 0.4901182949542999\n",
      "Batch 901 - loss: 0.551453173160553\n",
      "Batch 902 - loss: 0.5075100660324097\n",
      "Batch 903 - loss: 0.5516164302825928\n",
      "Batch 904 - loss: 0.4851098656654358\n",
      "Batch 905 - loss: 0.46987247467041016\n",
      "Batch 906 - loss: 0.48954665660858154\n",
      "Batch 907 - loss: 0.517198920249939\n",
      "Batch 908 - loss: 0.4700957238674164\n",
      "Batch 909 - loss: 0.5304751992225647\n",
      "Batch 910 - loss: 0.5213515162467957\n",
      "Batch 911 - loss: 0.4533175528049469\n",
      "Batch 912 - loss: 0.5297591686248779\n",
      "Batch 913 - loss: 0.49031975865364075\n",
      "Batch 914 - loss: 0.49087023735046387\n",
      "Batch 915 - loss: 0.4832319915294647\n",
      "Batch 916 - loss: 0.49512752890586853\n",
      "Batch 917 - loss: 0.47805848717689514\n",
      "Batch 918 - loss: 0.5160325765609741\n",
      "Batch 919 - loss: 0.46491122245788574\n",
      "Batch 920 - loss: 0.4895938038825989\n",
      "Batch 921 - loss: 0.5192911624908447\n",
      "Batch 922 - loss: 0.4729621112346649\n",
      "Batch 923 - loss: 0.5521988868713379\n",
      "Batch 924 - loss: 0.4731689691543579\n",
      "Batch 925 - loss: 0.5215893387794495\n",
      "Batch 926 - loss: 0.5721516013145447\n",
      "Batch 927 - loss: 0.5110895037651062\n",
      "Batch 928 - loss: 0.5084494352340698\n",
      "Batch 929 - loss: 0.5050021409988403\n",
      "Batch 930 - loss: 0.5379895567893982\n",
      "Batch 931 - loss: 0.5539660453796387\n",
      "Batch 932 - loss: 0.4696512818336487\n",
      "Batch 933 - loss: 0.548158586025238\n",
      "Batch 934 - loss: 0.5796489715576172\n",
      "Batch 935 - loss: 0.4715924561023712\n",
      "Batch 936 - loss: 0.494720995426178\n",
      "Batch 937 - loss: 0.4941616952419281\n",
      "Batch 938 - loss: 0.49463289976119995\n",
      "Batch 939 - loss: 0.5037786960601807\n",
      "Batch 940 - loss: 0.48167937994003296\n",
      "Batch 941 - loss: 0.5231866836547852\n",
      "Batch 942 - loss: 0.5302940607070923\n",
      "Batch 943 - loss: 0.467148095369339\n",
      "Batch 944 - loss: 0.5025279521942139\n",
      "Batch 945 - loss: 0.5605489611625671\n",
      "Batch 946 - loss: 0.4878743588924408\n",
      "Batch 947 - loss: 0.5337921977043152\n",
      "Batch 948 - loss: 0.5542662143707275\n",
      "Batch 949 - loss: 0.536438524723053\n",
      "Batch 950 - loss: 0.4782700836658478\n",
      "Batch 951 - loss: 0.5496158003807068\n",
      "Batch 952 - loss: 0.530730664730072\n",
      "Batch 953 - loss: 0.5050733685493469\n",
      "Batch 954 - loss: 0.5812591314315796\n",
      "Batch 955 - loss: 0.5059650540351868\n",
      "Batch 956 - loss: 0.49637967348098755\n",
      "Batch 957 - loss: 0.5513737201690674\n",
      "Batch 958 - loss: 0.504263162612915\n",
      "Batch 959 - loss: 0.46635308861732483\n",
      "Batch 960 - loss: 0.5236931443214417\n",
      "Batch 961 - loss: 0.4937181770801544\n",
      "Batch 962 - loss: 0.4796470105648041\n",
      "Batch 963 - loss: 0.4771764278411865\n",
      "Batch 964 - loss: 0.5423023700714111\n",
      "Batch 965 - loss: 0.513159453868866\n",
      "Batch 966 - loss: 0.44239479303359985\n",
      "Batch 967 - loss: 0.504377007484436\n",
      "Batch 968 - loss: 0.5151290893554688\n",
      "Batch 969 - loss: 0.5651522278785706\n",
      "Batch 970 - loss: 0.54909747838974\n",
      "Batch 971 - loss: 0.48592790961265564\n",
      "Batch 972 - loss: 0.4855591654777527\n",
      "Batch 973 - loss: 0.5318989753723145\n",
      "Batch 974 - loss: 0.4839770197868347\n",
      "Batch 975 - loss: 0.5062755346298218\n",
      "Batch 976 - loss: 0.45399171113967896\n",
      "Batch 977 - loss: 0.4721044898033142\n",
      "Batch 978 - loss: 0.5007005333900452\n",
      "Batch 979 - loss: 0.4852941334247589\n",
      "Batch 980 - loss: 0.5562634468078613\n",
      "Batch 981 - loss: 0.5369572639465332\n",
      "Batch 982 - loss: 0.6467822194099426\n",
      "Batch 983 - loss: 0.5086463689804077\n",
      "Batch 984 - loss: 0.46641772985458374\n",
      "Batch 985 - loss: 0.5648167729377747\n",
      "Batch 986 - loss: 0.4758574664592743\n",
      "Batch 987 - loss: 0.5343351364135742\n",
      "Batch 988 - loss: 0.49814504384994507\n",
      "Batch 989 - loss: 0.5082129836082458\n",
      "Batch 990 - loss: 0.4905446767807007\n",
      "Batch 991 - loss: 0.4623359739780426\n",
      "Batch 992 - loss: 0.5649006366729736\n",
      "Batch 993 - loss: 0.5327096581459045\n",
      "Batch 994 - loss: 0.5874848365783691\n",
      "Batch 995 - loss: 0.5772001147270203\n",
      "Batch 996 - loss: 0.48624128103256226\n",
      "Batch 997 - loss: 0.515894889831543\n",
      "Batch 998 - loss: 0.5107014179229736\n",
      "Batch 999 - loss: 0.5698442459106445\n",
      "Batch 1000 - loss: 0.5345703363418579\n",
      "Batch 1001 - loss: 0.53177410364151\n",
      "Batch 1002 - loss: 0.5755067467689514\n",
      "Batch 1003 - loss: 0.5345110893249512\n",
      "Batch 1004 - loss: 0.4734025001525879\n",
      "Batch 1005 - loss: 0.5021712779998779\n",
      "Batch 1006 - loss: 0.4678031802177429\n",
      "Batch 1007 - loss: 0.5615828037261963\n",
      "Batch 1008 - loss: 0.540809154510498\n",
      "Batch 1009 - loss: 0.5340598225593567\n",
      "Batch 1010 - loss: 0.4841698408126831\n",
      "Batch 1011 - loss: 0.5107244849205017\n",
      "Batch 1012 - loss: 0.5254955291748047\n",
      "Batch 1013 - loss: 0.5393947958946228\n",
      "Batch 1014 - loss: 0.4888187348842621\n",
      "Batch 1015 - loss: 0.4724918305873871\n",
      "Batch 1016 - loss: 0.5219259858131409\n",
      "Batch 1017 - loss: 0.47238123416900635\n",
      "Batch 1018 - loss: 0.5780102610588074\n",
      "Batch 1019 - loss: 0.48294931650161743\n",
      "Batch 1020 - loss: 0.5938189625740051\n",
      "Batch 1021 - loss: 0.4792560338973999\n",
      "Batch 1022 - loss: 0.4851350486278534\n",
      "Batch 1023 - loss: 0.47907981276512146\n",
      "Batch 1024 - loss: 0.5173918008804321\n",
      "Batch 1025 - loss: 0.5412366986274719\n",
      "Batch 1026 - loss: 0.5521448254585266\n",
      "Batch 1027 - loss: 0.4959784150123596\n",
      "Batch 1028 - loss: 0.47024837136268616\n",
      "Batch 1029 - loss: 0.4767392873764038\n",
      "Batch 1030 - loss: 0.5136611461639404\n",
      "Batch 1031 - loss: 0.5547086596488953\n",
      "Batch 1032 - loss: 0.4537247121334076\n",
      "Batch 1033 - loss: 0.4882665276527405\n",
      "Batch 1034 - loss: 0.45628106594085693\n",
      "Batch 1035 - loss: 0.5482937693595886\n",
      "Batch 1036 - loss: 0.4811103045940399\n",
      "Batch 1037 - loss: 0.5358294248580933\n",
      "Batch 1038 - loss: 0.5217886567115784\n",
      "Batch 1039 - loss: 0.5941086411476135\n",
      "Batch 1040 - loss: 0.5876712203025818\n",
      "Batch 1041 - loss: 0.42480820417404175\n",
      "Batch 1042 - loss: 0.5369759798049927\n",
      "Batch 1043 - loss: 0.5089430212974548\n",
      "Batch 1044 - loss: 0.526525616645813\n",
      "Batch 1045 - loss: 0.5134404301643372\n",
      "Batch 1046 - loss: 0.5001903176307678\n",
      "Batch 1047 - loss: 0.5605466365814209\n",
      "Batch 1048 - loss: 0.5213959813117981\n",
      "Batch 1049 - loss: 0.5129612684249878\n",
      "Batch 1050 - loss: 0.49654021859169006\n",
      "Batch 1051 - loss: 0.5774851441383362\n",
      "Batch 1052 - loss: 0.49114319682121277\n",
      "Batch 1053 - loss: 0.5170497894287109\n",
      "Batch 1054 - loss: 0.5270143747329712\n",
      "Batch 1055 - loss: 0.47105589509010315\n",
      "Batch 1056 - loss: 0.5320621728897095\n",
      "Batch 1057 - loss: 0.4749395549297333\n",
      "Batch 1058 - loss: 0.5747518539428711\n",
      "Batch 1059 - loss: 0.46664878726005554\n",
      "Batch 1060 - loss: 0.46963265538215637\n",
      "Batch 1061 - loss: 0.43847420811653137\n",
      "Batch 1062 - loss: 0.4869905710220337\n",
      "Batch 1063 - loss: 0.5232947468757629\n",
      "Batch 1064 - loss: 0.47083941102027893\n",
      "Batch 1065 - loss: 0.49606576561927795\n",
      "Batch 1066 - loss: 0.44724971055984497\n",
      "Batch 1067 - loss: 0.5651654005050659\n",
      "Batch 1068 - loss: 0.46847954392433167\n",
      "Batch 1069 - loss: 0.46036452054977417\n",
      "Batch 1070 - loss: 0.5152613520622253\n",
      "Batch 1071 - loss: 0.5282506346702576\n",
      "Batch 1072 - loss: 0.5303270220756531\n",
      "Batch 1073 - loss: 0.520671546459198\n",
      "Batch 1074 - loss: 0.4535026252269745\n",
      "Batch 1075 - loss: 0.537943422794342\n",
      "Batch 1076 - loss: 0.5417116284370422\n",
      "Batch 1077 - loss: 0.5261821746826172\n",
      "Batch 1078 - loss: 0.45127007365226746\n",
      "Batch 1079 - loss: 0.5000987648963928\n",
      "Batch 1080 - loss: 0.5392747521400452\n",
      "Batch 1081 - loss: 0.512516975402832\n",
      "Batch 1082 - loss: 0.5360696315765381\n",
      "Batch 1083 - loss: 0.5112825632095337\n",
      "Batch 1084 - loss: 0.5233723521232605\n",
      "Batch 1085 - loss: 0.53187096118927\n",
      "Batch 1086 - loss: 0.5194371938705444\n",
      "Batch 1087 - loss: 0.5149791836738586\n",
      "Batch 1088 - loss: 0.4533292055130005\n",
      "Batch 1089 - loss: 0.5097188949584961\n",
      "Batch 1090 - loss: 0.4629262685775757\n",
      "Batch 1091 - loss: 0.5035642981529236\n",
      "Batch 1092 - loss: 0.48263299465179443\n",
      "Batch 1093 - loss: 0.5412507653236389\n",
      "Batch 1094 - loss: 0.5533866286277771\n",
      "Batch 1095 - loss: 0.5428083539009094\n",
      "Batch 1096 - loss: 0.4660112261772156\n",
      "Batch 1097 - loss: 0.5327191948890686\n",
      "Batch 1098 - loss: 0.5205658078193665\n",
      "Batch 1099 - loss: 0.47666996717453003\n",
      "Batch 1100 - loss: 0.5642266273498535\n",
      "Batch 1101 - loss: 0.4609420597553253\n",
      "Batch 1102 - loss: 0.5291569232940674\n",
      "Batch 1103 - loss: 0.48922842741012573\n",
      "Batch 1104 - loss: 0.5112770795822144\n",
      "Batch 1105 - loss: 0.4961422383785248\n",
      "Batch 1106 - loss: 0.48996907472610474\n",
      "Batch 1107 - loss: 0.5179821848869324\n",
      "Batch 1108 - loss: 0.48546865582466125\n",
      "Batch 1109 - loss: 0.5509293079376221\n",
      "Batch 1110 - loss: 0.5567806363105774\n",
      "Batch 1111 - loss: 0.5375496745109558\n",
      "Batch 1112 - loss: 0.5492984056472778\n",
      "Batch 1113 - loss: 0.4854857623577118\n",
      "Batch 1114 - loss: 0.5282564759254456\n",
      "Batch 1115 - loss: 0.5488595962524414\n",
      "Batch 1116 - loss: 0.5247502326965332\n",
      "Batch 1117 - loss: 0.496092826128006\n",
      "Batch 1118 - loss: 0.48428043723106384\n",
      "Batch 1119 - loss: 0.5246991515159607\n",
      "Batch 1120 - loss: 0.47060343623161316\n",
      "Batch 1121 - loss: 0.5053427219390869\n",
      "Batch 1122 - loss: 0.5170584917068481\n",
      "Batch 1123 - loss: 0.5056992173194885\n",
      "Batch 1124 - loss: 0.5056123733520508\n",
      "Batch 1125 - loss: 0.48920294642448425\n",
      "Batch 1126 - loss: 0.5610184073448181\n",
      "Batch 1127 - loss: 0.5501039624214172\n",
      "Batch 1128 - loss: 0.5298903584480286\n",
      "Batch 1129 - loss: 0.489538311958313\n",
      "Batch 1130 - loss: 0.5274261832237244\n",
      "Batch 1131 - loss: 0.5083749890327454\n",
      "Batch 1132 - loss: 0.5152562260627747\n",
      "Batch 1133 - loss: 0.5255103707313538\n",
      "Batch 1134 - loss: 0.5558158755302429\n",
      "Batch 1135 - loss: 0.4937812387943268\n",
      "Batch 1136 - loss: 0.5016114711761475\n",
      "Batch 1137 - loss: 0.5004177689552307\n",
      "Batch 1138 - loss: 0.4889375567436218\n",
      "Batch 1139 - loss: 0.4916343092918396\n",
      "Batch 1140 - loss: 0.46752479672431946\n",
      "Batch 1141 - loss: 0.5361562967300415\n",
      "Batch 1142 - loss: 0.5630406737327576\n",
      "Batch 1143 - loss: 0.48760807514190674\n",
      "Batch 1144 - loss: 0.5426276326179504\n",
      "Batch 1145 - loss: 0.5077547430992126\n",
      "Batch 1146 - loss: 0.5093610286712646\n",
      "Batch 1147 - loss: 0.4811326563358307\n",
      "Batch 1148 - loss: 0.4953817129135132\n",
      "Batch 1149 - loss: 0.420657217502594\n",
      "Batch 1150 - loss: 0.4929059147834778\n",
      "Batch 1151 - loss: 0.5090125203132629\n",
      "Batch 1152 - loss: 0.5379371643066406\n",
      "Batch 1153 - loss: 0.46953508257865906\n",
      "Batch 1154 - loss: 0.5010055899620056\n",
      "Batch 1155 - loss: 0.5409148335456848\n",
      "Batch 1156 - loss: 0.5711970329284668\n",
      "Batch 1157 - loss: 0.5273718237876892\n",
      "Batch 1158 - loss: 0.49927470088005066\n",
      "Batch 1159 - loss: 0.5676035284996033\n",
      "Batch 1160 - loss: 0.512830913066864\n",
      "Batch 1161 - loss: 0.4792718291282654\n",
      "Batch 1162 - loss: 0.46019065380096436\n",
      "Batch 1163 - loss: 0.5384165644645691\n",
      "Batch 1164 - loss: 0.49779266119003296\n",
      "Batch 1165 - loss: 0.4834277927875519\n",
      "Batch 1166 - loss: 0.5241131782531738\n",
      "Batch 1167 - loss: 0.46761956810951233\n",
      "Batch 1168 - loss: 0.4526524841785431\n",
      "Batch 1169 - loss: 0.5027013421058655\n",
      "Batch 1170 - loss: 0.5482484698295593\n",
      "Batch 1171 - loss: 0.48692086338996887\n",
      "Batch 1172 - loss: 0.48313823342323303\n",
      "Batch 1173 - loss: 0.5373001098632812\n",
      "Batch 1174 - loss: 0.4956464469432831\n",
      "Batch 1175 - loss: 0.5296007394790649\n",
      "Batch 1176 - loss: 0.4698992073535919\n",
      "Batch 1177 - loss: 0.48629283905029297\n",
      "Batch 1178 - loss: 0.442485511302948\n",
      "Batch 1179 - loss: 0.5237413048744202\n",
      "Batch 1180 - loss: 0.5092387199401855\n",
      "Batch 1181 - loss: 0.49269330501556396\n",
      "Batch 1182 - loss: 0.5699527859687805\n",
      "Batch 1183 - loss: 0.5823931694030762\n",
      "Batch 1184 - loss: 0.4868568480014801\n",
      "Batch 1185 - loss: 0.4835057556629181\n",
      "Batch 1186 - loss: 0.4755244553089142\n",
      "Batch 1187 - loss: 0.4750599265098572\n",
      "Batch 1188 - loss: 0.5648781061172485\n",
      "Batch 1189 - loss: 0.5359455943107605\n",
      "Batch 1190 - loss: 0.5394093990325928\n",
      "Batch 1191 - loss: 0.5406203866004944\n",
      "Batch 1192 - loss: 0.5010508894920349\n",
      "Batch 1193 - loss: 0.49601686000823975\n",
      "Batch 1194 - loss: 0.5203365683555603\n",
      "Batch 1195 - loss: 0.4198528230190277\n",
      "Batch 1196 - loss: 0.48788970708847046\n",
      "Batch 1197 - loss: 0.48174476623535156\n",
      "Batch 1198 - loss: 0.5173929929733276\n",
      "Batch 1199 - loss: 0.4794308543205261\n",
      "Batch 1200 - loss: 0.5097352266311646\n",
      "Batch 1201 - loss: 0.5011700391769409\n",
      "Batch 1202 - loss: 0.5511895418167114\n",
      "Batch 1203 - loss: 0.5277379751205444\n",
      "Batch 1204 - loss: 0.4659515619277954\n",
      "Batch 1205 - loss: 0.4945947229862213\n",
      "Batch 1206 - loss: 0.5038491487503052\n",
      "Batch 1207 - loss: 0.4951622784137726\n",
      "Batch 1208 - loss: 0.5184645056724548\n",
      "Batch 1209 - loss: 0.5174010992050171\n",
      "Batch 1210 - loss: 0.5562700629234314\n",
      "Batch 1211 - loss: 0.4786972105503082\n",
      "Batch 1212 - loss: 0.49009838700294495\n",
      "Batch 1213 - loss: 0.5107976794242859\n",
      "Batch 1214 - loss: 0.48001205921173096\n",
      "Batch 1215 - loss: 0.46414914727211\n",
      "Batch 1216 - loss: 0.49991241097450256\n",
      "Batch 1217 - loss: 0.5423253774642944\n",
      "Batch 1218 - loss: 0.5412037372589111\n",
      "Batch 1219 - loss: 0.5837506055831909\n",
      "Batch 1220 - loss: 0.5324998497962952\n",
      "Batch 1221 - loss: 0.4878113865852356\n",
      "Batch 1222 - loss: 0.46862292289733887\n",
      "Batch 1223 - loss: 0.4753313660621643\n",
      "Batch 1224 - loss: 0.5374859571456909\n",
      "Batch 1225 - loss: 0.5425835847854614\n",
      "Batch 1226 - loss: 0.46395957469940186\n",
      "Batch 1227 - loss: 0.4811416566371918\n",
      "Batch 1228 - loss: 0.5181909799575806\n",
      "Batch 1229 - loss: 0.5471423864364624\n",
      "Batch 1230 - loss: 0.5157420039176941\n",
      "Batch 1231 - loss: 0.44773462414741516\n",
      "Batch 1232 - loss: 0.5630868673324585\n",
      "Batch 1233 - loss: 0.5185291767120361\n",
      "Batch 1234 - loss: 0.5242905020713806\n",
      "Batch 1235 - loss: 0.4642558693885803\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
