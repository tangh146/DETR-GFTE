{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([65]) in the model instantiated\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([65, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Detr(\n",
       "  (model): DetrForObjectDetection(\n",
       "    (model): DetrModel(\n",
       "      (backbone): DetrConvModel(\n",
       "        (conv_encoder): DetrConvEncoder(\n",
       "          (model): FeatureListNet(\n",
       "            (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "            (bn1): DetrFrozenBatchNorm2d()\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "            (layer1): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "                (downsample): Sequential(\n",
       "                  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (1): DetrFrozenBatchNorm2d()\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Bottleneck(\n",
       "                (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (layer2): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "                (downsample): Sequential(\n",
       "                  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                  (1): DetrFrozenBatchNorm2d()\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Bottleneck(\n",
       "                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (3): Bottleneck(\n",
       "                (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (layer3): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "                (downsample): Sequential(\n",
       "                  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                  (1): DetrFrozenBatchNorm2d()\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (3): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (4): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (5): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (layer4): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "                (downsample): Sequential(\n",
       "                  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                  (1): DetrFrozenBatchNorm2d()\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Bottleneck(\n",
       "                (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn1): DetrFrozenBatchNorm2d()\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): DetrFrozenBatchNorm2d()\n",
       "                (drop_block): Identity()\n",
       "                (act2): ReLU(inplace=True)\n",
       "                (aa): Identity()\n",
       "                (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn3): DetrFrozenBatchNorm2d()\n",
       "                (act3): ReLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (position_embedding): DetrSinePositionEmbedding()\n",
       "      )\n",
       "      (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (query_position_embeddings): Embedding(100, 256)\n",
       "      (encoder): DetrEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x DetrEncoderLayer(\n",
       "            (self_attn): DetrAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): ReLU()\n",
       "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): DetrDecoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-5): 6 x DetrDecoderLayer(\n",
       "            (self_attn): DetrAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): DetrAttention(\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (class_labels_classifier): Linear(in_features=256, out_features=65, bias=True)\n",
       "    (bbox_predictor): DetrMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from detr_model import Detr\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from utils import load_config\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "config = load_config(r\"train.yaml\")\n",
    "\n",
    "model = Detr(\n",
    "    train_mode=True,\n",
    "    pretrained='facebook/detr-resnet-50',\n",
    "    checkpoint = None,\n",
    "    config=config)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# logger = WandbLogger(project='parallel_tables', name='stage_3_DETR_pretraining')\n",
    "\n",
    "# Set up checkpointing and trainer\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"validation/loss\",\n",
    "    filename=\"detr-{epoch:02d}-{validation/loss:.2f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    "    dirpath=r\"..\\checkpoints\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    log_every_n_steps=10,\n",
    "    # logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    val_check_interval=0.5,  # Run validation 2 times per epoch\n",
    "    devices=1,\n",
    "    accelerator=\"gpu\",\n",
    "    gradient_clip_val=0.1,\n",
    "    accumulate_grad_batches=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                   | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model | DetrForObjectDetection | 41.5 M | train\n",
      "---------------------------------------------------------\n",
      "41.3 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "41.5 M    Total params\n",
      "166.071   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d189eeecf7484e5584cc0f12e379f3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "PossibleUserWarning: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe0d081d78646a29f4272ca1cdd8d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f83357f170c47bb997b74b564b58854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7819bbf8cee43ae8a375a738b79bb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:193\u001b[0m, in \u001b[0;36mBatchFeature.convert_to_tensors\u001b[1;34m(self, tensor_type)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[1;32m--> 193\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m tensor\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:142\u001b[0m, in \u001b[0;36mBatchFeature._get_is_as_tensor_fns.<locals>.as_tensor\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 142\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[0;32m    147\u001b[0m ):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    575\u001b[0m     ckpt_path,\n\u001b[0;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m )\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:986\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1030\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1030\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:212\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     batch, _, __ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     batch_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:78\u001b[0m, in \u001b[0;36m_MaxSizeCycle.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m         out[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumed[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\Downloads\\DETR-GFTE\\data.py:73\u001b[0m, in \u001b[0;36mcreate_dataloaders.<locals>.<lambda>\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m     70\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TrainDataset(train_data_path, train_label_path, image_processor)\n\u001b[0;32m     71\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m TrainDataset(val_data_path, val_label_path, image_processor)\n\u001b[1;32m---> 73\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, collate_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m b: \u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_processor\u001b[49m\u001b[43m)\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, collate_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m b: collate_fn(b, image_processor), batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loader, val_loader\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\Downloads\\DETR-GFTE\\data.py:61\u001b[0m, in \u001b[0;36mcollate_fn\u001b[1;34m(batch, image_processor)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_fn\u001b[39m(batch, image_processor):\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# DETR authors employ various image sizes during training, making it not possible \u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# to directly batch together images. Hence they pad the images to the biggest \u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# resolution in a given batch, and create a corresponding binary pixel_mask \u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# which indicates which pixels are real/which are padding\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m---> 61\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[43mimage_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: labels\n\u001b[0;32m     67\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\detr\\image_processing_detr.py:1227\u001b[0m, in \u001b[0;36mDetrImageProcessor.pad\u001b[1;34m(self, images, annotations, constant_values, return_pixel_mask, return_tensors, data_format, input_data_format, update_bboxes, pad_size)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     masks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1222\u001b[0m         make_pixel_mask(image\u001b[38;5;241m=\u001b[39mimage, output_size\u001b[38;5;241m=\u001b[39mpadded_size, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format)\n\u001b[0;32m   1223\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[0;32m   1224\u001b[0m     ]\n\u001b[0;32m   1225\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m masks\n\u001b[1;32m-> 1227\u001b[0m encoded_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mBatchFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annotations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1230\u001b[0m     encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1231\u001b[0m         BatchFeature(annotation, tensor_type\u001b[38;5;241m=\u001b[39mreturn_tensors) \u001b[38;5;28;01mfor\u001b[39;00m annotation \u001b[38;5;129;01min\u001b[39;00m padded_annotations\n\u001b[0;32m   1232\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:79\u001b[0m, in \u001b[0;36mBatchFeature.__init__\u001b[1;34m(self, data, tensor_type)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, tensor_type: Union[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mstr\u001b[39m, TensorType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data)\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:199\u001b[0m, in \u001b[0;36mBatchFeature.convert_to_tensors\u001b[1;34m(self, tensor_type)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    198\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing values of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 199\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    200\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate padding \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
