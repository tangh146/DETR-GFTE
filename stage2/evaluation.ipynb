{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of many evaluators for the 5 models that we trained in this project. Some of these models require special annotations that are wrangled from the original PubTabNet annotations. The wrangled annotations are really quite big (some approaching 100GB in size) so we cannot feasibly and cheaply store them in cloud services. \n",
    "\n",
    "In the various filepaths in this notebook, we have included instructions for the data wrangling pipelines that you must apply to the original PubTabNet annotations to obtain the annotations that are ready to be used in this notebook. The pipelines referenced are all found in the misc folder.\n",
    "\n",
    "If you are stuck, please contact us for a walkthrough or request to temporarily host the annotations for you to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from utils import get_iou, coco2xyxy, xyxy2coco, get_psuedo_knn, process_target, get_table_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\remote desktop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNLightning(\n",
       "  (gnet): GraphNetwork(\n",
       "    (conv1): GCNConv(8, 128)\n",
       "    (conv2): GCNConv(128, 128)\n",
       "    (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (lin_final): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import GNLightning\n",
    "\n",
    "if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "gnet = GNLightning.load_from_checkpoint(checkpoint_path=r\"..\\checkpoints\\gnet_stage2.ckpt\",\n",
    "                                    d_model=128,\n",
    "                                    lr=1e-3,\n",
    "                                    batch_size=2,\n",
    "                                    num_workers=0,\n",
    "                                    train_path=r'..\\misc\\placeholder.jsonl',\n",
    "                                    val_path=r'..\\misc\\placeholder.jsonl')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "gnet.to(device)\n",
    "gnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "        input_labels,  \n",
    "        image_dir,  \n",
    "        iou_match_threshold=0.5,\n",
    "        device = \"cuda\"):\n",
    "    \n",
    "    eval_values = []\n",
    "\n",
    "    # Count total lines in the input file for progress tracking\n",
    "    with open(input_labels, 'r', encoding=\"utf8\") as infile:\n",
    "        total_lines = sum(1 for _ in infile)\n",
    "\n",
    "    # Progress bar setup\n",
    "    progress = tqdm(total=total_lines, desc=\"Processing Batches\", unit=\"samples\")\n",
    "\n",
    "    with open(input_labels, 'r', encoding=\"utf8\") as infile:\n",
    "\n",
    "        for line in infile:\n",
    "            # Parse the JSON line\n",
    "            label = json.loads(line)\n",
    "\n",
    "            # Update progress bar\n",
    "            progress.update(1)\n",
    "\n",
    "            # === FORWARD PASS THROUGH THE DETR MODEL TO GET THE PRED BBOXES AND HIDDEN STATES ===\n",
    "\n",
    "            image = Image.open(os.path.join(image_dir, label['filename'])).convert(\"RGB\")\n",
    "\n",
    "            # Forward pass through the model\n",
    "            # ...\n",
    "\n",
    "            bbox_indices = []\n",
    "            filtered_boxes = []\n",
    "            filtered_hidden_states = []\n",
    "            gt_bboxes_coco = label['gt_bboxes']\n",
    "            gt_bboxes_xyxy = [coco2xyxy(box) for box in gt_bboxes_coco]\n",
    "            gt_bbox_indices = torch.tensor(label['gt_bbox_indices'], dtype=torch.int)\n",
    "\n",
    "            for pred_box in gt_bboxes_xyxy:\n",
    "\n",
    "                # Find the ground truth box with the highest IoU\n",
    "                max_iou = 0\n",
    "                best_gt_index = -1\n",
    "                for i, gt_bbox in enumerate(gt_bboxes_xyxy):\n",
    "                    iou = get_iou(pred_box, gt_bbox)\n",
    "                    if iou > max_iou:\n",
    "                        max_iou = iou\n",
    "                        best_gt_index = i\n",
    "\n",
    "                # Keep the DETR bbox if the highest IoU exceeds the threshold\n",
    "                if max_iou >= iou_match_threshold:\n",
    "                    filtered_boxes.append(pred_box)\n",
    "                    bbox_indices.append(gt_bbox_indices[best_gt_index])\n",
    "\n",
    "            filtered_boxes = torch.tensor([xyxy2coco(bbox) for bbox in filtered_boxes])\n",
    "            filtered_hidden_states = torch.tensor(filtered_hidden_states)\n",
    "\n",
    "            probs, edge_index = gnet(filtered_boxes, torch.tensor([image.size[0], image.size[1]]))\n",
    "\n",
    "            probs, edge_index = probs.to('cpu'), edge_index.to('cpu')\n",
    "\n",
    "            # === GET THE GROUNTRUTH EDGE SET AS A DICT OF (START BBOX INDEX, END BBOX INDEX): CLASS ===\n",
    "\n",
    "            thead_grid, tbody_grid = get_table_grid(''.join(label['html']))\n",
    "            table_grid = thead_grid + tbody_grid\n",
    "\n",
    "            gt_edge_index = get_psuedo_knn(torch.tensor(gt_bboxes_coco))\n",
    "\n",
    "            gt_bbox_index_pairs = torch.stack((\n",
    "                gt_bbox_indices[gt_edge_index[0]],  # Start bounding boxes\n",
    "                gt_bbox_indices[gt_edge_index[1]]   # End bounding boxes\n",
    "            ), dim=1)\n",
    "\n",
    "            gt_classes = process_target(gt_bbox_index_pairs, table_grid) # dtype long\n",
    "\n",
    "            gt_edgeset = {}\n",
    "\n",
    "            # Iterate over the pairs and classes\n",
    "            for pair, gt_class in zip(gt_bbox_index_pairs, gt_classes):\n",
    "                start_bbox_index = pair[0].item()  # Convert to a standard Python integer\n",
    "                end_bbox_index = pair[1].item()   # Convert to a standard Python integer\n",
    "                gt_edgeset[(start_bbox_index, end_bbox_index)] = gt_class.item()  # Map to the class value \n",
    "\n",
    "            # === PARSE THROUGH EACH PRED EDGE AND CHECK IF IT MATCHES WITH THE GT EDGESET ===\n",
    "            numerator = 0\n",
    "            for i, (start, end) in enumerate(edge_index.t()):\n",
    "                \n",
    "                # Get the predicted class for the edge\n",
    "                predicted_class = torch.argmax(probs[i]).item()\n",
    "\n",
    "                # no relationship edge, skip\n",
    "                if predicted_class == 0: continue\n",
    "\n",
    "                if (bbox_indices[start].item(), bbox_indices[end].item()) in gt_edgeset and gt_edgeset[(bbox_indices[start].item(), bbox_indices[end].item())] == predicted_class:\n",
    "                    numerator+=1\n",
    "\n",
    "            denominator = sum(1 for value in gt_edgeset.values() if value != 0)\n",
    "\n",
    "            eval_values.append(numerator/denominator)\n",
    "\n",
    "            if progress.n == 50: break\n",
    "\n",
    "        # Close the progress bar\n",
    "        progress.close()\n",
    "\n",
    "    return eval_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79967b6fb7d42eca47ae8b17a53d636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Batches:   0%|          | 0/9081 [00:00<?, ?samples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_values = evaluate(\n",
    "    input_labels=r'path to the output of running ptn2gcn with split=val',\n",
    "    # insert link to pubtabnet val image directory here\n",
    "    image_dir=r\"path to pubtabnet val images directory\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849713198478725\n"
     ]
    }
   ],
   "source": [
    "print(sum(eval_values)/len(eval_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
