{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from utils import get_iou, coco2xyxy, xyxy2coco, get_psuedo_knn, process_target, get_table_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNLightning(\n",
       "  (gnet): GraphNetwork(\n",
       "    (conv1): GCNConv(8, 128)\n",
       "    (conv2): GCNConv(128, 128)\n",
       "    (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (lin_final): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       "  (criterion): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import GNLightning\n",
    "\n",
    "if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "gnet = GNLightning.load_from_checkpoint(checkpoint_path=r\"..\\checkpoints\\gnet_stage1.ckpt\",\n",
    "                                    d_model=128,\n",
    "                                    lr=1e-3,\n",
    "                                    batch_size=2,\n",
    "                                    num_workers=0,\n",
    "                                    train_path=r'..\\datasets\\gcn\\stage3\\ptn2gcn\\train.jsonl',\n",
    "                                    val_path=r'..\\datasets\\gcn\\stage3\\ptn2gcn\\val.jsonl')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "gnet.to(device)\n",
    "gnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "        input_labels,  \n",
    "        image_dir,  \n",
    "        iou_match_threshold=0.5,\n",
    "        device = \"cuda\"):\n",
    "    \n",
    "    eval_values = []\n",
    "\n",
    "    # Count total lines in the input file for progress tracking\n",
    "    with open(input_labels, 'r', encoding=\"utf8\") as infile:\n",
    "        total_lines = sum(1 for _ in infile)\n",
    "\n",
    "    # Progress bar setup\n",
    "    progress = tqdm(total=total_lines, desc=\"Processing Batches\", unit=\"samples\")\n",
    "\n",
    "    with open(input_labels, 'r', encoding=\"utf8\") as infile:\n",
    "\n",
    "        for line in infile:\n",
    "            # Parse the JSON line\n",
    "            label = json.loads(line)\n",
    "\n",
    "            # Update progress bar\n",
    "            progress.update(1)\n",
    "\n",
    "            # === FORWARD PASS THROUGH THE DETR MODEL TO GET THE PRED BBOXES AND HIDDEN STATES ===\n",
    "\n",
    "            image = Image.open(os.path.join(image_dir, label['filename'])).convert(\"RGB\")\n",
    "\n",
    "            # Forward pass through the model\n",
    "            # ...\n",
    "\n",
    "            bbox_indices = []\n",
    "            filtered_boxes = []\n",
    "            filtered_hidden_states = []\n",
    "            gt_bboxes_coco = label['gt_bboxes']\n",
    "            gt_bboxes_xyxy = [coco2xyxy(box) for box in gt_bboxes_coco]\n",
    "            gt_bbox_indices = torch.tensor(label['gt_bbox_indices'], dtype=torch.int)\n",
    "\n",
    "            for pred_box in gt_bboxes_xyxy:\n",
    "\n",
    "                # Find the ground truth box with the highest IoU\n",
    "                max_iou = 0\n",
    "                best_gt_index = -1\n",
    "                for i, gt_bbox in enumerate(gt_bboxes_xyxy):\n",
    "                    iou = get_iou(pred_box, gt_bbox)\n",
    "                    if iou > max_iou:\n",
    "                        max_iou = iou\n",
    "                        best_gt_index = i\n",
    "\n",
    "                # Keep the DETR bbox if the highest IoU exceeds the threshold\n",
    "                if max_iou >= iou_match_threshold:\n",
    "                    filtered_boxes.append(pred_box)\n",
    "                    bbox_indices.append(gt_bbox_indices[best_gt_index])\n",
    "\n",
    "            filtered_boxes = torch.tensor([xyxy2coco(bbox) for bbox in filtered_boxes])\n",
    "            filtered_hidden_states = torch.tensor(filtered_hidden_states)\n",
    "\n",
    "            probs, edge_index = gnet(filtered_boxes, torch.tensor([image.size[0], image.size[1]]))\n",
    "\n",
    "            probs, edge_index = probs.to('cpu'), edge_index.to('cpu')\n",
    "\n",
    "            # === GET THE GROUNTRUTH EDGE SET AS A DICT OF (START BBOX INDEX, END BBOX INDEX): CLASS ===\n",
    "\n",
    "            thead_grid, tbody_grid = get_table_grid(''.join(label['html']))\n",
    "            table_grid = thead_grid + tbody_grid\n",
    "\n",
    "            gt_edge_index = get_psuedo_knn(torch.tensor(gt_bboxes_coco))\n",
    "\n",
    "            gt_bbox_index_pairs = torch.stack((\n",
    "                gt_bbox_indices[gt_edge_index[0]],  # Start bounding boxes\n",
    "                gt_bbox_indices[gt_edge_index[1]]   # End bounding boxes\n",
    "            ), dim=1)\n",
    "\n",
    "            gt_classes = process_target(gt_bbox_index_pairs, table_grid) # dtype long\n",
    "\n",
    "            gt_edgeset = {}\n",
    "\n",
    "            # Iterate over the pairs and classes\n",
    "            for pair, gt_class in zip(gt_bbox_index_pairs, gt_classes):\n",
    "                start_bbox_index = pair[0].item()  # Convert to a standard Python integer\n",
    "                end_bbox_index = pair[1].item()   # Convert to a standard Python integer\n",
    "                gt_edgeset[(start_bbox_index, end_bbox_index)] = gt_class.item()  # Map to the class value \n",
    "\n",
    "            # === PARSE THROUGH EACH PRED EDGE AND CHECK IF IT MATCHES WITH THE GT EDGESET ===\n",
    "            numerator = 0\n",
    "            counted_edges = set()\n",
    "            for i, (start, end) in enumerate(edge_index.t()):\n",
    "                \n",
    "                # Get the predicted class for the edge\n",
    "                predicted_class = torch.argmax(probs[i]).item()\n",
    "\n",
    "                # no relationship edge, skip\n",
    "                if predicted_class == 0: \n",
    "                    continue\n",
    "\n",
    "                # Convert to tuple for comparison\n",
    "                edge = (bbox_indices[start].item(), bbox_indices[end].item())\n",
    "\n",
    "                # Ensure unique counting\n",
    "                if edge in counted_edges:\n",
    "                    continue\n",
    "\n",
    "                if edge in gt_edgeset and gt_edgeset[edge] == predicted_class:\n",
    "                    numerator += 1\n",
    "                    counted_edges.add(edge)    # Convert to tuple for comparison\n",
    "                edge = (bbox_indices[start].item(), bbox_indices[end].item())\n",
    "\n",
    "                # Ensure unique counting\n",
    "                if edge in counted_edges:\n",
    "                    continue\n",
    "\n",
    "                if edge in gt_edgeset and gt_edgeset[edge] == predicted_class:\n",
    "                    numerator += 1\n",
    "                    counted_edges.add(edge)\n",
    "\n",
    "            denominator = sum(1 for value in gt_edgeset.values() if value != 0)\n",
    "\n",
    "            # print('edge_index:', edge_index)\n",
    "            # print('gt_edgeset keys:', gt_edgeset.keys())\n",
    "            print('numerator, denominator:', numerator, denominator)\n",
    "\n",
    "            eval_values.append(numerator/denominator)\n",
    "\n",
    "            if progress.n == 50: break\n",
    "\n",
    "        # Close the progress bar\n",
    "        progress.close()\n",
    "\n",
    "    return eval_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa07875abaf42b98aff59acfae360d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Batches:   0%|          | 0/9081 [00:00<?, ?samples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerator, denominator: 24 52\n",
      "numerator, denominator: 44 104\n",
      "numerator, denominator: 20 20\n",
      "numerator, denominator: 28 44\n",
      "numerator, denominator: 74 112\n",
      "numerator, denominator: 264 656\n",
      "numerator, denominator: 12 30\n",
      "numerator, denominator: 110 202\n",
      "numerator, denominator: 46 80\n",
      "numerator, denominator: 247 614\n",
      "numerator, denominator: 98 162\n",
      "numerator, denominator: 61 110\n",
      "numerator, denominator: 56 104\n",
      "numerator, denominator: 126 230\n",
      "numerator, denominator: 90 134\n",
      "numerator, denominator: 264 454\n",
      "numerator, denominator: 263 650\n",
      "numerator, denominator: 172 440\n",
      "numerator, denominator: 405 666\n",
      "numerator, denominator: 220 448\n",
      "numerator, denominator: 71 162\n",
      "numerator, denominator: 85 154\n",
      "numerator, denominator: 43 80\n",
      "numerator, denominator: 548 1072\n",
      "numerator, denominator: 108 232\n",
      "numerator, denominator: 88 146\n",
      "numerator, denominator: 440 870\n",
      "numerator, denominator: 82 168\n",
      "numerator, denominator: 168 290\n",
      "numerator, denominator: 32 82\n",
      "numerator, denominator: 42 78\n",
      "numerator, denominator: 138 362\n",
      "numerator, denominator: 138 256\n",
      "numerator, denominator: 356 838\n",
      "numerator, denominator: 110 194\n",
      "numerator, denominator: 146 232\n",
      "numerator, denominator: 231 538\n",
      "numerator, denominator: 184 424\n",
      "numerator, denominator: 76 130\n",
      "numerator, denominator: 36 44\n",
      "numerator, denominator: 214 388\n",
      "numerator, denominator: 116 266\n",
      "numerator, denominator: 30 56\n",
      "numerator, denominator: 30 42\n",
      "numerator, denominator: 275 556\n",
      "numerator, denominator: 281 786\n",
      "numerator, denominator: 198 364\n",
      "numerator, denominator: 662 1274\n",
      "numerator, denominator: 81 142\n",
      "numerator, denominator: 138 342\n"
     ]
    }
   ],
   "source": [
    "eval_values = evaluate(\n",
    "    input_labels=r'..\\datasets\\gcn\\stage3\\ptn2gcn\\val.jsonl',\n",
    "    # insert link to pubtabnet val image directory here\n",
    "    image_dir=r\"C:\\Users\\remote desktop\\Downloads\\pubtabnet\\val\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5288683135277303\n"
     ]
    }
   ],
   "source": [
    "print(sum(eval_values)/len(eval_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
