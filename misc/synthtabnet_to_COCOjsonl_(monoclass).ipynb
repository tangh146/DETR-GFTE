{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max bbox padding: 236\n",
      "max table width padding: 15\n",
      "max table height padding: 25\n",
      "deformity count: 0\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import json\n",
    "from utils import get_table_grid\n",
    "\n",
    "def filter_and_process_jsonl(input_path, output_path, mode='train'):\n",
    "    max_annotations_length = 0\n",
    "    max_table_width = 0\n",
    "    max_table_height = 0\n",
    "    impurities = 0\n",
    "\n",
    "    with open(input_path, 'r', encoding=\"utf8\") as infile, open(output_path, 'w', encoding=\"utf8\") as outfile:\n",
    "        for line in infile:\n",
    "            # Parse the JSON line\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "            except:\n",
    "                # print(line)\n",
    "                # raise Exception('json.loads error')\n",
    "                continue\n",
    "            \n",
    "            # Check if split == \"train\"\n",
    "            if data[\"split\"] == mode:\n",
    "                bbox = []\n",
    "                for cell in data['html']['cells']:\n",
    "                    if cell['bbox'][4]==2:\n",
    "                        bbox.append(cell['bbox'][:4])\n",
    "                    else:\n",
    "                        # for empty cells, we define the bbox to be as small and out of the way as possible\n",
    "                        # such as to be automatically voided as candidate gt bboxes when calculating iou scores\n",
    "                        bbox.append([0,0,0.01,0.01])\n",
    "\n",
    "                # in this case we do not need bbox classification, so there is only 1 class\n",
    "                category_id = [0] * len(bbox)\n",
    "\n",
    "                annotations = []\n",
    "                for b, c in zip(bbox, category_id):\n",
    "                    xmin, ymin, xmax, ymax = b\n",
    "                    width = xmax - xmin\n",
    "                    height = ymax - ymin\n",
    "                    area = width * height\n",
    "                    annotation = {\n",
    "                        'bbox': [xmin, ymin, width, height],\n",
    "                        'category_id': c,\n",
    "                        'area': area\n",
    "                    }\n",
    "                    annotations.append(annotation)\n",
    "\n",
    "                # image_id is actually not necessary for training and stn doesnt have it\n",
    "                output = {\n",
    "                    'filename': data['filename'],\n",
    "                    'image_id': 0,\n",
    "                    'html': data['html']['structure']['tokens'],\n",
    "                    'annotations': annotations\n",
    "                }\n",
    "\n",
    "                pure = True\n",
    "\n",
    "                html = data['html']['structure']['tokens']\n",
    "                html = ''.join(html)\n",
    "                \n",
    "                max_annotations_length = max(max_annotations_length, len(annotations))\n",
    "\n",
    "                thead_grid, tbody_grid = get_table_grid(html)\n",
    "                table_grid = thead_grid + tbody_grid\n",
    "                max_table_width = max(max_table_width, len(table_grid[0]))\n",
    "                max_table_height = max(max_table_height, len(table_grid))\n",
    "\n",
    "                base_width = len(table_grid[0])\n",
    "                for row in table_grid:\n",
    "                    if len(row) != base_width:\n",
    "                        pure = False\n",
    "\n",
    "                if pure:\n",
    "                    # Write the JSON object to the new JSONL file\n",
    "                    outfile.write(json.dumps(output) + '\\n')\n",
    "                else:\n",
    "                    impurities += 1\n",
    "\n",
    "    print(f\"max bbox padding: {max_annotations_length}\")\n",
    "    print(f\"max table width padding: {max_table_width}\")\n",
    "    print(f\"max table height padding: {max_table_height}\")\n",
    "    print(f\"deformity count: {impurities}\")\n",
    "\n",
    "input_jsonl_path = r\"C:\\Users\\tangy\\Downloads\\fintabnet\\fintabnet\\synthetic_data.jsonl\"\n",
    "output_jsonl_path = r\"C:\\Users\\tangy\\Downloads\\DETR-GFTE\\datasets\\stn_fintabnet_val.jsonl\"\n",
    "\n",
    "filter_and_process_jsonl(input_jsonl_path, output_jsonl_path, mode='val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
