{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augment the coco format labels with DETR hidden states for stage 3 of the project\n",
    "\n",
    "input: output of ptn2gcn\n",
    "\n",
    "runs DETR on each model to get the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.ops as ops  # For NMS\n",
    "from utils import get_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn2stage3(\n",
    "        input_labels, \n",
    "        output_labels, \n",
    "        image_dir, \n",
    "        detr_model, \n",
    "        checkpoint, \n",
    "        batch_size, \n",
    "        iou_threshold=0.5, \n",
    "        confidence_threshold=0.5, \n",
    "        iou_match_threshold=0.5):\n",
    "    # Set up the image processor and the DETR model\n",
    "    image_processor = DetrImageProcessor.from_pretrained(detr_model)\n",
    "    model = DetrForObjectDetection.from_pretrained(detr_model)\n",
    "    state_dict = torch.load(checkpoint)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Count total lines in the input file for progress tracking\n",
    "    with open(input_labels, 'r', encoding=\"utf8\") as infile:\n",
    "        total_lines = sum(1 for _ in infile)\n",
    "\n",
    "    # Progress bar setup\n",
    "    progress = tqdm(total=total_lines, desc=\"Processing Batches\", unit=\"samples\")\n",
    "\n",
    "    with open(input_labels, 'r', encoding=\"utf8\") as infile, open(output_labels, 'w', encoding=\"utf8\") as outfile:\n",
    "        labels = []\n",
    "\n",
    "        for line in infile:\n",
    "            # Parse the JSON line\n",
    "            label = json.loads(line)\n",
    "            labels.append(label)\n",
    "\n",
    "            # Update progress bar\n",
    "            progress.update(1)\n",
    "\n",
    "            if len(labels) == batch_size:\n",
    "                # Load and process the batch of images\n",
    "                images = [Image.open(os.path.join(image_dir, label['filename'])).convert(\"RGB\") for label in labels]\n",
    "                inputs = image_processor(images=images, return_tensors=\"pt\")\n",
    "\n",
    "                # Forward pass through the model\n",
    "                outputs = model(**inputs)\n",
    "\n",
    "                logits = outputs.logits  # Shape: (batch_size, num_queries, num_classes)\n",
    "                pred_boxes = outputs.pred_boxes  # Shape: (batch_size, num_queries, 4)\n",
    "                hidden_states = outputs.last_hidden_state  # Shape: (batch_size, num_queries, hidden_dim)\n",
    "\n",
    "                # Process each image in the batch\n",
    "                for idx, label in enumerate(labels):\n",
    "                    logits_img = logits[idx]  # Shape: (num_queries, num_classes)\n",
    "                    boxes_img = pred_boxes[idx]  # Shape: (num_queries, 4)\n",
    "                    hidden_states_img = hidden_states[idx]  # Shape: (num_queries, hidden_dim)\n",
    "\n",
    "                    # as per the docs\n",
    "                    prob = F.softmax(logits_img, dim=-1)\n",
    "                    scores, _ = prob[..., :-1].max(-1)\n",
    "\n",
    "                    # Filter by confidence threshold\n",
    "                    keep = scores > confidence_threshold\n",
    "                    boxes_img = boxes_img[keep]\n",
    "                    hidden_states_img = hidden_states_img[keep]\n",
    "                    scores = scores[keep]\n",
    "\n",
    "                    # Apply NMS\n",
    "                    if boxes_img.shape[0] > 0:\n",
    "                        keep_nms = ops.nms(boxes_img, scores, iou_threshold)\n",
    "                        boxes_img = boxes_img[keep_nms]\n",
    "                        hidden_states_img = hidden_states_img[keep_nms]\n",
    "\n",
    "                    # Match DETR boxes to ground truth boxes\n",
    "                    bbox_indices = []\n",
    "                    filtered_boxes = []\n",
    "                    filtered_hidden_states = []\n",
    "                    gt_bboxes = label['gt_bboxes']\n",
    "                    gt_bbox_indices = label['gt_bbox_indices']\n",
    "\n",
    "                    for detr_bbox, hidden_state in zip(boxes_img, hidden_states_img):\n",
    "                        # Convert DETR bbox to COCO format (list of 4 numbers)\n",
    "                        detr_bbox_coco = detr_bbox.detach().cpu().numpy().tolist()\n",
    "\n",
    "                        # Find the ground truth box with the highest IoU\n",
    "                        max_iou = 0\n",
    "                        best_gt_index = -1\n",
    "                        for i, gt_bbox in enumerate(gt_bboxes):\n",
    "                            iou = get_iou(detr_bbox_coco, gt_bbox)\n",
    "                            if iou > max_iou:\n",
    "                                max_iou = iou\n",
    "                                best_gt_index = i\n",
    "\n",
    "                        # Keep the DETR bbox if the highest IoU exceeds the threshold\n",
    "                        if max_iou >= iou_match_threshold:\n",
    "                            filtered_boxes.append(detr_bbox_coco)\n",
    "                            filtered_hidden_states.append(hidden_state.detach().cpu().numpy().tolist())\n",
    "                            bbox_indices.append(gt_bbox_indices[best_gt_index])\n",
    "\n",
    "                    # Add fields to the label\n",
    "                    label['bboxes'] = filtered_boxes\n",
    "                    label['hidden_states'] = filtered_hidden_states\n",
    "                    label['bbox_indices'] = bbox_indices\n",
    "\n",
    "                # Write the processed batch to the output file\n",
    "                for label in labels:\n",
    "                    outfile.write(json.dumps(label) + '\\n')\n",
    "\n",
    "                # Reset batch\n",
    "                labels = []\n",
    "\n",
    "        # Close the progress bar\n",
    "        progress.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn2stage3(\n",
    "    input_labels=r\"C:\\Users\\tangy\\Downloads\\DETR-GFTE\\datasets\\ptn_examples_val\\PubTabNet_Examples-val.jsonl\",\n",
    "    output_labels=r\"C:\\Users\\tangy\\Downloads\\DETR-GFTE\\datasets\\ptn_examples_val\\ptn_examples_val.jsonl\",\n",
    "    image_dir=r\"\",\n",
    "    detr_model=\"facebook/detr-resnet-50\",\n",
    "    checkpoint=\"\",\n",
    "    batch_size=4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
